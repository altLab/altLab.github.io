<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

		<!-- <base href="https://altlab.org/d/" />  -->
		<title>Newsletter altLab - 2017-06-01 - Nº 109 | altLab Documenta</title>
				<meta name="description" content="Newsletter altLab Nº109 de 1 de junho de 2017">
				<meta property="og:type" content="article" />
		<meta property="og:title" content="Newsletter altLab - 2017-06-01 - Nº 109 | altLab Documenta" />
		<meta property="og:description" content="Newsletter altLab Nº109 de 1 de junho de 2017" />
		<meta property="og:url" content="https://altlab.org/d/m/jpralves/newsletters/2017/109/" />
		<meta property="og:site_name" content="altLab Documenta" />

		<!-- Bootstrap -->
		<link href="../../../../../themes/altlab/css/bootstrap.min.css" rel="stylesheet">
		<link href="../../../../../themes/altlab/override-test.css" rel="stylesheet">
		<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
		<script src="../../../../../themes/altlab/js/jquery-1.12.4.min.js"></script>
		<!-- Include all compiled plugins (below), or include individual files as needed -->
		<script src="../../../../../themes/altlab/js/bootstrap.min.js"></script>

	</head>
	<body>
<div class="container">
<div class="container-fluid">
      <div class="page-header hidden-xs" id="brand-logo">
        <h1><a href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-gradoverwhite.png" width="180" height="120" alt="Home" style="vertical-align:text-bottom" /></a> Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></h1>

      </div>
			<nav class="navbar navbar-inverse">

				<div class="container-fluid">
					<div class="navbar-header">
						<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#myNavbar">
							<span class="sr-only">Toggle navigation</span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
<div class="visible-xs">
<a class="navbar-brand" href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-documenta.png" width="58" height="35" alt="Home" style="margin-top: -7px;"></a>
						<a class="navbar-brand" href="../../../../../index.html">Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></a></div>
					</div>
					<div class="collapse navbar-collapse" id="myNavbar">
						<ul class="nav navbar-nav">

           	<li id="dropdown.1" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Membros <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../index.html">Index</a>
</li>
   
           	<li id="dropdown.101" class="dropdown">
		<a href="../../../index.html">João Alves <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.102" class="dropdown">
		<a href="../../../../sislog/index.html">Fernando Carvalho <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.103" class="dropdown">
		<a href="../../../../pangelo/index.html">Pedro Ângelo <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.104" class="dropdown">
		<a href="../../../../dinix/index.html">Dinix <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../funke/funke.html">m/funke/funke</a>
  
   	</li>
            	<li id="dropdown.106" class="dropdown">
		<a href="../../../../afonsom/index.html">Afonso Muralha <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.107" class="dropdown">
		<a href="../../../../x3msnake/index.html">X3msnake <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../ampmendes/index.html">António Mendes</a>
  
   	</li>
            	<li>
		<a href="../../../../guardajoao/index.html">GuardaJoao</a>
  
   	</li>
            	<li>
		<a href="../../../../jac/index.html">JAC</a>
  
   	</li>
            	<li>
		<a href="../../../../nini/index.html">Nuno Nini</a>
  
   	</li>
 
</ul>
    	</li>
            	<li id="dropdown.2" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Documentação Partilhada <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../../s/index.html">Index</a>
</li>
   
                         	<li id="dropdown.203" class="dropdown">
		<a href="../../../../../s/workshops/index.html">Workshops <span class="caret"></span></a>
  
      	</li>
                   	<li>
		<a href="../../../../../s/documenta/index.html">Documenta DevMap</a>
  
   	</li>
                   	<li>
		<a href="../../../../../s/processos/index.html">Processos do Lab (draft)</a>
  
   	</li>
            	<li id="dropdown.208" class="dropdown">
		<a href="../../../../../s/recursos/index.html">Recursos <span class="caret"></span></a>
  
      	</li>
 
</ul>
    	</li>
 
						</ul>
					</div>
				</div>
			</nav>

			<div class="container">
				<div class="container">
				<section id="content">
					<div class="inner">
						<p><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
<link rel="stylesheet" href="../res/_shb.css"></p>

<script src="../res/_shb.min.js" type="text/javascript"></script>

<div style="text-align: center;">
<button class="btn my-btn btn-md disabled">Share:</button>
<div class="btn-group" id="shb"></div>
</div>

<p><br></p>

<h1 id="topo"><img src="../res/__Titulo.png" alt="Newsletter altLab" /></h1>

<p>2017-06-01 - Nº 109</p>

<div style="position: fixed; z-index: 65535; right: 10px; bottom: 10px;">
<a href='#topo' title='Go to Top'><img src="../res/_gotop.png" alt="go to top image" /></a>
</div>

<div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'pt', layout: google.translate.TranslateElement.FloatPosition.TOP_LEFT, multilanguagePage: true}, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<p><DIV class="articledetail"><SPAN class="articledetail"></p>

<h2>Editorial</h2>

<p>Esta é a Newsletter Nº 109 que se apresenta com o mesmo formato que as anteriores. Se gostar da Newsletter partilhe-a!</p>

<p>Todas as Newsletters encontram-se indexadas no <a href="../../index.html">link</a>.</p>

<p>Esta Newsletter tem os seguintes tópicos:</p>

<ul>
<li><a href="#Novidades-da-Semana">Novidades da Semana</a></li>
<li><a href="#Ciencia-e-Tecnologia">Ciência e Tecnologia</a></li>
<li><a href="#Documentacao">Documentação</a></li>
<li><a href="#Projetos-Maker">Projetos Maker</a></li>
</ul>

<p>Faz hoje anos que nascia em 1907 <a href="https://en.wikipedia.org/wiki/Frank_Whittle">Frank Whittle</a>. Este engenheiro inglês da RAF ficou na história como sendo o responsável pela invenção do motor a jato. Whittle continuou a trabalhar no princípio do motor a jato após o trabalho da sua tese, mas finalmente abandonou-o quando através de cálculos demonstrou que pesaria tanto como um motor convencional do mesmo impulso. Ponderando o problema que ele pensou: "Por que não substituir uma turbina pelo motor de pistão?" Em vez de usar um motor de pistão para fornecer o ar comprimido para o queimador, uma turbina pode ser usada para extrair algum poder da exaustão e conduzir um compressor similar ao utilizado para super-alimentadores. O impulso de escape restante iria alimentar o avião.
Faz hoje também anos <a href="https://en.wikipedia.org/wiki/Nicolas_L%C3%A9onard_Sadi_Carnot">Nicolas Léonard Sadi Carnot</a>. Este físico e engenheiro militar francês nascido em 1796 ficou conhecido como o paii da termodinâmica. Carnot criou a primeira teoria bem sucedida da eficiência máxima de motores de calor. O trabalho de Carnot atraiu pouca atenção durante sua vida, mas depois foi usado por Rudolf Clausius e Lord Kelvin para formalizar a segunda lei da termodinâmica e definir o conceito de entropia. Ficou conhecido pelo ciclo de Carnot e pelo teorema de Carnot que é um princípio que especifica os limites da eficiência máxima que qualquer motor térmico pode obter. A eficiência de um motor Carnot depende unicamente da diferença entre os reservatórios de temperatura quente e fria.</p>

<p>Esta semana ficámos a saber que a SpaceX fez história ao lançar com sucesso o primeiro foguete com o seu "booster" reutilizado. A dupla conquista de relançar um foguete usado e recuperar o foguete novamente foram saudados pelo milionário do fundador da SpaceX, Elon Musk, como um passo revolucionário na busca em reduzir os custos de lançamento e reduzir os intervalos entre os slots espaciais.
A NASA alterou o nome da nave espacial Solar Probe Plus - a primeira missão da humanidade para uma estrela, que será lançada em 2018 - para "Parker Solar Probe" em homenagem ao astrofísico Eugene Parker. Esta missão pretende sondar a coroa exterior do Sol. Vai-se aproximar até 8,5 raios solares (5,9 milhões de quilómetros) da "superfície" do Sol
Também esta semana começou a construção do maior telescópio óptico do mundo. Uma vez completo, será conhecido como o maior telescópio óptico do mundo, que é cinco vezes maior do que os principais instrumentos de observação que estamos a usar hoje. De acordo com os especialistas, o tamanho do telescópio óptico tem o potencial de transformar a nossa compreensão do universo, e com seu espelho principal, ele terá cerca de 39 metros. O ELT está situado numa montanha de 3.000 metros de altura no meio do deserto de Atacama e está calendarizado para começar a trabalhar em 2024.</p>

<p>Na Newsletter desta semana apresentamos diversos projetos de maker. São igualmente apresentados três livros, um sobre partilha de conhecimento com o mundo de forma sustentada, outro sobre introdução a robôs autónomos e o ultimo sobre fundamentos de programação - uma aproximação estruturada e modular usando C++.</p>

<p><img src="../res/_jpralves.jpg" alt="jpralves" /> João Alves (<a href="https://altlab.org/d/m/jpralves/newsletters/2017/109/&#x6d;&#97;&#105;&#x6c;&#116;&#111;&#x3a;&#x6a;&#112;&#114;&#x61;&#108;&#118;&#x65;&#x73;&#64;g&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;o&#x6d;#x6d;&a&i&l&t&o&:&j&p&r&a&l&v&e&s&@g&m&a&i&l&.&co&m"><span class="__cf_email__" data-cfemail="abc1dbd9cac7ddced8ebccc6cac2c785c8c4c6">[email&#160;protected]</span></a>)</p>

<p>O conteúdo da Newsletter encontra-se sob a licença <img src="../res/_by-nc-sa4.0.png" alt="by-nc-sa4.0" /> <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>

<p></SPAN></DIV></p>

<hr />

<h1 id="Novidades-da-Semana">Novidades da Semana</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS109_SpacexMakesHistoryBySuccessful.jpg" alt="SpaceX makes history by successfully launching first recycled rocket booster" class="lefter"></p>

<h2><a href="http://www.telegraph.co.uk/news/2017/03/31/spacex-makes-history-successfully-launching-first-recycled-rocket/">SpaceX makes history by successfully launching first recycled rocket booster</a></h2>

<p><em>"A SpaceX Falcon 9 rocket recovered at sea from its maiden flight last year blasted off again from Florida on Thursday in the first successful launch of a recycled orbital-class booster, then capped the feat with another return landing on an ocean platform. The unprecedented twin achievements of re-launching a used rocket and salvaging the vehicle yet again were hailed by billionaire SpaceX founder Elon Musk as a revolutionary step in his quest to slash launch costs and shorten intervals between space shots."</em> <a href="http://www.telegraph.co.uk/news/2017/03/31/spacex-makes-history-successfully-launching-first-recycled-rocket/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS109_NasaRenamesSolarProbeMissionTo.jpg" alt="NASA Renames Solar Probe Mission to Honor Pioneering Physicist Eugene Parker" class="lefter"></p>

<h2><a href="https://www.nasa.gov/feature/goddard/2017/nasa-renames-solar-probe-mission-to-honor-pioneering-physicist-eugene-parker">NASA Renames Solar Probe Mission to Honor Pioneering Physicist Eugene Parker</a></h2>

<p><em>"NASA has renamed the Solar Probe Plus spacecraft — humanity’s first mission to a star, which will launch in 2018 — as the Parker Solar Probe in honor of astrophysicist Eugene Parker. The announcement was made at a ceremony at the University of Chicago, where Parker serves as the S. Chandrasekhar Distinguished Service Professor Emeritus, Department of Astronomy and Astrophysics. In 1958, Parker — then a young professor at the university’s Enrico Fermi Institute — published an article in the Astrophysical Journal called “Dynamics of the interplanetary gas and magnetic fields.” Parker believed there was high speed matter and magnetism constantly escaping the sun, and that it affected the planets and space throughout our solar system. This phenomenon, now known as the solar wind, has been proven to exist repeatedly through direct observation. Parker’s work forms the basis for much of our understanding about how stars interact with the worlds that orbit them."</em> <a href="https://www.nasa.gov/feature/goddard/2017/nasa-renames-solar-probe-mission-to-honor-pioneering-physicist-eugene-parker">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS109_ConstructionCommencesOnTheWorl.jpg" alt="Construction commences on the world’s largest optical telescope" class="lefter"></p>

<h2><a href="http://thetechnews.com/2017/05/28/construction-commences-on-the-worlds-largest-optical-telescope/">Construction commences on the world’s largest optical telescope</a></h2>

<p><em>"After years of planning and financial anxieties, construction began on the European Extremely Large Telescope on Friday. Once completed, it will be known as the world’s largest optical telescope, which is five times larger than the top observing instruments we are using today. According to the backers, the size of the optical telescope comes with the potential of transforming our understanding of the universe, and with its main mirror, it will calculate some 39 meters (43 yards) across. The ELT is situated on a 3,000 meter-high Mountain in the middle of the Atacama desert and is scheduled to start operating in 2024."</em> <a href="http://thetechnews.com/2017/05/28/construction-commences-on-the-worlds-largest-optical-telescope/">[...]</a>
 </SPAN></DIV></p>

<h2>Outras Notícias</h2>

<ul>
<li><a href="http://spectrum.ieee.org/computing/hardware/google-plans-to-demonstrate-the-supremacy-of-quantum-computing">Google Plans to Demonstrate the Supremacy of Quantum Computing</a></li>
<li><a href="https://techcrunch.com/2017/05/27/googles-alphago-ai-is-retiring/">After beating the world’s elite Go players, Google’s AlphaGo AI is retiring</a></li>
<li><a href="http://esr.ibiblio.org/?p=7540">The Adventure begins again</a></li>
<li><a href="https://www.microchip.com/pressreleasepage/microchip-simplifies-the-design-of-low-power-lcd-applications">Microchip Simplifies the Design of Low-Power LCD Applications</a></li>
<li><a href="https://www.microchip.com/en/pressreleasepage/microchip-introduces-PIC32MZDA">Microchip Introduces the Industry’s First MCU with Integrated 2D GPU and Integrated DDR2 Memory for Groundbreaking Graphics Capabilities</a></li>
<li><a href="https://www.qualcomm.com/news/releases/2017/05/31/qualcomm-announces-flagship-companies-build-windows-10-pcs-powered">Qualcomm Announces Flagship Companies to Build Windows 10 PCs Powered by Snapdragon</a></li>
<li><a href="https://www.darpa.mil/news-events/2017-05-24">DARPA Picks Design for Next-Generation Spaceplane</a></li>
<li><a href="https://techcrunch.com/2017/05/30/yandexs-on-demand-taxi-service-debuts-its-self-driving-car-project/">Yandex’s on-demand taxi service debuts its self-driving car project</a></li>
<li><a href="https://www.nasa.gov/press-release/a-whole-new-jupiter-first-science-results-from-nasa-s-juno-mission">A Whole New Jupiter: First Science Results from NASA’s Juno Mission</a></li>
</ul>

<h1 id="Ciencia-e-Tecnologia">Ciência e Tecnologia</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_TheDeafBlindCanNowWatchTelevis.jpg" alt="The deaf-blind can now “watch” television without intermediaries" class="lefter"></p>

<h2><a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/Detalle/Comunicacion_C/1371232271985/1371215537949/The_deaf-blind_can_now_%E2%80%9Cwatch%E2%80%9D_television_without_intermediaries">The deaf-blind can now “watch” television without intermediaries</a></h2>

<p><em>"Today Universidad Carlos III de Madrid (UC3M), Telefónica and FASOCIDE (the Spanish acronym for the Federation of Deaf-Blind Persons Associations) presented the PervasiveSUB technology, ground-breaking software which allows deaf-blind persons to receive and enjoy television content without intermediaries at the same time as the people around them. PervasiveSUB compiles all the subtitles of television channels and sends them to a central server which forwards them to smartphones or tablets. From there, they are sent to the Braille line of the deaf-blind person thanks to the GoAll app, which integrates the software, is compatible with different Braille lines and makes it possible to control the speed of the subtitles that are captured directly from the TV broadcast in perfect synchronization. The presentation, which took place at the UC3M Madrid-Puerta de Toledo campus, was attended by Ángel García Crespo, a UC3M professor and  director of the project; Arancha Díaz-Lladó, the director of Telefónica’s Sustainable Innovation; and Francisco José Trigueros Molina, the president of FASOCIDE. Also in attendance was a group of deaf-blind persons who gave a demonstration of how this technology works. PervasiveSUB, financed by Telefónica, was developed by the research group at the UC3M Pedro Juan de LastanosaInstitute of Technological Development and Promotion of Innovation. García Crespo, who headed the group, stated that “one of the big problems deaf-blind persons face is the scant attention they receive, which is demonstrated by the fact that they weren’t recognized by the European Parliament until 2004.”"</em> <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/Detalle/Comunicacion_C/1371232271985/1371215537949/The_deaf-blind_can_now_%E2%80%9Cwatch%E2%80%9D_television_without_intermediaries">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_RitTeamCreatesHighSpeedInterne.jpg" alt="RIT team creates high-speed internet lane for emergency situations" class="lefter"></p>

<h2><a href="https://www.rit.edu/news/story.php?id=61939">RIT team creates high-speed internet lane for emergency situations</a></h2>

<p><em>"In a disaster, a delay can mean the difference between life and death. Emergency responders don’t have time to wait in traffic—even on the congested information superhighway. That’s why researchers at Rochester Institute of Technology are developing a faster and more reliable way to send and receive large amounts of data through the internet. By a creating a new network protocol, called Multi Node Label Routing protocol, researchers are essentially developing a new high-speed lane of online traffic, specifically for emergency information. The project, funded by a grant from the National Science Foundation and US Ignite, aims to improve the information flow between emergency responders at the scene of an incident and decision-makers at the office of emergency management."</em> <a href="https://www.rit.edu/news/story.php?id=61939">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_BacteriaWithMulticolorVision.jpg" alt="Bacteria with multicolor vision" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/bacteria-multicolor-vision-0526">Bacteria with multicolor vision</a></h2>

<p><em>"MIT researchers have engineered bacteria with “multicolor vision” — E. coli that recognize red, green, or blue (RGB) light and, in response to each color, express different genes that perform different biological functions. To showcase the technology, the researchers produced several colored images on culture plates — one of which spells out “MIT” — by using RGB lights to control the pigment produced by the bacteria. Outside of the lab, the technology could also prove useful for commercial, pharmaceutical, and other applications. The E. coli is programmed with a protein- and enzyme-based system, analogous to a computer chip, with several different modules to process the light input and produce a biological output. In computing terms, a “sensor array” first becomes activated in the presence of either red, green, or blue light, and a “circuit” processes the signal. Then, a “resource allocator” connects the processed information to “actuators” that implement the corresponding biological function. Think of the new E. coli as microbial marionettes, with colored light instead of puppet strings making the bacteria act in a certain way, says MIT professor of biological engineering Chris Voigt, co-author of a paper in Nature describing the technology. “Using different colors, we can control different genes that are being expressed,” he says. The paper’s co-authors are former postdocs Jesus Fernandez-Rodriguez, Felix Moser, and Miryoung Song."</em> <a href="http://news.mit.edu/2017/bacteria-multicolor-vision-0526">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_TowardMassProducibleQuantumCom.jpg" alt="Toward mass-producible quantum computers" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/toward-mass-producible-quantum-computers-0526">Toward mass-producible quantum computers</a></h2>

<p><em>"Quantum computers are experimental devices that offer large speedups on some computational problems. One promising approach to building them involves harnessing nanometer-scale atomic defects in diamond materials. But practical, diamond-based quantum computing devices will require the ability to position those defects at precise locations in complex diamond structures, where the defects can function as qubits, the basic units of information in quantum computing. In today’s of Nature Communications, a team of researchers from MIT, Harvard University, and Sandia National Laboratories reports a new technique for creating targeted defects, which is simpler and more precise than its predecessors. In experiments, the defects produced by the technique were, on average, within 50 nanometers of their ideal locations."</em> <a href="http://news.mit.edu/2017/toward-mass-producible-quantum-computers-0526">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_WaltzingRobotTeachesBeginnersH.jpg" alt="Waltzing robot teaches beginners how to dance like a pro" class="lefter"></p>

<h2><a href="https://www.newscientist.com/article/2132582-waltzing-robot-teaches-beginners-how-to-dance-like-a-pro/">Waltzing robot teaches beginners how to dance like a pro</a></h2>

<p><em>"Got no one to dance with? Not to worry – you might soon be gliding through the moves, thanks to a robotic instructor designed to teach humans how to dance. The robot’s designers had already created mechanical dance partners that follow a human’s lead, but the new machine gently guides novices through routines while adapting to their skill level. This is trickier, says Diego Felipe Paez Granados at Tohoku University in Sendai, Japan, who led the research, because the robot must keep students on course without becoming too forceful. The 1.8-metre-tall robot has wheels, but its upper body moves like that of a human dancer. A force sensor and two laser rangefinders track its student’s movements, which are compared against motion-capture data recorded from professional dancers to judge their performance. As they progress, the robot gradually reduces the force used to lead them so they become less reliant on its guidance. Its face displays real-time feedback to help pinpoint mistakes, as well as showing them their overall progress to provide encouragement. In tests with volunteers who had never waltzed before, five out of six improved, according to results to be presented at the International Conference on Robotics and Automation in Singapore later this month. With another group, the robot was not programmed to adapt to students’ progress and four out of six showed no improvement."</em> <a href="https://www.newscientist.com/article/2132582-waltzing-robot-teaches-beginners-how-to-dance-like-a-pro/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_UnveilingTheQuantumNecklace.jpg" alt="Unveiling the Quantum Necklace" class="lefter"></p>

<h2><a href="https://www.oist.jp/news-center/news/2017/5/24/unveiling-quantum-necklace">Unveiling the Quantum Necklace</a></h2>

<p><em>"The quantum world is both elegant and mysterious. It is a sphere of existence where the laws of physics experienced in everyday life are broken—particles can exist in two places at once, they can react to each other over vast distances, and they themselves seem confused over whether they are particles or waves. For those not involved in the field, this world may seem trifling, but recently, researchers from the Okinawa Institute of Science and Technology Graduate University (OIST) have theoretically described two quantum states that are extraordinary in both the physics that define them and their visual appeal: a complex quantum system that simulates classical physics and a spellbinding necklace-like state. Their study is published in the journal Physical Review A. The quest for these states begins with a doughnut, or rather, a doughnut-shaped container housing a rotating superfluid. This superfluid, which is a fluid that moves with no friction, is made of Bose-Einstein condensates (BECs) comprising particles with no charge that are cooled to near-zero degrees kelvin, a temperature so cold, that it does not exist in the universe outside of laboratories. At this temperature, particles begin to exhibit strange properties—they clump together, and eventually become indistinguishable from one another. In effect, they become a single entity and thus move as one. Since this whirling BEC superfluid is operating at a quantum scale, where tiny distances and low temperatures reign, the physical characteristics of its rotation are not those seen in the classical world. Consider a father who is swinging his daughter around in a circle by the arms. Classical physics mandates that the child’s legs will move faster than her hands around the circle, since her legs must travel further to make a complete turn."</em> <a href="https://www.oist.jp/news-center/news/2017/5/24/unveiling-quantum-necklace">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_FujitsuAndDaidoUniversityRepli.jpg" alt="Fujitsu and Daido University Replicate Molten Metal Pouring Behavior with Newly Developed Simulation Technology" class="lefter"></p>

<h2><a href="http://www.fujitsu.com/global/about/resources/news/press-releases/2017/0525-01.html">Fujitsu and Daido University Replicate Molten Metal Pouring Behavior with Newly Developed Simulation Technology</a></h2>

<p><em>"Fujitsu Limited and Daido University Professor Yasuhiro Maeda have jointly developed new simulation technology that can accurately replicate splash and wave behavior in the surface of molten metals when they are being poured. In the casting process, which is used in component manufacturing in a variety of fields, such as automobiles and IT devices, molten metal is poured into a mold to be cast into a shape. The way molten metal flows through the interior of a mold significantly effects casting quality, but because the interior is impossible to see, there has been a demand for a simulation that can clarify how molten metal flows within the mold. However, simulation of this flow has been difficult to achieve as the way molten metal flows can change greatly depending on the oxide film that forms when metal contacts the air. Now, based on a simulation technology known as the particle method(1), Fujitsu and Daido University have developed a new way to calculate flow variations with physical properties (viscosity) near the boundary between it and the air. This technology was then verified, comparing it to an actual experiment modeling a process where aluminum alloy melted at high temperatures is poured into casting equipment, which confirmed that the manner of splash suppression in line with the oxide film on the poured liquid metal could be accurately simulated. This technology creates a simulation to clarify how molten metal flows inside casting equipment and molds, a process which cannot be observed from the outside. This will make it possible to change metal pouring procedures so as to more quickly manufacture high quality products, which is expected to contribute to improving casting productivity. Details of this technology will be announced at the 169th JFS Meeting (Japan Foundry Engineering Society), which will be held on the Setagaya campus of Tokyo City University on May 26-29."</em> <a href="http://www.fujitsu.com/global/about/resources/news/press-releases/2017/0525-01.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_ManagingAnEcoFriendlyHouseWith.jpg" alt="Managing an eco-friendly house with Lego-like technology bricks" class="lefter"></p>

<h2><a href="https://actu.epfl.ch/news/managing-an-eco-friendly-house-with-lego-like-te-2/">Managing an eco-friendly house with Lego-like technology bricks</a></h2>

<p><em>"hanks to startup ThinkEE’s modular system – which consists of technology bricks linking various connected devices – data from a host of sensors can be collected regardless of the sensors’ protocols. It can also be used to control the devices in real time from a single interface. The system recently underwent pre-market testing in the NeighborHub eco-friendly house, which will be Switzerland’s entry in the international Solar Decathlon competition. As part of the Solar Decathlon challenge, EPFL-born startup ThinkEE has created a smart ecosystem to control the house – dubbed NeighborHub – that Switzerland will present at the competition in Denver this fall. The ecosystem includes sensors for measuring things like air temperature, humidity and power consumption, as well as a battery. The sensors will be located throughout the wooden house in order to minimize its energy usage. The system is designed to collect data from all the sensors and compile it onto a single platform, making it easier to monitor and manage the house’s devices. One of the ten criteria on which houses entered in the competition will be judged is smart energy use. The houses must also run entirely on solar power. “One challenge we faced was how to connect the various objects in the home, given that the environment was constantly changing – we had to adapt to the project schedule and deadlines,” said Jean-Charles Fosse, one of the founders of ThinkEE. “The information we obtain from the data will be available to the home’s occupants and visitors, but with different access rights.” The startup’s system will be unveiled to the public in the blueFACTORY innovation district in Fribourg, Switzerland, on 10 June, as part of NeighborHub’s open-door day."</em> <a href="https://actu.epfl.ch/news/managing-an-eco-friendly-house-with-lego-like-te-2/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_FujitsuDevelopsHighVoltageCath.jpg" alt="Fujitsu Develops High-Voltage Cathode Material for Lithium Iron Phosphate Rechargeable Batteries" class="lefter"></p>

<h2><a href="http://www.fujitsu.com/global/about/resources/news/press-releases/2017/0529-01.html">Fujitsu Develops High-Voltage Cathode Material for Lithium Iron Phosphate Rechargeable Batteries</a></h2>

<p><em>"Fujitsu Laboratories Ltd. today announced that it has successfully developed a cathode material for lithium iron phosphate rechargeable batteries. This new material offers high voltage that could only be achieved by cobalt-based materials in the past. Currently, the rare metal cobalt is a component of cathodes in high capacity and high-voltage lithium rechargeable batteries for electric vehicles (EVs) and home storage batteries. As these devices become more popular, there are concerns regarding future shortages of cobalt used in rechargeable lithium-ion batteries. Significant cost increases are also expected, generating interest in abundant and cheap iron to replace cobalt as the constituent element in rechargeable batteries. However, iron could not offer voltage comparable to that of cobalt-based materials. Now Fujitsu Laboratories has discovered a new factor that can improve the voltage of iron-based materials. Using a proprietary materials design technology as well as a technology that precisely controls the composition of raw materials and the formation process of materials, Fujitsu Laboratories has successfully synthesized lithium iron pyrophosphate (Li5.33Fe5.33(P2O7)4). This phosphate-based material has a voltage of 3.8 V, comparable to that of existing cobalt-based materials. In the future, Fujitsu Laboratories will seek to improve the performance of cathodes using this newly developed iron-based material. By advancing the design of new crystal structures that can maintain a high voltage state for longer periods, Fujitsu Laboratories aims to develop cathode materials that offer high energy density comparable to cobalt-based materials. In this way, Fujitsu Laboratories will contribute to lowering the cost of lithium rechargeable batteries and the devices that use them. Details are being announced at the 231st ECS Meeting, an international conference on electrochemistry, currently underway in New Orleans, U.S., from May 28 to June 1."</em> <a href="http://www.fujitsu.com/global/about/resources/news/press-releases/2017/0529-01.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_NanomaterialsWithPotentialForE.jpg" alt="Nanomaterials with potential for environmentally friendly hydrogen production" class="lefter"></p>

<h2><a href="https://www.uu.se/en/research/news/article/?id=8846&amp;typ=artikel">Nanomaterials with potential for environmentally friendly hydrogen production</a></h2>

<p><em>"In an article in the journal Energy and Environmental Science, researchers from Uppsala University, Sweden, present a type of low-cost and environmental-friendly organic polymer nano-material as photocatalysts for hydrogen generation, and propose the working mechanism of the photocatalytic reactive site. Development of photocatalysts for light driven hydrogen generation from water is an ideal way to convert and store solar energy. Due to limited light absorption, high-cost and potential metal-pollutant from inorganic catalysts, scientists have started looking for organic alternative. In this work, the Uppsala researchers have studied organic polymers as photocatalysts (light-driven catalysts). The bottleneck of all existing organic photocatalyts is that they are hydrophobic (water insoluble), making it difficult for protons to penetrate into the pores of the materials and to interact with reactive sites. Consequently, the performance of photocatalysis based on those materials is still behind that of the traditional metal-based inorganic photocatalysts. Scientists have to add a lot of organic solvent in the reactor in order to make a good dispensability of organic polymeric photocatalyst. Using a so-called Nano-scale precipitation method to prepare the organic polymeric photocatalyst into small nano-scaled particles (Pdots) can make the organic photocatalyst nicely dispersed in aqueous solution. “With help from hydrophilic co-polymer, we are able to provide proton channels inside the Pdot photocatalyst to mimic the naturural photosynthesis system. This can dramatically improve the performance of hydrogen generation” says Haining Tian, Docent from Department of Chemistry - Ångström Laboratory. His research group published the proof-of-concept work last year (in Angew. Chem. Int. Ed., 2016, 55(40), 12306). In order to understand more about the system and further improve it, Haining Tian together with his research colleague C. Moyses Araujo from Department of Physics-Ångström Laboratory have jointly led the work to dig out the reactive sites in the Pdot photocatalyts and photocatalytic working mechanism. By tuning the structure of polymers and evaluating different photocatalytic mechanisms, the researchers could approximately find the reactive sites located at the electron acceptor units and concluded that the heteroatoms should play a crucial role on photocatalytsis. "It is difficult to experimentally get accurate information on which heteroatom, either N or S, is the reactive site in the electron acceptor unit” says Haining Tian. With help from a computational study based on first-principles theory, the scientists eventually targeted the real reactive site in Pdots photocatalysts – the N atoms – and also concluded that the unique Pdots structure is beneficial for proton reduction reaction. “Hydrogen bond formed between two polymers in Pdot photocatalysts significantly lowers the energy barrier of proton reduction reaction. The Pdots is indeed a type of ideal photocatalysts” says C. Moyses Araujo. On the basis of this work, the scientists are now aiming at more efficient and stable Pdots catalyst by reasonably tuning the polymer structure for light driven hydrogen generation."</em> <a href="https://www.uu.se/en/research/news/article/?id=8846&amp;typ=artikel">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_AGlovePoweredBySoftRoboticsToI.jpg" alt="A glove powered by soft robotics to interact with virtual reality environments" class="lefter"></p>

<h2><a href="http://jacobsschool.ucsd.edu/news/news_releases/release.sfe?id=2225">A glove powered by soft robotics to interact with virtual reality environments</a></h2>

<p><em>"Engineers at UC San Diego are using soft robotics technology to make light, flexible gloves that allow users to feel tactile feedback when they interact with virtual reality environments.  The researchers used the gloves to realistically simulate the tactile feeling of playing a virtual piano keyboard. Engineers recently presented their research, which is still at the prototype stage, at the Electronic Imaging, Engineering Reality for Virtual Reality conference in Burlingame, Calif. Currently, VR user interfaces consist of remote-like devices that vibrate when a user touches a virtual surface or object. “They’re not realistic,” said Jurgen Schulze, a researcher at the Qualcomm Institute at UC San Diego and one of the paper’s senior authors. “You can’t touch anything, or feel resistance when you’re pushing a button. By contrast, we are trying to make the user feel like they’re in the actual environment from a tactile point of view.” Other research teams and industry have worked on gloves as VR interfaces. But these are bulky and made from heavy materials, such as metal. The glove the engineers developed has a soft exoskeleton equipped with soft robotic muscles that make it much lighter and easier to use."</em> <a href="http://jacobsschool.ucsd.edu/news/news_releases/release.sfe?id=2225">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_NewMethodOfCharacterizingGraph.jpg" alt="New Method of Characterizing Graphene" class="lefter"></p>

<h2><a href="https://www.unibas.ch/en/News-Events/News/Uni-Research/New-Method-of-Characterizing-Graphene.html">New Method of Characterizing Graphene</a></h2>

<p><em>"Scientists have developed a new method of characterizing graphene’s properties without applying disruptive electrical contacts, allowing them to investigate both the resistance and quantum capacitance of graphene and other two-dimensional materials. Researchers from the Swiss Nanoscience Institute and the University of Basel’s Department of Physics reported their findings in the journal Physical Review Applied. Graphene consists of a single layer of carbon atoms. It is transparent, harder than diamond and stronger than steel, yet flexible, and a significantly better conductor of electricity than copper. Since graphene was first isolated in 2004, scientists across the world have been researching its properties and the possible applications for the ultrathin material. Other two-dimensional materials with similarly promising fields of application also exist; however, little research has been carried out into their electronic structures."</em> <a href="https://www.unibas.ch/en/News-Events/News/Uni-Research/New-Method-of-Characterizing-Graphene.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_ANewSpinOnElectronics.jpg" alt="A New Spin on Electronics" class="lefter"></p>

<h2><a href="https://unews.utah.edu/a-new-spin-on-electronics/">A New Spin on Electronics</a></h2>

<p><em>"A University of Utah-led team has discovered that a class of “miracle materials” called organic-inorganic hybrid perovskites could be a game changer for future spintronic devices. Spintronics uses the direction of the electron spin — either up or down — to carry information in ones and zeros. A spintronic device can process exponentially more data than traditional electronics that use the ebb and flow of electrical current to generate digital instructions. But physicists have struggled to make spintronic devices a reality. The new study, published online today in Nature Physics, is the first to show that organic-inorganic hybrid perovskites are a promising material class for spintronics. The researchers discovered that the perovskites possess two contradictory properties necessary to make spintronic devices work — the electrons’ spin can be easily controlled, and can also maintain the spin direction long enough to transport information, a property known as spin lifetime."</em> <a href="https://unews.utah.edu/a-new-spin-on-electronics/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_HowAiCanKeepAcceleratingAfterM.jpg" alt="How AI Can Keep Accelerating After Moore’s Law" class="lefter"></p>

<h2><a href="https://www.technologyreview.com/s/607917/how-ai-can-keep-accelerating-after-moores-law/">How AI Can Keep Accelerating After Moore’s Law</a></h2>

<p><em>"Google CEO Sundar Pichai was obviously excited when he spoke to developers about a blockbuster result from his machine-learning lab earlier this month. Researchers had figured out how to automate some of the work of crafting machine-learning software, something that could make it much easier to deploy the technology in new situations and industries. But the project had already gained a reputation among AI researchers for another reason: the way it illustrated the vast computing resources needed to compete at the cutting edge of machine learning. A paper from Google’s researchers says they simultaneously used as many as 800 of the powerful and expensive graphics processors that have been crucial to the recent uptick in the power of machine learning (see “10 Breakthrough Technologies 2013: Deep Learning”). They told MIT Technology Review that the project had tied up hundreds of the chips for two weeks solid—making the technique too resource-intensive to be more than a research project even at Google. A coder without ready access to a giant collection of GPUs would need deep pockets to replicate the experiment. Renting 800 GPUs from Amazon’s cloud computing service for just a week would cost around $120,000 at the listed prices. Feeding data into deep learning software to train it for a particular task is much more resource intensive than running the system afterwards, but that still takes significant oomph. “Computing power is a bottleneck right now for machine learning,” says Reza Zadeh, an adjunct professor at Stanford University and founder and CEO of Matroid, a startup that helps companies use software to identify objects like cars and people in security footage and other video. The sudden thirst for new power to drive AI comes at a time when the computing industry is adjusting to the loss of two things it has relied on for 50 years to keep chips getting more powerful. One is Moore’s Law, which forecast that the number of transistors that could be fitted into a given area of a chip would double every two years. The other is a phenomenon called Dennard scaling, which describes how the amount of power that transistors use scales down as they shrink. Neither holds true today. Intel has slowed the pace at which it introduces generations of new chips with smaller, denser transistors (see “Moore’s Law Is Dead. Now What?”). And the usual efficiency gains that transistors showed as they got smaller came to a halt in the mid-2000s, making power consumption a major headache."</em> <a href="https://www.technologyreview.com/s/607917/how-ai-can-keep-accelerating-after-moores-law/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_FightingForgeryWithPaperFinger.jpg" alt="Fighting forgery with paper fingerprints" class="lefter"></p>

<h2><a href="http://www.ncl.ac.uk/press/news/2017/05/paperfingerprints/">Fighting forgery with paper fingerprints</a></h2>

<p><em>"Scientists from Newcastle University, UK, have found an inexpensive and easy way to validate the authenticity of ANY paper document just by taking a picture of it on a standard camera. Analysing the translucent patterns revealed when a light shines through paper, the researchers have been able to identify a unique ‘texture’ fingerprint for every single sheet of paper. Capturing the random interweaving of the wooden particles, they show that a unique fingerprint code can be captured and verified with 100% accuracy using nothing more than an off-the-shelf camera. They further show that the fingerprinting process remains highly reliable even if the paper is treated with rough handling such as crumpling, soaking, scribbling and heating. Publishing their findings today in the academic journal ACM Transactions on Information and System Security, the team – Ehsan Toreini, Dr Feng Hao and Dr Siamak Shahandashti - say the findings offer a new way to verify physical documents and reduce the risk of forgery."</em> <a href="http://www.ncl.ac.uk/press/news/2017/05/paperfingerprints/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_ANetworkOfCrystalsForLongDista.jpg" alt="A network of crystals for long-distance quantum communication" class="lefter"></p>

<h2><a href="http://www.unige.ch/sciences/Actualites/2017/News-290517-1_en.html">A network of crystals for long-distance quantum communication</a></h2>

<p><em>"Quantum physic can guarantee that a message has not be intercepted before reaching its destination. Thanks to the laws of quantum physic, a particle of light – a photon – can be in two distinct states simultaneously, comparable to a coin thrown in the air, which is virtually both head and tail before reaching the ground. Like when the coin is grabbed, this superposition of states is destroyed as soon as it is read. This peculiar feature allow one to detect an evil eavesdropper when sending a message. However, this technique is so far limited to short distances. In order to extend the reach of these quantum communications, researchers from the University of Geneva (UNIGE), Switzerland, have demonstrated a novel protocol based on a crystal than can emit quantum light as well as store it for arbitrary long times. This work, to appear in Physical Review Letters, paves the way for a future quantum repeater. Quantum superposition is one of the fascinating features of quantum physic. “In order to test the security of communication link, we can use particles of light, photons, onto which we encode quantum bits (analogous to the bit used in computing) ”, explains Cyril Laplane, a researcher in the Group of Applied Physics at UNIGE. He continues: “We then take advantage of the properties of quantum superposition, allowing the photon to be simultaneously in two states, to test the security of a communication link”. Indeed if the photon is intercepted and read, the superposition of states is lost, only one of the two states remains. Hence, the recipient can know if the message has been intercepted."</em> <a href="http://www.unige.ch/sciences/Actualites/2017/News-290517-1_en.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_InternetOfThingsLetTheAvatarsT.jpg" alt="Internet of things: Let the avatars talk to each other" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/internet-of-things-let-avatars-talk-to-each-other-sanjay-sarma-0530">Internet of things: Let the avatars talk to each other</a></h2>

<p><em>"On the 25th anniversary of the universal barcode in 1999, the barcode community gathered around Sanjay Sarma and his colleagues and said, “Let’s do this.” “Our idea,” says Sarma, vice president for open learning and the Fred Fort Flowers (1941) and Daniel Fort Flowers (1941) Professor of Mechanical Engineering at MIT, “was to track everything in the supply chain.” Some companies knew they had too much inventory. Others didn’t know where their inventory was. Consumers couldn’t find the right sized shirt while that shirt was sitting in the back room. Food was going bad and shelves went un-stocked. Things got lost in the supply chain. So, Sarma, along with research scientist David Brock of MIT and Kevin Ashton, a visiting researcher from Proctor and Gamble, came up with a low-cost radio frequency identification (RFID) tag. “At the time, it was a crazy idea,” says Sarma. “But it stuck.” RFID tags, which had been around for several decades, were clunky and expensive — partly because of the amount of data placed on the tags. “We used to say, ‘Someday the internet will be everywhere’ — this was late 90s — and we didn’t have the word 'cloud' yet. So, we used to say, ‘Someday, you can write the data in the sky,’” says Sarma, who developed new standards for RFID, new manufacturing processes, and innovative ways to use them in the supply chain. The supply chain industry adopted the protocol, and standards-making efforts shifted. Auto ID Labs laid the groundwork for the standardization of RFID technology. It took sensing of identity — the job of RFID and barcodes — and made it universal. Auto ID Labs, where Sarma remains active today, emerged from the MIT Auto ID Center. “In many ways that effort also laid the groundwork for what is now called the internet of things,” Sarma says."</em> <a href="http://news.mit.edu/2017/internet-of-things-let-avatars-talk-to-each-other-sanjay-sarma-0530">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT109_ExploringElusiveHighEnergyPart.jpg" alt="Exploring elusive high-energy particles in an unusual metal" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/weyl-fermions-high-energy-particles-infrared-detectors-0530">Exploring elusive high-energy particles in an unusual metal</a></h2>

<p><em>"Mid-infrared wavelengths of light are invisible to the eye but can be useful for a number of technologies, including night vision, thermal sensing, and environmental monitoring. Now, a new phenomenon in an unconventional metal, found by physicists at MIT and elsewhere, could provide a new way of making highly sensitive detectors for these elusive wavelengths. The phenomenon is closely related to a particle that has been predicted by high-energy physicists but never observed. Physicists group all the fundamental particles in nature into two categories, fermions and bosons, according to a property called spin. The fermions, in turn, have three types: Dirac, Majorana, and Weyl. Dirac fermions include the electrons in regular metals such as copper or gold. The other two are unconventional particles that can give rise to strange and fundamentally new physics, which potentially can be used to build more efficient circuits and other devices. The Weyl fermion was first theorized almost a century ago by German physicist Hermann Weyl. Even though its existence is posited as part of the equations that form the widely accepted Standard Model of subatomic physics, Weyl fermions have never actually been observed experimentally. The theory predicts that they should move at the speed of light, and, at the same time, spin about the direction of motion. They come in two varieties depending on whether their rotation around the direction of motion is clockwise or counterclockwise. This property is known as the handedness, or chirality, of Weyl fermions. Even though Weyl fermions have never been observed directly, researchers have recently observed a phenomenon that mimics essential aspects of their theorized properties, in a class of unconventional metals known as Weyl semimetals. One remaining challenge was to experimentally measure the chirality of these Weyl fermions, which evaded detection from most standard experimental techniques. In a paper published in the journal Nature Physics, an MIT team was able to measure Weyl fermion chirality by using circularly polarized light. This work was done by MIT postdocs Qiong Ma and Su-Yang Xu; physics professors Nuh Gedik, Pablo Jarillo-Herrero, and Patrick Lee; and eight other researchers at MIT and other universities in the U.S., China, and Singapore."</em> <a href="http://news.mit.edu/2017/weyl-fermions-high-energy-particles-infrared-detectors-0530">[...]</a>
 </SPAN></DIV></p>

<h1 id="Documentacao">Documentação</h1>

<p>A documentação é parte essencial do processo de aprendizagem e a Internet além de artigos interessantes de explorar também tem alguma documentação em formato PDF interessante de ler. Todos os <em>links</em> aqui apresentados são para conteúdo disponibilizado livremente pelo editor do livro.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB109_MadeWithCreativeCommons.jpg" alt="Made With Creative Commons" class="lefter"></p>

<h2><a href="https://creativecommons.org/wp-content/uploads/2017/04/made-with-cc.pdf">Made With Creative Commons</a></h2>

<p><em>"A guide to sharing your knowledge and creativity with the world, and sustaining your operation while you do."</em> <a href="https://creativecommons.org/wp-content/uploads/2017/04/made-with-cc.pdf">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB109_IntroductionToAutonomousRobots.jpg" alt="Introduction to Autonomous Robots, v1.7, October 6, 2016" class="lefter"></p>

<h2><a href="https://github.com/correll/Introduction-to-Autonomous-Robots/releases/download/v1.9/book.pdf">Introduction to Autonomous Robots, v1.7, October 6, 2016</a></h2>

<p><em>"This book provides an algorithmic perspective to autonomous robotics to students with a sophomore-level of linear algebra and probability theory. Robotics is an emerging field at the intersection of mechanical and electrical engineering with computer science. With computers becoming more powerful, making robots smart is getting more and more into the focus of attention and robotics research most challenging frontier. While there are a large number of textbooks on the mechanics and dynamics of robots that address sophomore-level undergraduates available, books that provide a broad algorithmic perspective are mostly limited to the graduate level. This book has therefore been developed not to create "yet another textbook, but better than the others", but to allow me to teach robotics to the 3rd and 4th-year undergraduates at the Department of Computer Science at the University of Colorado. Although falling under the umbrella of "Artificial Intelligence", standard AI techniques are not sufficient to tackle problems that involve uncertainty, such as a robot’s interaction in the real world. This book uses simple trigonometry to develop the kinematic equations of simple manipulators and mobile robots, then introduces path planning, sensing, and hence uncertainty. The robot localization problem is introduced by formally introducing error propagation, which leads to Markov localization, the Particle filter and finally the Extended Kalman Filter, and Simultaneous Localization and Mapping."</em> <a href="https://github.com/correll/Introduction-to-Autonomous-Robots/releases/download/v1.9/book.pdf">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB109_ProgrammingFundamentalsAModula.jpg" alt="Programming Fundamentals: A Modular Structured Approach Using C++" class="lefter"></p>

<h2><a href="https://tfetimes.com/wp-content/uploads/2015/06/Programming.pdf">Programming Fundamentals: A Modular Structured Approach Using C++</a></h2>

<p><em>"The learning modules of this textbook/collection were, for the most part, written without consideration of a specific programming language. In many cases the C++ language is discussed as part of the explanation of the concept. Often the examples used for C++ are exactly the same for the Java programming language. However, some modules were written specifically for the C++ programming language. This could not be avoided as the C++ language is used in conjunction with this textbook/collection by the author in teaching college courses. This open source compiler/IDE (Integrated Development Environment) was used to develop the demonstration source code files provided within the modules of this textbook/collection. The compiler/IDE is presented to the student in the second module of Chapter 1, with instructions for downloading, installing and using the compiler/IDE. A more complete explanation of the IDE along with demonstration source code listings with errors is presented in first module of Chapter 5. All of the source code files provided in this textbook/collection contain only ANSI standard C++ code and should work on any standard C++ compiler like Microsoft Visual Studio (which includes C++), Microsoft Visual C++ Express or Borland C++ Builder."</em> <a href="https://tfetimes.com/wp-content/uploads/2015/06/Programming.pdf">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB109_SignalComputingDigitalSignalsI.jpg" alt="Signal Computing: Digital Signals in the Software Domain" class="lefter"></p>

<h2><a href="http://faculty.washington.edu/stiber/pubs/Signal-Computing/Signal%20Computing.pdf">Signal Computing: Digital Signals in the Software Domain</a></h2>

<p><em>"Digital signals place great demands on processing power, network bandwidth, storage capacity, I/O speed, and software design. As a result, signal computing is a great laboratory for exercising the full range of knowledge of computer science. In this book, you will learn how digital signals are captured, represented, processed, communicated, and stored in computers. The specific topics we will cover include: physical properties of the source information (such as sound or images), devices for information capture (microphones, cameras), digitization, compression, digital signal representation (JPEG, MPEG), digital signal processing (DSP), and network communication. By the end of this book, you should understand the problems and solutions facing signal computing systems development in the areas of user interfaces, information retrieval, data structures and algorithms, and communications. "</em> <a href="http://faculty.washington.edu/stiber/pubs/Signal-Computing/Signal%20Computing.pdf">[...]</a>
 </SPAN></DIV></p>

<h1 id="Projetos-Maker">Projetos Maker</h1>

<p>Diversos Projetos interessantes.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_HowToBuildAnArduinoPirMotionAc.jpg" alt="How to Build an Arduino PIR Motion-Activated Camera System" class="lefter"></p>

<h2><a href="https://diyhacking.com/build-arduino-pir-motion-activated-camera-system/">How to Build an Arduino PIR Motion-Activated Camera System</a></h2>

<p><em>"It may be too early for Christmas-themed projects, but I’m sure you can find a use for this PIR motion-activated camera system anytime of the year! "</em> <a href="https://diyhacking.com/build-arduino-pir-motion-activated-camera-system/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_LedMatrixArduino.jpg" alt="Led Matrix Arduino" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Led-Matrix-Arduino/">Led Matrix Arduino</a></h2>

<p><em>"In this tutorial i will show you how to interface 8x8 Led Matrix with Arduino UNO"</em> <a href="http://www.instructables.com/id/Led-Matrix-Arduino/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_BeyondInfinityTableTheInteract.jpg" alt="Beyond Infinity Table - the Interactive Coffee Table for the Modern Age" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Beyond-Infinity-Table-the-Interactive-Coffee-Table/">Beyond Infinity Table - the Interactive Coffee Table for the Modern Age</a></h2>

<p><em>"Beyond Infinity Table is a beautiful, interactive coffee table that will leave you amazed, bewildered, and maybe just a little dizzy! The sides are stained, clear coated, and engraved for that extra pizazz. It features over 960 LEDs, each individually controlled with 24bit color. These LEDs make up a total of FORTY individual infinity mirrors, culminating into one awesome coffee table. It doesnt stop there! This table features a total of 4 hidden USB ports, each capable of doing a full 2A charging. Thats 4 Ipads at once without a sweat! For those that have broken from cables, it also features an inductive charging pad clearly marked with a laser engraving. When it comes to having a bit more power, there is a 2 port AC outlet, for those that would like to plug in a laptop or 2 for charging. The final amazing feature is a hidden touchscreen LCD that allows for full control over table functions. Anywhere from setting simple patterns to playing a game of Pac-man! Programmed with Arduino and run on a Teensy 3.1, adding features isn't impossible, and highly encouraged! Make a table and let me see what you got!"</em> <a href="http://www.instructables.com/id/Beyond-Infinity-Table-the-Interactive-Coffee-Table/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_AndroidThingsAICandyDispenser.jpg" alt="Android Things A.I. Candy Dispenser" class="lefter"></p>

<h2><a href="https://www.hackster.io/alvarowolfx/android-things-a-i-candy-dispenser-a47e74">Android Things A.I. Candy Dispenser</a></h2>

<p><em>"A candy dispenser running Android Things that exchanges photos for candies. It uses computer vision to classify the image. The Android Things A.I. Candy Dispenser: here's a demonstration of how to create a “smart” candy machine. The device is a game that asks the user for a specific thing like a bird, dog or cat, and the user should show a photo of that thing in the predefined time to win candies. This project uses a button to interact with the user, obtains images via a camera peripheral and a modified electric candy dispenser being controlled by a GPIO with a transistor. When the user takes a picture, it processes the image data using Google’s Cloud Vision API, which returns annotations and metadata of the image. This info is used by the device to see if it matches what was requested. When we have a match, the motor of the candy machine is activated and give the user the prize. All users interface is presented in a Serial i2C 20x4 Display. The device (Raspberry Pi 3B) is running Android Things dev preview. It has a camera connected to take pictures, a 20x4 Serial i2c Display to show the "little" game state, a arcade button to interact with the game and a simple NPN transistor to activate the candy machine DC motor."</em> <a href="https://www.hackster.io/alvarowolfx/android-things-a-i-candy-dispenser-a47e74">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_MakeYourMidiAccordion.jpg" alt="Make Your MIDI Accordion" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Make-Your-MIDI-Accordion/">Make Your MIDI Accordion</a></h2>

<p><em>"Playing myself concertina i was searching about a solution to fit my needs: - i wanted to play with a headset for my neighboorhood; - i wanted to try computer assister music; There was no good solution on the market so i have buy two arduinos and that was the begining of this adventure."</em> <a href="http://www.instructables.com/id/Make-Your-MIDI-Accordion/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_DiyWifiRcCarWithEsp8266AndArdu.jpg" alt="DIY WIFI RC Car With ESP8266 and Arduino IDE" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-WIFI-RC-Car-With-ESP8266-and-Arduino-IDE/">DIY WIFI RC Car With ESP8266 and Arduino IDE</a></h2>

<p><em>"This project is an example of remotely controlled car via WIFI. The circuit is based on ESP8266, and the software is written in the Arduino IDE. As an engine driver, I used the L298N. The vehicle's speed is controlled by PWM in the range of 0 to 1023. Digital control offers more possibilities than the usual controller. I also added a RGB LED as light and buzzer as a horn."</em> <a href="http://www.instructables.com/id/DIY-WIFI-RC-Car-With-ESP8266-and-Arduino-IDE/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_IotWeatherBoxWithCustomAlarmsT.jpg" alt="IoT: Weather Box (with Custom Alarms & Timers)" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/IoT-Weather-Box-with-Custom-Alarms-Timers/">IoT: Weather Box (with Custom Alarms &amp; Timers)</a></h2>

<p><em>"I was, some time ago, quite interested in IoT projects and so I thought it would be fun to make something associated with the Internet. I recently purchased the micro-controller called the nodeMCU and it's superb. After having decided to build a weather station that would display all the weather information with just a push of a button, I delved into the first step of making it. But, there is something that remains to be added. That is, it's not just confined to doing simply that much(displaying the weather information of my city), but also it is able to keep your alarms and timers for you. Doesn't that sound cool?! That means it's like an Alarm clock with custom timers combined with a Weather station. It also does a fair job of displaying the time and date. It works with the nodeMCU and quite a few other components included in the build. Still, it could be exposed suitably for more improvement like the addition of more features. I have also used a DHT11 temperature sensor for measuring the room's temperature in which this weather box of ours may be in, besides fetching information from the internet about the weather. So that you can have a good comparison between the both. I also decided to use an MQTT server for uploading this information on the web so that i can, from anywhere, have a look at the local weather information sensed by this prototype. I guess that will suffice the introduction part."</em> <a href="http://www.instructables.com/id/IoT-Weather-Box-with-Custom-Alarms-Timers/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_LongEarthStepperNightLight.jpg" alt=""Long Earth" Stepper Night Light" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Long-Earth-Stepper-Night-Light/">"Long Earth" Stepper Night Light</a></h2>

<p><em>"Ever since I read Terry Pratchett and Stephen Baxter's The Long Earth, I wanted to build a stepper box. It took me a while to figure out the details. As it turns out, Willis Linsay's original stepper diagram (source) is less of a straightforward build than people want you to believe. In this Instructable, I'll lay out the details of how you can build your own stepper. Once you reach the Earth of your choosing and decide to settle, you can still use it as a cool night light. That is, after you built the infrastructure for an electric power grid etc. Hey, no one ever said it would be easy!"</em> <a href="http://www.instructables.com/id/Long-Earth-Stepper-Night-Light/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_4WireLcdControlWithBlAndContra.jpg" alt="4 Wire LCD control with BL and contrast using Shift Register" class="lefter"></p>

<h2><a href="https://www.hackster.io/mrDeltaKilo/4-wire-lcd-control-with-bl-and-contrast-using-shift-register-ac4e89">4 Wire LCD control with BL and contrast using Shift Register</a></h2>

<p><em>"Looking for the ability to control an LCD from Arduino without having to use 12 pins, I designed a breakout board featuring a 74HC595 shift register and an NPN transistor with the ability to control the display (including backlight control) with either 4 wires, allowing control of contrast through code, or 3 wires, allowing the addition of a potentiometer for static contrast. If controlling contrast via code, the included modified LiquidCrystal library adds fade_in(), fade_out(), and highlight() functions. In addition lcd.backlight() and lcd.no_backlight() will control whether the backlight is active or not. The project was recreated in Fritzing showing a breadboard diagram, schematic, and recreation of EAGLE PCB design used in my case."</em> <a href="https://www.hackster.io/mrDeltaKilo/4-wire-lcd-control-with-bl-and-contrast-using-shift-register-ac4e89">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_CheapestSmartHomeFor38.jpg" alt="Cheapest Smart Home for $38" class="lefter"></p>

<h2><a href="https://www.hackster.io/naran-inc/cheapest-smart-home-for-38-98718f">Cheapest Smart Home for $38</a></h2>

<p><em>"Use Raspberry Pi Zero W to make the cheapest and easiest yet very useful smart home automation for $38 only and no skills needed! Have you heard of the new Raspberry Pi Zero? Only priced at $5 (or $10 for the W version), it revolutionizes smart home by making it cheaper than ever and accessible to any budget. Another part of making smart home more accessible is the connection and automation part. That’s why we developed Prota OS, the Raspberry Pi based OS, that helps you connect your devices, sensors and services in a single smart hub and write automation workflows in natural language."</em> <a href="https://www.hackster.io/naran-inc/cheapest-smart-home-for-38-98718f">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_SmartSocketWithTemperatureHumi.jpg" alt="Smart Socket With Temperature Humidity Sensor, Laptop or Smartphone Battery Auto Cut in Cut Off Switch" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Smart-Socket-With-Temperature-Humidity-Sensor-Lapt/">Smart Socket With Temperature Humidity Sensor, Laptop or Smartphone Battery Auto Cut in Cut Off Switch</a></h2>

<p><em>"This is a Smart Plug-point with Temperature Humidity Sensor DHT 11 and a Emergency LED Light. As usual this socket can be turned on and off through WiFi of any smartphone. This can also be connected to Internet and avail feature as Internet of Thing (IOT)."</em> <a href="http://www.instructables.com/id/Smart-Socket-With-Temperature-Humidity-Sensor-Lapt/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_CheerlightsInternetConnectedHa.jpg" alt="CheerLights Internet-Connected Hat" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/CheerLights-Internet-Connected-Hat/">CheerLights Internet-Connected Hat</a></h2>

<p><em>"This festive e-Textile hat combines the magic of CheerLights with a Particle Photon, a microcontroller that can connect to the cloud to help you with all of your Internet of Things projects! The result of my tinkering was an internet-enabled wearable that changes colors in sync with lights all over the world, in response to Twitter messages mentioning @CheerLights and the name of a desired color. According to CheerLights' Twitter bio, "CheerLights is an #internetofthings project by @scharler to synchronize lights to the same color at the same time all around the world." If you haven't tried it, prepare to be dazzled and amused by this charming global phenomenon!"</em> <a href="http://www.instructables.com/id/CheerLights-Internet-Connected-Hat/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_WirelessAttendanceSystemUsingW.jpg" alt="Wireless Attendance System Using Wi-Fi (ESP8266)with MySQL" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Wireless-Attendance-System-Using-Wi-Fi-ESP8266with/">Wireless Attendance System Using Wi-Fi (ESP8266)with MySQL</a></h2>

<p><em>"Here We are going to connect Node MCU ESP8266 and RFID- RC522 with MYSQL Database. So for that first we should connect our Node MCU ESP8266 Board with RFID Module. By using the RFID Module we are going to scan our RFID card and tag which are allow or not. And by using our ESP8266 we are going to send that data to our MYSQL Database which is connect through a php page. In this case we are using php script as well. From arduino code we are making a get request to our php page. Make sure that php page you have to put inside /var/www/html."</em> <a href="http://www.instructables.com/id/Wireless-Attendance-System-Using-Wi-Fi-ESP8266with/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_SoundActivatedLedLightWithTime.jpg" alt="Sound Activated LED Light With Timer" class="lefter"></p>

<h2><a href="http://www.electronics-lab.com/project/sound-activated-led-light-timer/">Sound Activated LED Light With Timer</a></h2>

<p><em>"Clap to light switch with timer project is very useful project for power saving applications. The project switches on the LED light for 45 to 60 seconds when receives two clap sound. This project can be used in store room, toilets, dark area where switch is not visible, night lamp, places where light on off switch is not accessible easily. Single transistor used as microphone preamplifier, diode converts AC signal in to DC , and PIC micro-controller take care of LED On/OFF Time, LED  time depends on two jumpers J1, J2 which provides four options s 45, 50, 55, 60 seconds. MJE3055 transistor used in output to drive LED, one series resistor R10 helps to control the current going through LED, R10 can be alter as per LED Voltage and current. 3V to 12V LED with maximum current 500mA can be used. Use higher current Darlington transistor like TIP147 for higher current Load. Onboard potentiometer trimmer for sound sensitivity adjust. D1 power LED."</em> <a href="http://www.electronics-lab.com/project/sound-activated-led-light-timer/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_ArduinoToControlHomeApplianceU.jpg" alt="Arduino to Control Home Appliance Using Web App" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-to-Control-Home-Appliance-Using-Web-App/">Arduino to Control Home Appliance Using Web App</a></h2>

<p><em>"In this project we are going to light the bulb from remote location using web services. In this we are going to use one Arduino interfacing with 12 bulb using 3 relay module with low level trigger. We can trigger the relay from anywhere in the world using a website in which we’ll have GUI Button. In each trigger of relay the correspondence Bulb or group of bulb will glow."</em> <a href="http://www.instructables.com/id/Arduino-to-Control-Home-Appliance-Using-Web-App/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_Crabot.jpg" alt="Crabot" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Crabot/">Crabot</a></h2>

<p><em>"The Crabot is an engineering project that is meant to introduce interested people to electrical engineering, Arduino coding, and robotics. It is also meant for further experimentation, improvement, and fun!"</em> <a href="http://www.instructables.com/id/Crabot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_WiFinderTheOpenWiFiFindingLigh.jpg" alt="Wi-Finder: the Open Wi-Fi Finding Lightsaber for Less Than 20$" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Wi-Finder-the-Open-Wi-Fi-Finding-Lightsaber-for-Le/">Wi-Finder: the Open Wi-Fi Finding Lightsaber for Less Than 20$</a></h2>

<p><em>"Have you ever been wandering around searching for an open wifi? The Wi-Finder will not only find open Wi-Fi hotspots around, it will also detect if they are really open or just displaying a login screen asking for money to use the network. And the best thing: It's cheaper than 20$! The Wi-Finder has 3 modes: If you start it, it shines blue, to indicate it is scanning for Wi-Fi networks. In case an open Wi-Fi access point is detected, the color switches to yellow to indicate that the Wi-Finder is trying to connect to the access point. If the Wi-Finder manages to get a stable connection and download a website successfully, the color will change to green. If there is no connection to the internet, the color will switch to blue again and the Wi-Finder starts searching for other Wi-Fis. A red color means that every Wi-Fi network has been scanned and none of them is open."</em> <a href="http://www.instructables.com/id/Wi-Finder-the-Open-Wi-Fi-Finding-Lightsaber-for-Le/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_LightboxMusicVisualizer.jpg" alt="LightBox Music Visualizer" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/LightBox-Music-Visualizer/">LightBox Music Visualizer</a></h2>

<p><em>"The LightBox uses your phone's or tablet's built-in microphone to analyze music to generate beautiful light patterns that match the music. Just start the app, place your phone or tablet somewhere near a sound source, and your box will visualize the sound in real-time. The LightBox can also be used a colorful ambient light."</em> <a href="http://www.instructables.com/id/LightBox-Music-Visualizer/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_CrazyEngineersDrawingRobotArdu.jpg" alt="Crazy Engineer’s Drawing Robot / Arduino GRBL CoreXY Servo" class="lefter"></p>

<h2><a href="https://www.hackster.io/arnabdasbwn/crazy-engineer-s-drawing-robot-arduino-grbl-corexy-servo-fb5269">Crazy Engineer’s Drawing Robot / Arduino GRBL CoreXY Servo</a></h2>

<p><em>"Hi. Thank you for showing Interest in this project. This Project was my engineering’s final year capstone project. It took me a month to make this Project and I had fun building it. Below I am writing a step by step DIY guide to help you build your own CNC Drawing Robot. The guide is quite long with both text and video. I have given most details so that you will not feel any problem if you are new to making projects of this kind. The Crazy Engineer’s Drawing Robot or Arduino GRBL CoreXY Servo Drawbot is a CNC based drawing robot. It is open source and open hardware based project. It uses Arduino UNO (Atmega328p) as the brain of the robot and a special GRBL firmware for G-Code Interpretation and motion control. It also uses a core [X, Y] Cartesian movement to control both X and Y axis. The Z axis is controlled by a servo motor to lift pen up and down. Crazy Engineer’s Drawing Robot is a simple CNC Drawing Robot, capable of writing or drawing on almost any flat surface. It can write with gel pens, permanent markers, and a variety of other writing implements to handle an endless number of applications. Its writing head extends beyond the machine, making it possible to draw on objects bigger than the machine itself."</em> <a href="https://www.hackster.io/arnabdasbwn/crazy-engineer-s-drawing-robot-arduino-grbl-corexy-servo-fb5269">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_ConductivePaintArt.jpg" alt="Conductive Paint Art" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Conductive-Paint-Art/">Conductive Paint Art</a></h2>

<p><em>"In this Instructable I detail the process that I took in designing a project that can light up LED's using conductive paint. I have written this in the hopes that you can completely remake the project I did (and hopefully make it better than me), but also use this as a stepping stone to creating other projects using conductive paint because information about how to work with it can be sparse. As a result, I have made this as in-depth as possible."</em> <a href="http://www.instructables.com/id/Conductive-Paint-Art/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_EalArduinoLaserHarp.jpg" alt="EAL - Arduino Laser Harp" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/EAL-Arduino-Laser-Harp/">EAL - Arduino Laser Harp</a></h2>

<p><em>"Hello and welcome to my instructables. I'm going to tell you how I programmed and build my very own Laser Harp, using an arduino UNO. First off, I want to say that I am new to the arduino environment, and this was my first project. This is a project I made in my elective subject at Erhvervsakademiet Lillebælt in Denmark. The idea was to build a frame with 3 lasers on one side pointing at 3 photoresistors on the opposite side. When the laser beam was cut, a tone would play from a piezo buzzer."</em> <a href="http://www.instructables.com/id/EAL-Arduino-Laser-Harp/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_ObstacleDetectionRobotUsingThr.jpg" alt="Obstacle Detection Robot Using Three Ultrasonic Sensors and Arduino UNO" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Obstacle-Detection-Robot-Using-Three-Ultrasonic-Se/">Obstacle Detection Robot Using Three Ultrasonic Sensors and Arduino UNO</a></h2>

<p><em>"Here we are going to implement a bot which is going to detect obstacle and according to that, it going to change its direction. In this project we are going to make Avoid obstacle Robot. Here we are going to interface three ultrasonic sensors with arduino uno. We are also using two Dc motors so for that we need one motor driver module because Arduino itself is not capable to give that much amount of current which is able to run dc motors. So for that we are using Motor Driver Module (L298D)."</em> <a href="http://www.instructables.com/id/Obstacle-Detection-Robot-Using-Three-Ultrasonic-Se/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_ArduinoFingerprintSensorTutori.jpg" alt="Arduino Fingerprint Sensor Tutorial" class="lefter"></p>

<h2><a href="https://www.hackster.io/nickthegreek82/arduino-fingerprint-sensor-tutorial-103bb4">Arduino Fingerprint Sensor Tutorial</a></h2>

<p><em>"Dear friends welcome to another tutorial! Today we are going to build an interesting Arduino project which is using a fingerprint sensor module. Without any further delay, let’s get started! I always wanted to try a fingerprint sensor module in order to learn more about its technology and use it in some of my projects in order to add biometric security to them. In order to demonstrate a simple use of the sensor a built this simple project. I have hooked up the sensor to an Arduino Nano, and I also use the small but very fast 1.44 inch color TFT display. The project asks for a valid fingerprint in order to unlock. When I place my finger on the sensor, it recognizes my finger, turns the fingerprint icon green and it welcomes me. If my girlfriend places her finger on the sensor, it also recognizes her, and displays a welcome message with her name. If I place another finger on the sensor, the project does not unlock the screen. It works fine and you are going to see, you can build this project in less than 10 minutes! Let’s see how to achieve that!"</em> <a href="https://www.hackster.io/nickthegreek82/arduino-fingerprint-sensor-tutorial-103bb4">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_ArtnetLedPixelsWithEsp8266.jpg" alt="Artnet LED Pixels With ESP8266" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Artnet-LED-Pixels-With-ESP8266/">Artnet LED Pixels With ESP8266</a></h2>

<p><em>"After the success of my last Instructable, ESP8266 Artnet to DMX, I have completely revamped my espArtNetNode code, releasing v2 with new features such as RDM support and WS2812 output. This code is still in beta and there are a few known bugs - and probably a few unknown also. I have written this Instructable to help with some common questions on setting this device up to control WS2812 pixels. We will quickly look at how I have laid out and wired my 30 x 15 pixels, then I'll show you which settings you need to get the ESP connected. Next, I'll do a quick run through how to patch the ESP outputs into Jinx so we can get some cool effects running. In the final step, I'll discuss some of the issues I'm currently having and things I'd like to add in the future. The video here will show you very quickly through all of these steps. I apologize for the poor sound quality - I don't have an external microphone and my laptop fans are really loud. I'd love to see how you use this. Post some photos, videos and comments below to let me know your experience and any suggestions you may have. I read all the comments I receive and try to reply in a timely manner."</em> <a href="http://www.instructables.com/id/Artnet-LED-Pixels-With-ESP8266/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_HowToBuildYourOwnGoogleAiyWith.jpg" alt="How to build your own Google AIY without the Kit" class="lefter"></p>

<h2><a href="http://hackaday.com/2017/05/30/diy-google-aiy/">How to build your own Google AIY without the Kit</a></h2>

<p><em>"Google’s voice assistant has been around for a while now and when Amazon released its Alexa API and ported the PaaS Cloud code to the Raspberry Pi 2 it was just a matter of time before everyone else jumped on the fast train to maker kingdom. Google just did it in style. Few know that the Google Assistant API for the Raspberry Pi 3 has been out there for some time now but when they decided to give away a free kit with the May 2017 issues of MagPi magazine, they made an impression on everyone. Unfortunately the world has more makers and hackers and the number of copies of the magazine are limited. In this writeup, I layout the DIY version of the AIY kit for everyone else who wants to talk to a cardboard box. I take a closer look at the free kit, take it apart, put it together and replace it with DIY magic. To make things more convenient, I also designed an enclosure that you can 3D print to complete the kit. Lets get started."</em> <a href="http://hackaday.com/2017/05/30/diy-google-aiy/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_BreweryProjectWithAnArduinoAnd.jpg" alt="Brewery Project With an Arduino and a Raspberry Pi" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Brewery-Project-With-an-Arduino-and-a-Raspberry-Pi/">Brewery Project With an Arduino and a Raspberry Pi</a></h2>

<p><em>"Hello everyone, welcome to our pico-brewery project. Through this tutorial we will explain you how to proceed to realize your installation. As you can imagine, we obviously love to drink beers so to have a brewery it's an old dream. When the professor asked us “what will be your project?” The design and the automation of a brewery was an fatality. The goal of this project is to create a pico-brewery with a limited budget and this including an Arduino and a Raspberry-pie. The budget has to around 150 euros. To achieve our goal, we worked with recovery components. Moreover, the CERISIC (Centre d’études et de recherches de la categories techniques de la HELHa), helped us providing several components. Thanks to them for the help. We had the idea of a vertical brewery to allow making beer without a lot of space. The idea was to create a low-cost brewery but also to give the ambitious at people to make their pico-brewery."</em> <a href="http://www.instructables.com/id/Brewery-Project-With-an-Arduino-and-a-Raspberry-Pi/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_DetectTheRpmOfYourMotorUsingAP.jpg" alt="Detect the rpm of your motor using a Photoelectric IR Through Beam Sensor" class="lefter"></p>

<h2><a href="https://www.modmypi.com/blog/detect-the-rpm-of-your-motor-using-a-photoelectric-ir-through-beam-sensor">Detect the rpm of your motor using a Photoelectric IR Through Beam Sensor</a></h2>

<p><em>"In this project you will learn how to wire up a Photoelectric IR Through Beam Sensor (HC-89) and write some code to calculate the speed at which a motor is rotating."</em> <a href="https://www.modmypi.com/blog/detect-the-rpm-of-your-motor-using-a-photoelectric-ir-through-beam-sensor">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_TemperatureControlledFanWithLe.jpg" alt="Temperature Controlled Fan With LED Status" class="lefter"></p>

<h2><a href="https://www.hackster.io/bbtinkerer/temperature-controlled-fan-with-led-status-e147d3">Temperature Controlled Fan With LED Status</a></h2>

<p><em>"Simple ATtiny85 fan controller to turn a fan on/off based on temperature. Includes an LED as a temperature indicator. LED is dim at start of fan on temperature and blinks when above a max temperature. Fan is not PWM controlled since I am using a small 5V fan which is quiet running at 100%. The controller is in sleep state while the temperature is below the minimum threshold and wakes up every ~8 seconds to recheck the temperature. When temperature is above minimum threshold, the controller will stay awake checking every second till the temperature falls below the minimum threshold. The code uses ds18b20 library by Davide Gironi. I want to make a 12V power supply for external hard drives. I have a bunch of external hard drives running that are connected to the router, media center, and a Raspberry Pi. The 12V wall warts are taking up way too much space. The fan controller will be used in the power supply enclosure. I'm not sure if the power supply will need a fan but I figure since I'm learning how to use microcontrollers might as well build something I will put to use. My choice of parts were left overs from other projects. You will need to change things up to suite your needs. Make sure to use a logic level N-MOSFET that can handle the requirements of your fan. Follow the schematics in the KiCad in the GitHub repository. There is PCB diagram that fits a perfboard if you want to follow the layout I made."</em> <a href="https://www.hackster.io/bbtinkerer/temperature-controlled-fan-with-led-status-e147d3">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_ClearwalkerBluetoothControl.jpg" alt="ClearWalker Bluetooth Control" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/ClearWalker-Bluetooth-Control/">ClearWalker Bluetooth Control</a></h2>

<p><em>"In this project, I'll be outlining how I am able to control my ClearWalker strandbeest-style contraption via Bluetooth. The device uses two motors to control 8 legs and is steered in a similar manner to a tank, or a robot that steers with two wheels that go different speeds. These basic instructions should work for many types of vehicles. This article won't go over how to actually build one of these 'beests, as that would be more of a book. Check out the original Strandbeest here, or my ClearWalker YouTube playlist for more general build info."</em> <a href="http://www.instructables.com/id/ClearWalker-Bluetooth-Control/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_PianoUsing555Timer.jpg" alt="Piano Using 555 Timer" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Intro-for-Piano-Using-555-Timer/">Piano Using 555 Timer</a></h2>

<p><em>"A tone is a sound which is produced by a regular vibration. So it has only one frequency even though intensity/amplitude can vary. Loudspeaker is one of the electronic transducer which converts electrical signals to pressure variation to produce the sensation of sound. The diaphragm of the speaker will vibrate according to the frequency and amplitude of electrical signals feed to it. Audible frequency range of humans is from 20Hz to 20KHz, so we are going to generate electrical signals in this range using 555 IC and feed it to the speaker. The 555 timer is operated in Astable multivibrator mode. In Astable mode multivibrator mode, timer produces accurate free running square waveforms without the aid of any external triggers."</em> <a href="http://www.instructables.com/id/Intro-for-Piano-Using-555-Timer/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_ArduinoControlledLedLightShow.jpg" alt="Arduino Controlled Led Light Show" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Controlled-Led-Light-Show/">Arduino Controlled Led Light Show</a></h2>

<p><em>"LEDs dancing on music beats."</em> <a href="http://www.instructables.com/id/Arduino-Controlled-Led-Light-Show/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_IotFidget.jpg" alt="IoT Fidget" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/IoT-Fidget/">IoT Fidget</a></h2>

<p><em>"This instructables show how to make an IoT Fidget. When you playing a fidget cube, someone may ask: "what is the effect when you press the Fidget's button?" Apart from the explanation of how to reduce your stress level, lets make your click become part of IoT big data. It may help to analyse how stress you are..."</em> <a href="http://www.instructables.com/id/IoT-Fidget/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_PhoneControlledWatchDogsWrench.jpg" alt="Phone Controlled Watch Dogs Wrench Mask" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Phone-Controlled-Watch-Dogs-Wrench-Mask/">Phone Controlled Watch Dogs Wrench Mask</a></h2>

<p><em>"My son came across "Wrench" character from watch dogs and thought it would be a really good idea for us to try and make a copy of the mask, we built this mask together and he is really happy with it - best part is that you control the eyes from any phone! If you like this project please vote for us :)"</em> <a href="http://www.instructables.com/id/Phone-Controlled-Watch-Dogs-Wrench-Mask/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_FaceAndEyeDetectionUsingOpencv.jpg" alt="Face and Eye Detection Using OpenCv With Raspberry Pi" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Face-and-Eye-Detection-Using-OpenCv-With-Raspberry/">Face and Eye Detection Using OpenCv With Raspberry Pi</a></h2>

<p><em>"In this project we are using OpenCv in Raspberry pi. This project is used to detect the human Face and eye with the help of OpenCv tool. In order to do object detection with cascade files, you first need cascade files. For the extremely popular tasks, these file already exist."</em> <a href="http://www.instructables.com/id/Face-and-Eye-Detection-Using-OpenCv-With-Raspberry/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_Carduino.jpg" alt="Carduino" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Carduino-2/">Carduino</a></h2>

<p><em>"There are lots of information which characterise a car: the revolution of the engine per minute, the velocity, its position and other general information. It could be interesting to recover that data from a car. That is the goal of our project. There are multiple applications. These applications are for a personal or a professional use: For example, the position can be used to catch thieves; The acquisition of the velocity can be used in a race; The assembly can also be used for preventive maintenance. General information about the state of the motor can be recuperated with the help of the canbus module; It can also send you a SMS to help you to find your car or to inform you when there is a problem (broken glass by example). All of the data are then stored in a SQL database."</em> <a href="http://www.instructables.com/id/Carduino-2/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_Bmp2805110LcdArduino.jpg" alt="BMP280+5110 LCD Arduino" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/BMP2805110-LCD-Arduino/">BMP280+5110 LCD Arduino</a></h2>

<p><em>"I just had a long weekend and after finishing with my electronics soldering i got an idea. I have a few BMP280 sensors that i ordered by mistake , but i didn't use them for a while. Since i did not found a project for the 5110 LCD, i thought it would be fun to make one :) This is a very simple sketch to measure the barometric pressure and temperature data. It's my first Arduino code that i made by myself, so it is "simple" :) !"</em> <a href="http://www.instructables.com/id/BMP2805110-LCD-Arduino/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_Attiny85RobotInsectV20.jpg" alt="ATtiny85 Robot Insect V2.0" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/ATtiny85-Robot-Insect-V20/">ATtiny85 Robot Insect V2.0</a></h2>

<p><em>"The intention is to build an as simple as possible yet beautiful robot insect, and then apply it to their own choice, as a swarm insect or equipped with an IR sensor or color sensor ........ I would like to see two Robot Insects could communicate with each other via IR or Mic and Piezo"</em> <a href="http://www.instructables.com/id/ATtiny85-Robot-Insect-V20/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_MakeYourOwnArduinoWithPowerSup.jpg" alt="Make Your Own Arduino With Power Supply and Bootloader" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Make-Your-Own-Arduino-With-Power-Supply-and-Bootlo/">Make Your Own Arduino With Power Supply and Bootloader</a></h2>

<p><em>"Presented here is a low cost idea for making arduino at home. In this project, step by step information is provided from power supply to bootloading to program the Microcontroller. Here is the clone Arduino Board. I have used ATMEGA 8P for this project. You can use ATMEGA 328/168/8 or any Blank IC for this project of the same series. Here various softwares are used like Arduino IDE. You should have some basic knowledge about ARDUINO UNO and its programming and applications. Here various tiny connectors are used so one must very precisely solder all the components."</em> <a href="http://www.instructables.com/id/Make-Your-Own-Arduino-With-Power-Supply-and-Bootlo/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_SoundToRcServoDriver.jpg" alt="Sound to RC Servo Driver" class="lefter"></p>

<h2><a href="http://www.electronics-lab.com/project/sound-rc-servo-driver/">Sound to RC Servo Driver</a></h2>

<p><em>"This project is designed for Animatronics and Puppeteer applications, however it can be used in other applications like sound responsive toys, robots etc. Especially this project helps to move the jaw or mouth of animatronics creature. The project moves RC servo once receives any kind of sound.  Rotation angle depends on sound level, more the sound level more the movement. Movement of the servo is proportional to sound level. Circuit has 4 channel servo drivers, First channel is driven by sound, and rest 3 RC servos controlled by on board trimmer potentiometer, these 3 channels helps to drive other movement of animatronics figure. Sound Received by microphone is convered to DC voltage, PIC16F72 microcontroller converts DC voltage into RC PWM signal. Circuits works with 6V DC , advisable to use battery for low jitter."</em> <a href="http://www.electronics-lab.com/project/sound-rc-servo-driver/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM109_WeatherAwareSprinklerControlle.jpg" alt="Weather Aware Sprinkler Controller" class="lefter"></p>

<h2><a href="https://www.hackster.io/msmaha/weather-aware-sprinkler-controller-b546dd">Weather Aware Sprinkler Controller</a></h2>

<p><em>"This project uses the Particle Photon and a relay module to create a 6 station sprinkler controller. It has these features not found in similar projects: Uses Weather Underground API to prevent watering when windy, rainy, or too cold. Signup for a free developer account here; Has a built in web interface that you can access from any browser device on your local WiFi network; Manual control page lets you trigger any zone from your phone's browser to facilitate sprinkler adjustment and testing."</em> <a href="https://www.hackster.io/msmaha/weather-aware-sprinkler-controller-b546dd">[...]</a>
 </SPAN></DIV></p>

<hr />

<p>That's all Folks!</p>

<script data-cfasync="false" src="../../../../../../cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>SHB.build({elementID: 'shb', pref: { btnSizeClass: 'btn-md', btnClass: 'btn my-btn'}, buttons: { fbLike: true, fbShare:true, tweet: true, plusOne: true, plusShare: true,linkedInShare:true}});</script>

					</div>
				</section>
				</div> <!-- Container -->

				<footer id="footer" class="panel-footer">
					<div class="inner">
						<a href="https://github.com/PhileCMS/Phile">Phile</a> was made by <a href="https://github.com/PhileCMS">The PhileCMS Community</a>.
					</div>
				</footer>
			</div>
		</div>
</div>
		<script type="text/javascript">
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-20725619-1']);
            _gaq.push(['_trackPageview']);
            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
        </script>
		<!-- Matomo -->
<script type="text/javascript">
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//matomo.altlab.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '2']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
	</body>
</html>
