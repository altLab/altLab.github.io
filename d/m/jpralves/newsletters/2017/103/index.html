<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

		<!-- <base href="https://altlab.org/d/" />  -->
		<title>Newsletter altLab - 2017-04-20 - Nº 103 | altLab Documenta</title>
				<meta name="description" content="Newsletter altLab Nº103 de 20 de Abril de 2017">
				<meta property="og:type" content="article" />
		<meta property="og:title" content="Newsletter altLab - 2017-04-20 - Nº 103 | altLab Documenta" />
		<meta property="og:description" content="Newsletter altLab Nº103 de 20 de Abril de 2017" />
		<meta property="og:url" content="https://altlab.org/d/m/jpralves/newsletters/2017/103/" />
		<meta property="og:site_name" content="altLab Documenta" />

		<!-- Bootstrap -->
		<link href="../../../../../themes/altlab/css/bootstrap.min.css" rel="stylesheet">
		<link href="../../../../../themes/altlab/override-test.css" rel="stylesheet">
		<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
		<script src="../../../../../themes/altlab/js/jquery-1.12.4.min.js"></script>
		<!-- Include all compiled plugins (below), or include individual files as needed -->
		<script src="../../../../../themes/altlab/js/bootstrap.min.js"></script>

	</head>
	<body>
<div class="container">
<div class="container-fluid">
      <div class="page-header hidden-xs" id="brand-logo">
        <h1><a href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-gradoverwhite.png" width="180" height="120" alt="Home" style="vertical-align:text-bottom" /></a> Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></h1>

      </div>
			<nav class="navbar navbar-inverse">

				<div class="container-fluid">
					<div class="navbar-header">
						<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#myNavbar">
							<span class="sr-only">Toggle navigation</span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
<div class="visible-xs">
<a class="navbar-brand" href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-documenta.png" width="58" height="35" alt="Home" style="margin-top: -7px;"></a>
						<a class="navbar-brand" href="https://altlab.org/d/">Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></a></div>
					</div>
					<div class="collapse navbar-collapse" id="myNavbar">
						<ul class="nav navbar-nav">

           	<li id="dropdown.1" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Membros <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../index.html">Index</a>
</li>
   
           	<li id="dropdown.101" class="dropdown">
		<a href="https://altlab.org/d/m/jpralves/">João Alves <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.102" class="dropdown">
		<a href="https://altlab.org/d/m/sislog/">Fernando Carvalho <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.103" class="dropdown">
		<a href="https://altlab.org/d/m/pangelo/">Pedro Ângelo <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.104" class="dropdown">
		<a href="../../../../dinix/index.html">Dinix <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../funke/funke.html">m/funke/funke</a>
  
   	</li>
            	<li id="dropdown.106" class="dropdown">
		<a href="../../../../afonsom/index.html">Afonso Muralha <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.107" class="dropdown">
		<a href="../../../../x3msnake/index.html">X3msnake <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="https://altlab.org/d/m/ampmendes/">António Mendes</a>
  
   	</li>
            	<li>
		<a href="../../../../guardajoao/index.html">GuardaJoao</a>
  
   	</li>
            	<li>
		<a href="../../../../jac/index.html">JAC</a>
  
   	</li>
            	<li>
		<a href="https://altlab.org/d/m/nini/">Nuno Nini</a>
  
   	</li>
 
</ul>
    	</li>
            	<li id="dropdown.2" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Documentação Partilhada <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="https://altlab.org/d/s/">Index</a>
</li>
   
                         	<li id="dropdown.203" class="dropdown">
		<a href="https://altlab.org/d/s/workshops/">Workshops <span class="caret"></span></a>
  
      	</li>
                   	<li>
		<a href="../../../../../s/documenta/index.html">Documenta DevMap</a>
  
   	</li>
                   	<li>
		<a href="https://altlab.org/d/s/processos/">Processos do Lab (draft)</a>
  
   	</li>
            	<li id="dropdown.208" class="dropdown">
		<a href="../../../../../s/recursos/index.html">Recursos <span class="caret"></span></a>
  
      	</li>
 
</ul>
    	</li>
 
						</ul>
					</div>
				</div>
			</nav>

			<div class="container">
				<div class="container">
				<section id="content">
					<div class="inner">
						<p><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
<link rel="stylesheet" href="../res/_shb.css"></p>

<script src="../res/_shb.min.js" type="text/javascript"></script>

<div style="text-align: center;">
<button class="btn my-btn btn-md disabled">Share:</button>
<div class="btn-group" id="shb"></div>
</div>

<p><br></p>

<h1 id="topo"><img src="../res/__Titulo.png" alt="Newsletter altLab" /></h1>

<p>2017-04-20 - Nº 103</p>

<div style="position: fixed; z-index: 65535; right: 10px; bottom: 10px;">
<a href='#topo' title='Go to Top'><img src="../res/_gotop.png" alt="go to top image" /></a>
</div>

<div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'pt', layout: google.translate.TranslateElement.FloatPosition.TOP_LEFT, multilanguagePage: true}, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<p><DIV class="articledetail"><SPAN class="articledetail"></p>

<h2>Editorial</h2>

<p>Esta é a Newsletter Nº 103 que se apresenta com o mesmo formato que as anteriores. Se gostar da Newsletter partilhe-a!</p>

<p>Todas as Newsletters encontram-se indexadas no <a href="https://altlab.org/d/m/jpralves/newsletters/">link</a>.</p>

<p>Esta Newsletter tem os seguintes tópicos:</p>

<ul>
<li><a href="#Novidades-da-Semana">Novidades da Semana</a></li>
<li><a href="#Ciencia-e-Tecnologia">Ciência e Tecnologia</a></li>
<li><a href="#Modelos-3D">Modelos 3D</a></li>
<li><a href="#Projetos-Maker">Projetos Maker</a></li>
</ul>

<p>Faz hoje anos que nascia em 1818 <a href="https://en.wikipedia.org/wiki/Heinrich_G%C3%B6bel">Heinrich Göbel</a>. Este inventor Alemão, ficou conhecido por ter desenvolvido as lâmpadas de incandescência 25 anos antes de Thomas Edison.
Hoje a china lançou com sucesso o cargueiro espacial não-tripulado Tianzhou-1. Este irá acoplar-se com o laboratório espacial Tiangong-2 a 21 de Abril.
A Baidu vai lançar já em Julho a sua tecnologia de carros sem condutor. Ainda em ambiente restrito este irá ser expandido gradualmente até 2020 para estradas e auto-estradas.
A Apple recebeu a licença para poder testar carros sem condutor na Califórnia. Este passo é uma forte indicação das intenções da companhia.</p>

<p>Na Newsletter desta semana apresentamos diversos projetos de maker assim como alguns modelos 3D que poderão ser úteis.</p>

<p><img src="../res/_jpralves.jpg" alt="jpralves" /> João Alves (<a href="https://altlab.org/d/m/jpralves/newsletters/2017/103/&#x6d;&#97;&#105;&#x6c;&#116;&#111;&#x3a;&#x6a;&#112;&#114;&#x61;&#108;&#118;&#x65;&#x73;&#64;g&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;o&#x6d;#x6d;&a&i&l&t&o&:&j&p&r&a&l&v&e&s&@g&m&a&i&l&.&co&m"><span class="__cf_email__" data-cfemail="23495351424f55465063444e424a4f0d404c4e">[email&#160;protected]</span></a>)</p>

<p>O conteúdo da Newsletter encontra-se sob a licença <img src="../res/_by-nc-sa4.0.png" alt="by-nc-sa4.0" /> <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>

<p></SPAN></DIV></p>

<hr />

<h1 id="Novidades-da-Semana">Novidades da Semana</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS103_ChinaLaunchesItsFirstSpaceCarg.jpg" alt="China Launches Its First Space Cargo Ship Into Orbit" class="lefter"></p>

<h2><a href="http://www.space.com/36539-china-launches-tianzhou-1-space-cargo-ship.html">China Launches Its First Space Cargo Ship Into Orbit</a></h2>

<p><em>"China's bid to establish a permanently crewed space station got a boost today (April 20) with the launch of the country's first cargo supply spacecraft: the Tianzhou-1. The uncrewed Tianzhou-1 cargo resupply spacecraft launched into orbit atop a Long March 7 Y2 booster from the Wenchang Satellite Launch Center in the southern island province of Hainan. Liftoff occurred at 7:41 p.m. local time (7:41 a.m. EDT/1141 GMT) at the spaceport. Space program officials in China declared mission success shortly after the rocket launched and the vehicle deployed its solar panels. Tianzhou-1 is now on track to dock with the Tiangong-2 space laboratory, or "Heavenly Palace 2," where two astronauts spent a month last October in China's longest-ever crewed spaceflight. That crewed mission, called Shenzhou-11,lasted 33 days."</em> <a href="http://www.space.com/36539-china-launches-tianzhou-1-space-cargo-ship.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS103_BaiduToLaunchSelfDrivingCarTec.jpg" alt="Baidu to launch self-driving car technology in July" class="lefter"></p>

<h2><a href="http://www.reuters.com/article/us-baidu-autonomous-idUSKBN17L05K">Baidu to launch self-driving car technology in July</a></h2>

<p><em>"Baidu Inc (BIDU.O) said on Tuesday it would launch its self-driving car technology for restricted environment in July before gradually introducing fully autonomous driving capabilities on highways and open city roads by 2020. The project is named Apollo after the lunar landing program, the Chinese search giant said, adding it would work with partners who provide vehicles, sensors and other components for the new technology. As part of its push into artificial intelligence (AI), the company in January named former Microsoft Corp (MSFT.O) executive Qi Lu as chief operating officer. Two months after the appointment, Baidu's chief scientist Andrew Ng, who led AI and augmented reality (AR) projects, said he would step down. The company also launched a $200 million fund in October to focus on AI, AR and deep learning, followed by a $3 billion fund announced in September to target mid- and late- stage start-ups."</em> <a href="http://www.reuters.com/article/us-baidu-autonomous-idUSKBN17L05K">[...]</a>
 </SPAN></DIV></p>

<h2>Outras Notícias</h2>

<ul>
<li><a href="http://www.businessinsider.com/apple-officially-testing-self-driving-cars-california-dmv-confirms-2017-4">Apple has an official permit to test self-driving cars in California, DMV confirms</a></li>
<li><a href="https://blog.arduino.cc/2017/04/18/introducing-the-arduino-mkrfox1200/">Introducing the Arduino MKRFOX1200</a></li>
<li><a href="https://aws.amazon.com/blogs/aws/ec2-f1-instances-with-fpgas-now-generally-available/">EC2 F1 Instances with FPGAs – Now Generally Available</a></li>
<li><a href="https://techcrunch.com/2017/04/18/facebook-open-sources-caffe2-its-flexible-deep-learning-framework-of-choice/">Facebook open sources Caffe2, its flexible deep learning framework of choice</a></li>
</ul>

<h1 id="Ciencia-e-Tecnologia">Ciência e Tecnologia</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_GraphenePhototransistorPromisi.jpg" alt="Graphene ‘phototransistor’ promising for optical technologies" class="lefter"></p>

<h2><a href="http://www.purdue.edu/newsroom/releases/2017/Q2/graphene-phototransistor-promising-for-optical-technologies.html">Graphene ‘phototransistor’ promising for optical technologies</a></h2>

<p><em>"Researchers have solved a problem hindering development of highly sensitive optical devices made of a material called graphene, an advance that could bring applications from imaging and displays to sensors and high-speed communications. Graphene is an extremely thin layer of carbon that is promising for optoelectronics, and researchers are trying to develop graphene-based photodetectors, devices that are critical for many technologies. However, typical photodetectors made of graphene have only a small area that is sensitive to light, limiting their performance. Now, researchers have solved the problem by combining graphene with a comparatively much larger silicon carbide substrate, creating graphene field-effect transistors, or GFETs, which can be activated by light, said Yong Chen, a Purdue University professor of physics and astronomy and electrical and computer engineering, and director of the Purdue Quantum Center. High-performance photodetectors might be useful for applications including high-speed communications and ultra-sensitive cameras for astrophysics, as well as sensing applications and wearable electronics. Arrays of the graphene-based transistors might bring high-resolution imaging and displays."</em> <a href="http://www.purdue.edu/newsroom/releases/2017/Q2/graphene-phototransistor-promising-for-optical-technologies.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_AsuTeamConnectsHumansRobotsThr.jpg" alt="ASU team connects humans, robots through common language" class="lefter"></p>

<h2><a href="https://asunow.asu.edu/20170412-creativity-asu-team-connects-humans-robots-through-common-language">ASU team connects humans, robots through common language</a></h2>

<p><em>"An ASU-led project that makes it easier for humans and robots to communicate is among the contenders for a spot in an international competition widely considered as the “Olympics of Technology.” Three doctoral candidates in computer science at Arizona State University’s Ira A. Fulton Schools of Engineering constitute Æffective Robotics, one of 12 teams that will compete next week in Seattle in the U.S. finals of the 2017 Microsoft Imagine Cup. They’re vying for a spot in the top six, which would earn them a place in the international finals in Seattle in July, where they would go for the top prize of $100,000, plus support to launch a start-up. Each year, about 350,000 students from more than 170 countries and regions enter the competition, including about 3,000 students at colleges and universities in the U.S. After several months of work on the project they’ve titled “Cloudy with a Chance of Synergy,” the Æffective Robotics members say that they’re confident. Tathagata Chakraborti, Anagha Kulkarni and Sarath Sreedharan will be presenting a concept — along with software — for the operations of a “factory of the future,” in which robots and humans would be connected through a networking system enabling them to effectively “share a brain.” The humans and robots would not actually be reading each other’s minds, Chakraborti said. But they would have technology that provides platforms for a “mutually understood vocabulary” and for “intention recognition and projection,” allowing everyone and everything connected to the network to anticipate each other’s physical movements and high-level goals and to comprehend the intentions and motivations behind those movements."</em> <a href="https://asunow.asu.edu/20170412-creativity-asu-team-connects-humans-robots-through-common-language">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_SupercomputerSimulationOffersP.jpg" alt="Supercomputer Simulation Offers Peek at the Future of Quantum Computers" class="lefter"></p>

<h2><a href="https://www.technologyreview.com/s/604140/a-milestone-for-quantum-computing/">Supercomputer Simulation Offers Peek at the Future of Quantum Computers</a></h2>

<p><em>"Computer scientists have a name for the point at which quantum computers become more powerful than ordinary computers. They call it “quantum supremacy,” and, by all accounts, that time is rapidly approaching. The current thinking is that a quantum computer capable of handling 49 qubits will match the capability of the most powerful supercomputer on the planet. And anything bigger than that will be beyond the ken of ordinary computing machines. That isn’t quite possible yet. But it raises important questions about how we can know whether these quantum computers will work as expected. To find out, computer scientists have begun using powerful classical computers to simulate the behavior of quantum computers. The idea is to calibrate and benchmark their behavior as accurately as possible, while we still can. After that, we’ll just have to trust the quantum world. Of course, nobody has yet simulated a 49-qubit quantum computer. But today, Thomas Haner and  Damian Steiger from ETH Zurich in Switzerland announce the most ambitious attempt to date. These guys have used the fifth most powerful supercomputer in the world to simulate the behavior of a 45-qubit quantum computer. “To our knowledge, this constitutes a new record in the maximal number of simulated qubits,” say Haner and Steiger. And they show how more powerful simulations ought to be possible. These simulations are difficult because of the sheer magnitude of the calculations that quantum computers make possible. This great power comes from the quantum phenomenon of superposition, which allows quantum particles, such as photons, to exist in more than one state at the same time. For example, a horizontally polarized photon can represent a 0 and a vertically polarized photon can represent a 1. But when a photon exists as a superposition of both horizontal and vertical polarizations at the same time, it can represent both a 0 and 1 in a calculation. In this way, two photons can represent four numbers, three photons can represent eight numbers, and so on. This is where quantum computers get their computational horsepower, and it is why classical computers pale in comparison."</em> <a href="https://www.technologyreview.com/s/604140/a-milestone-for-quantum-computing/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_BiasedBotsHumanPrejudicesSneak.jpg" alt="Biased bots: Human prejudices sneak into artificial intelligence systems" class="lefter"></p>

<h2><a href="https://phys.org/news/2017-04-biased-bots-human-prejudices-artificial.html">Biased bots: Human prejudices sneak into artificial intelligence systems</a></h2>

<p><em>"In debates over the future of artificial intelligence, many experts think of the new systems as coldly logical and objectively rational. But in a new study, researchers have demonstrated how machines can be reflections of us, their creators, in potentially problematic ways. Common machine learning programs, when trained with ordinary human language available online, can acquire cultural biases embedded in the patterns of wording, the researchers found. These biases range from the morally neutral, like a preference for flowers over insects, to the objectionable views of race and gender. Identifying and addressing possible bias in machine learning will be critically important as we increasingly turn to computers for processing the natural language humans use to communicate, for instance in doing online text searches, image categorization and automated translations. "Questions about fairness and bias in machine learning are tremendously important for our society," said researcher Arvind Narayanan, an assistant professor of computer science and an affiliated faculty member at the Center for Information Technology Policy (CITP) at Princeton University, as well as an affiliate scholar at Stanford Law School's Center for Internet and Society. "We have a situation where these artificial intelligence systems may be perpetuating historical patterns of bias that we might find socially unacceptable and which we might be trying to move away from." The paper, "Semantics derived automatically from language corpora contain human-like biases," published April 14 in Science. Its lead author is Aylin Caliskan, a postdoctoral research associate and a CITP fellow at Princeton; Joanna Bryson, a reader at University of Bath, and CITP affiliate, is a coauthor."</em> <a href="https://phys.org/news/2017-04-biased-bots-human-prejudices-artificial.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_4DPrintingGetsSimplerAndFaster.jpg" alt="4D Printing Gets Simpler and Faster" class="lefter"></p>

<h2><a href="https://cacm.acm.org/news/216039-4d-printing-gets-simpler-and-faster/fulltext">4D Printing Gets Simpler and Faster</a></h2>

<p><em>"A team of researchers from the Georgia Institute of Technology, the Singapore University of Technology and Design (SUTD), and Xi'an Jiaotong University and Zhejiang University in China have developed a new approach that significantly simplifies and increases the potential of four-dimensional (4D) printing by incorporating the mechanical programming post-processing step directly into the three-dimensional (3D) printing process. The method enables high-resolution 3D-printed components to be designed by computer simulation, 3D printed, and directly and rapidly transformed into new permanent configurations via the use of heat. The researchers found the new approach can help save printing time and materials by up to 90 percent, while completely eliminating the mechanical programming process from the design and manufacturing workflow."</em> <a href="https://cacm.acm.org/news/216039-4d-printing-gets-simpler-and-faster/fulltext">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_ComputersCreateRecipeForTwoNew.jpg" alt="Computers Create Recipe for Two New Magnetic Materials" class="lefter"></p>

<h2><a href="http://pratt.duke.edu/about/news/predicting-magnets">Computers Create Recipe for Two New Magnetic Materials</a></h2>

<p><em>"Material scientists have predicted and built two new magnetic materials, atom-by-atom, using high-throughput computational models. The success marks a new era for the large-scale design of new magnetic materials at unprecedented speed. Although magnets abound in everyday life, they are actually rarities—only about five percent of known inorganic compounds show even a hint of magnetism. And of those, just a few dozen are useful in real-world applications because of variability in properties such as effective temperature range and magnetic permanence. The relative scarcity of these materials can make them expensive or difficult to obtain, leading many to search for new options given how important magnets are in applications ranging from motors to magnetic resonance imaging (MRI) machines. The traditional process involves little more than trial and error, as researchers produce different molecular structures in hopes of finding one with magnetic properties. Many high-performance magnets, however, are singular oddities among physical and chemical trends that defy intuition. In a new study, materials scientists from Duke University provide a shortcut in this process. They show the capability to predict magnetism in new materials through computer models that can screen hundreds of thousands of candidates in short order. And, to prove it works, they’ve created two magnetic materials that have never been seen before. The results appear April 14, 2017, in Science Advances."</em> <a href="http://pratt.duke.edu/about/news/predicting-magnets">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_SprayOnMemoryCouldEnableBendab.jpg" alt="'Spray-on' Memory could enable bendable digital storage" class="lefter"></p>

<h2><a href="https://today.duke.edu/2017/04/spray-memory-could-enable-bendable-digital-storage">'Spray-on' Memory could enable bendable digital storage</a></h2>

<p><em>"USB flash drives are already common accessories in offices and college campuses. But thanks to the rise in printable electronics, digital storage devices like these may soon be everywhere – including on our groceries, pill bottles and even clothing. Duke University researchers have brought us closer to a future of low-cost, flexible electronics by creating a new “spray-on” digital memory device using only an aerosol jet printer and nanoparticle inks. The device, which is analogous to a 4-bit flash drive, is the first fully-printed digital memory that would be suitable for practical use in simple electronics such as environmental sensors or RFID tags. And because it is jet-printed at relatively low temperatures, it could be used to build programmable electronic devices on bendable materials like paper, plastic or fabric."</em> <a href="https://today.duke.edu/2017/04/spray-memory-could-enable-bendable-digital-storage">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_NeuronReadingNanowiresCouldAcc.jpg" alt="‘Neuron-reading’ Nanowires Could Accelerate Development of Drugs to Treat Neurological Diseases" class="lefter"></p>

<h2><a href="http://ucsdnews.ucsd.edu/pressrelease/neuron_reading_nanowires_could_accelerate_drug_development_to_treat_disease">‘Neuron-reading’ Nanowires Could Accelerate Development of Drugs to Treat Neurological Diseases</a></h2>

<p><em>"A team led by engineers at the University of California San Diego has developed nanowires that can record the electrical activity of neurons in fine detail. The new nanowire technology could one day serve as a platform to screen drugs for neurological diseases and could enable researchers to better understand how single cells communicate in large neuronal networks. “We’re developing tools that will allow us to dig deeper into the science of how the brain works,” said Shadi Dayeh, an electrical engineering professor at the UC San Diego Jacobs School of Engineering and the team’s lead investigator. “We envision that this nanowire technology could be used on stem-cell-derived brain models to identify the most effective drugs for neurological diseases,” said Anne Bang, director of cell biology at the Conrad Prebys Center for Chemical Genomics at the Sanford Burnham Medical Research Institute. The project was a collaborative effort between the Dayeh and Bang labs, neurobiologists at UC San Diego, and researchers at Nanyang Technological University in Singapore and Sandia National Laboratories. The researchers published their work Apr. 10 in Nano Letters."</em> <a href="http://ucsdnews.ucsd.edu/pressrelease/neuron_reading_nanowires_could_accelerate_drug_development_to_treat_disease">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_NewTechnologyCanBoostFibreOpti.jpg" alt="New technology can boost fibre-optic bandwidth" class="lefter"></p>

<h2><a href="http://www.dtu.dk/english/news/nyhed?id=906d90fd-38b1-4174-96b0-88d2524ee7dd">New technology can boost fibre-optic bandwidth</a></h2>

<p><em>"Jesper Bevensee Jensen, co-founder and CTO of the start-up company Bifrost Communications, was recently presented with the Danish Industry Foundation Entrepreneur Award of DKK 500,000 by HRH Crown Prince Frederik of Denmark. In its motivation for the award, the jury stressed, among other things, that the team behind Bifrost had developed a technology with ‘global potential’ which, by its very nature, was ideally suited for scaling and mass production. The company is ready to find investors who wish to inject money into Bifrost’s ground-breaking optical transceiver (contraction of the English words ‘transmitter’ and ‘receiver’, ed.). The technology will be able to improve fibre network range and increase the number of users. From being a demonstration model the size of a bread bin, the transceiver is to be developed into something akin to a USB stick which the team can test on the telecom operators’ existing fibre network. The aim is to secure billions of kroner in savings for the telecom sector, create economic growth and jobs, and faster internet connections. In recent years, the former assistant professor at DTU Fotonik published scientific articles and beat world records with lightning-fast wireless networks. However, he became increasingly interested in solving the industry’s need for cheap broadband solutions that could provide users with good, stable, and fast internet access. Jesper Bevensee Jensen therefore decided to simplify things, do away with costly complicated steps, and use new technologies. To that end, he registered two patents through DTU. In 2015, Jesper Bevensee Jensen was contacted by Bo Pedersen, formerly with DTU Fotonik and the man behind several telecommunications and nanotechnology start-ups. After just ten minutes, Jesper decided to become an entrepreneur instead of a DTU researcher. The two men rented the office next door to Jesper’s and started the company with help of ‘proof of concept’ funding from DTU. Gradually, the project saw several experienced entrepreneurs join the team."</em> <a href="http://www.dtu.dk/english/news/nyhed?id=906d90fd-38b1-4174-96b0-88d2524ee7dd">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_EngineeringHighlyAdaptableRobo.jpg" alt="Engineering highly adaptable robots requires new tools for new rules" class="lefter"></p>

<h2><a href="https://www.nsf.gov/news/special_reports/science_nation/index.jsp">Engineering highly adaptable robots requires new tools for new rules</a></h2>

<p><em>"Northwestern University mechanical engineering professor Todd Murphey and his team are engineering robots that one might say could make robotic assistance as seamless as "humanly" possible. With support from the National Science Foundation (NSF), the team is using novel algorithmic tools, such as a drawing robot, to develop the algorithms, or rules of behavior, that would greatly enhance a robot's ability to adapt to human unpredictability. Murphey points out that in order for robots to help people, they have to have at least a basic understanding of the types of tasks people can do. Some tasks, like lifting and placing an object, are close to the types of tasks that robots already do. Other tasks, like drawing, are harder for robots, partly because there are so many ways to get the same image. As Murphey explains: "And so, drawing is a type of task that's maybe not the same as that sort of precision manufacturing task that we've seen robots do historically." Murphey sees many possibilities for robots that work alongside humans in everyday tasks, but one application his lab is focused on currently is physical therapy. The goal is to develop robots that can help patients not only move through the paces of their physical therapy without hurting themselves but allow them to complete movement tasks by creating mechanical environments to make this feasible. "Algorithms developed here will eventually run on physical therapy robots designed to help people with tasks like balance and feeding themselves," says Murphey. His collaborator, Julius P. Dewald, runs the Northwestern School of Medicine's Physical Therapy and Human Movement Sciences Department. Dewald has pioneered the use of robotics in stroke rehabilitation and sees great promise in Murphey's new approaches."</em> <a href="https://www.nsf.gov/news/special_reports/science_nation/index.jsp">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_BakingHackResistanceDirectlyIn.jpg" alt="Baking Hack Resistance Directly into Hardware" class="lefter"></p>

<h2><a href="https://www.darpa.mil/news-events/2017-04-10">Baking Hack Resistance Directly into Hardware</a></h2>

<p><em>"Military and civilian technological systems, from fighter aircraft to networked household appliances, are becoming ever more dependent upon software systems inherently vulnerable to electronic intruders. To meet its mission of preventing technological surprise and increasing national security, DARPA has advanced a number of technologies to make software more secure. But what if hardware could be recruited to do a bigger share of that work? That’s the question DARPA’s new System Security Integrated Through Hardware and Firmware (SSITH) program aims to answer. “Security for electronic systems has been left up to software until now, but the overall confidence in this approach is summed up in the sardonic description of this standard practice as ‘patch and pray,’” said SSITH program manager Linton Salmon of the Agency’s Microsystems Technology Office. “This race against ever more clever cyberintruders is never going to end if we keep designing our systems around gullible hardware that can be fooled in countless ways by software. The SSITH program will complement DARPA software security efforts like High-Assurance Cyber Military Systems (HACMS) and the Cyber Grand Challenge (CGC) by taking advantage of new technologies to develop integrated circuits that are inherently impervious to software end-runs.” Any software patch to a hardware-based security flaw—whether it is in a personal computer or a corporate or government information-technology system—merely salves a symptom without addressing the underlying hardware vulnerability. Left untouched, that same hardware weakness remains vulnerable to follow-on software-based breaches that members of the clever club might devise. “To break this cycle and thwart both today’s and tomorrow’s software attacks, the SSITH program challenges researchers to design security directly at the hardware architecture level,” said Salmon. “Instead of relying on software Band-Aids to hardware-based security issues, we are aiming to remove those hardware vulnerabilities in ways that will disarm a large proportion of today’s software attacks.” SSITH specifically seeks to address the seven classes of hardware vulnerabilities listed in the Common Weakness Enumeration (cwe.mitre.org), a crowd-sourced compendium of security issues that is familiar to the information technology security community. In cyberjargon, these classes are: permissions and privileges, buffer errors, resource management, information leakage, numeric errors, crypto errors, and code injection. Researchers have documented some 2800 software breaches that have taken advantage of one or more of these hardware vulnerabilities, all seven of which are variously present to in the integrated microcircuitry of electronic systems around the world. Remove those hardware weaknesses, Salmon said, and you would effectively close down more than 40% of the software doors intruders now have available to them."</em> <a href="https://www.darpa.mil/news-events/2017-04-10">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_NewTechniqueCouldBreakBarriers.jpg" alt="New technique could break barriers to making smaller microchips" class="lefter"></p>

<h2><a href="https://news.uchicago.edu/article/2017/04/12/new-technique-could-break-barriers-making-smaller-microchips">New technique could break barriers to making smaller microchips</a></h2>

<p><em>"For the chips in our computers and smartphones to get faster, their components—the circuits and wires through which signals flow—have to get smaller. The miniaturization of these wires has taken scientists on a journey almost to the atomic level. Recently, scientists have begun to address and surmount certain barriers in physics that have prevented them from making even smaller wires. In a recent study published in Nature Nanotechnology, a team of researchers from the Argonne National Laboratory, the University of Chicago and MIT has developed a new way to create some of the world’s thinnest wires, using a process that could enable mass manufacturing with standard types of equipment. Templated assembly, or directed self-assembly, represents an easier and more cost-effective way to make nanowires with widths below 10 nanometers, which is about 100 atoms thick. The self-assembling materials are large molecules known as block copolymers. These block copolymers are the two-headed beasts of the chemical world—one end is water-loving, the other end is water-hating. Upon heating, they spontaneously form highly uniform structures at the molecular scale. On their own, however, the block copolymers would form a pattern that looks like a fingerprint or a piece of brain coral—useless for the creation of functional nanowires. The key to changing that pattern to something more ordered is the use of the chemically patterned templates."</em> <a href="https://news.uchicago.edu/article/2017/04/12/new-technique-could-break-barriers-making-smaller-microchips">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_GroupWorksTowardDevisingNextGe.jpg" alt="Group works toward devising next-gen superconductor" class="lefter"></p>

<h2><a href="http://www.news.cornell.edu/stories/2017/04/group-works-toward-devising-next-gen-superconductor">Group works toward devising next-gen superconductor</a></h2>

<p><em>"The experimental realization of ultrathin graphene – which earned two scientists from the University of Manchester, U.K., the Nobel Prize in physics in 2010 – has ushered in a new age in materials research. What started with graphene has evolved to include numerous related single-atom-thick materials, which have unusual properties due to their ultra-thinness. Among them are transition metal dichalcogenides (TMDs), materials that offer several key features not available in graphene and are emerging as next-generation semiconductors. TMDs could realize topological superconductivity and thus provide a platform for quantum computing – the ultimate goal of a Cornell research group led by Eun-Ah Kim, associate professor of physics. “Our proposal is very realistic – that’s why it’s exciting,” Kim said of her group’s research. “We have a theoretical strategy to materialize a topological superconductor … and that will be a step toward building a quantum computer. The history of superconductivity over the last 100 years has been led by accidental discoveries. We have a proposal that’s sitting on firm principles. “Instead of hoping for a new material that has the properties you want,” she said, “let’s go after it with insight and design principle.”"</em> <a href="http://www.news.cornell.edu/stories/2017/04/group-works-toward-devising-next-gen-superconductor">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_ResearchersMakeTheFirstFlexibl.jpg" alt="Researchers Make the First Flexible Memory Device Using Oxide Ferroelectric Material" class="lefter"></p>

<h2><a href="https://news.ncsu.edu/2017/04/flexible-thin-film/">Researchers Make the First Flexible Memory Device Using Oxide Ferroelectric Material</a></h2>

<p><em>"For the first time, researchers have been able to deposit an ultra-thin oxide ferroelectric film onto a flexible polymer substrate. The research team used the flexible ferroelectric thin films to make non-volatile memory devices that are wearable and resilient. “Ferroelectric materials are capable of storing charge, which makes them ideal for non-volatile memory devices,” says Jacob Jones, a professor of materials science and engineering at North Carolina State University and co-author of a paper on the work. “But ferroelectric materials tend to be brittle, and normally have to be made at high temperatures – which would destroy most polymers. We’ve now found a way to make an extremely thin film of ferroelectric material that can be made at low temperatures.” “What is most exciting about this work is the ability to make ferroelectric thin films at low temperatures and integrate them with carbon-based organic semiconductors to make highly flexible memory devices,” says Franky So, the corresponding author of the paper and Walter and Ida Freeman Distinguished Professor of Materials Science and Engineering at NC State. “The key to success of this work is the special technique we developed to make these ferroelectric thin films at low temperature and maintain the flexibility,” says Hyeonggeun Yu, a postdoctoral researcher at NC State and lead author of the paper. “We have created a new device platform which can integrate these memory devices with other flexible electronic circuits.” “This advance allowed us to create a pliable ferroelectric that can be used to create stable memory storage units for use in energy-efficient electronic applications for use in everything from space exploration to defense applications,” says Ching-Chang Chung, a postdoctoral researcher at NC State and co-author of the paper. The researchers worked with hafnium oxide, or hafnia, a material that has ferroelectric properties when applied as a thin film. And, for the first time, the researchers were able to show that the flexible hafnia thin films exhibited ferroelectric properties with thicknesses ranging from 20 nanometers (nm) to 50 nm. “This is a milestone in nanotechnology,” So says."</em> <a href="https://news.ncsu.edu/2017/04/flexible-thin-film/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_HighResolutionImagingWithConve.jpg" alt="High-resolution imaging with conventional microscopes" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/high-resolution-imaging-conventional-microscopes-0417">High-resolution imaging with conventional microscopes</a></h2>

<p><em>"MIT researchers have developed a way to make extremely high-resolution images of tissue samples, at a fraction of the cost of other techniques that offer similar resolution. The new technique relies on expanding tissue before imaging it with a conventional light microscope. Two years ago, the MIT team showed that it was possible to expand tissue volumes 100-fold, resulting in an image resolution of about 60 nanometers. Now, the researchers have shown that expanding the tissue a second time before imaging can boost the resolution to about 25 nanometers. This level of resolution allows scientists to see, for example, the proteins that cluster together in complex patterns at brain synapses, helping neurons to communicate with each other. It could also help researchers to map neural circuits, says Ed Boyden, an associate professor of biological engineering and brain and cognitive sciences at MIT."</em> <a href="http://news.mit.edu/2017/high-resolution-imaging-conventional-microscopes-0417">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_LearnALanguageWhileYouWaitForW.jpg" alt="Learn a language while you wait for WiFi" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/learn-language-while-you-wait-for-wifi-0417">Learn a language while you wait for WiFi</a></h2>

<p><em>"Hyper-connectivity has changed the way we communicate, wait, and productively use our time. Even in a world of 5G wireless and “instant” messaging, there are countless moments throughout the day when we’re waiting for messages, texts, and Snapchats to refresh. But our frustrations with waiting a few extra seconds for our emails to push through doesn’t mean we have to simply stand by. To help us make the most of these “micro-moments,” researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a series of apps called “WaitSuite” that test you on vocabulary words during idle moments, like when you’re waiting for an instant message or for your phone to connect to WiFi. Building on micro-learning apps like Duolingo, WaitSuite aims to leverage moments when a person wouldn’t otherwise be doing anything — a practice that its developers call “wait-learning.”"</em> <a href="http://news.mit.edu/2017/learn-language-while-you-wait-for-wifi-0417">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_ScientistsDevelopMeansFor3DPri.jpg" alt="Scientists Develop Means for 3D Printing Extraterrestrial Materials" class="lefter"></p>

<h2><a href="https://3dprinting.com/news/scientists-develop-3d-printing-extraterrestrial-materials/">Scientists Develop Means for 3D Printing Extraterrestrial Materials</a></h2>

<p><em>"One of the major hurdles in the collective effort towards space exploration is the transport of tools and materials. Due to the weight and speed limitations necessary to exit the Earth’s atmosphere, scientists have had to stock spacecraft’s sparingly. Another consequence of this has been a need to decrease time spent on outer space voyages. One of the ways in which aerospace engineers and rocket scientists have been trying to mitigate these factors is 3D printing soil. By printing on location, astronauts may be able to diminish the issues related to weight and space. Researchers at Northwestern’s Mccormick school of engineering have developed a novel means of processing martian and lunar soil. This new method is an extension of 3D painting methods. As a result of 3D painting and inks the team can process functional and structural parts. This method is space travel friendly and cost-effective, as well as light weighted in terms of transport costs. Another benefit of this method is that it doesn’t require lasers or intense heat. The texture of the materials is composed of micro-rocks. Despite this, the material is quite flexible. The texture is quite similar to rubber in this regard. Compositionally, it is 90% dust, so it is quite light as well. The material itself can be folded and rolled. As of right now, the team is working on a means of solidifying the material and creating harder structures from it. They theorise that the use of a furnace may potentially let them achieve this."</em> <a href="https://3dprinting.com/news/scientists-develop-3d-printing-extraterrestrial-materials/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_ColumbiaEngineersInventMethodT.jpg" alt="Columbia Engineers Invent Method to Control Light Propagation in Waveguides" class="lefter"></p>

<h2><a href="http://engineering.columbia.edu/news/nanfang-yu-light-propagation-waveguides">Columbia Engineers Invent Method to Control Light Propagation in Waveguides</a></h2>

<p><em>"A team of Columbia Engineering researchers, led by Applied Physics Assistant Professor Nanfang Yu, has invented a method to control light propagating in confined pathways, or waveguides, with high efficiency by using nano-antennas. To demonstrate this technique, they built photonic integrated devices that not only had record-small footprints but were also able to maintain optimal performance over an unprecedented broad wavelength range. Photonic integrated circuits (ICs) are based on light propagating in optical waveguides, and controlling such light propagation is a central issue in building these chips, which use light instead of electrons to transport data. Yu’s method could lead to faster, more powerful, and more efficient optical chips, which in turn could transform optical communications and optical signal processing. The study is published online in Nature Nanotechnology April 17."</em> <a href="http://engineering.columbia.edu/news/nanfang-yu-light-propagation-waveguides">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_ExplainedNeuralNetworks.jpg" alt="Explained: Neural Networks" class="lefter"></p>

<h2><a href="http://www.csail.mit.edu/explained_neural_networks">Explained: Neural Networks</a></h2>

<p><em>"In the past 10 years, the best-performing artificial-intelligence systems — such as the speech recognizers on smartphones or Google’s latest automatic translator — have resulted from a technique called “deep learning.” Deep learning is in fact a new name for an approach to artificial intelligence called neural networks, which have been going in and out of fashion for more than 70 years. Neural networks were first proposed in 1944 by Warren McCullough and Walter Pitts, two University of Chicago researchers who moved to MIT in 1952 as founding members of what’s sometimes called the first cognitive science department. Neural nets were a major area of research in both neuroscience and computer science until 1969, when, according to computer science lore, they were killed off by the MIT mathematicians Marvin Minsky and Seymour Papert, who a year later would become co-directors of the new MIT Artificial Intelligence Laboratory. The technique then enjoyed a resurgence in the 1980s, fell into eclipse again in the first decade of the new century, and has returned like gangbusters in the second, fueled largely by the increased processing power of graphics chips."</em> <a href="http://www.csail.mit.edu/explained_neural_networks">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_ProfJungKimAndProfInkyuParkDev.jpg" alt="Prof. Jung Kim and Prof. Inkyu Park developed a tactile sensor that can act as a skin for a robot" class="lefter"></p>

<h2><a href="http://me.kaist.ac.kr/mekaist-en/?p=102533">Prof. Jung Kim and Prof. Inkyu Park developed a tactile sensor that can act as a skin for a robot</a></h2>

<p><em>"A joint research team of Prof. Jung Kim and Prof. Inkyu Park of ME department, KAIST has developed a tactile sensor that can act as a skin for a robot using silicon and carbon materials. This technology is able to distinguish various types of tactile sensations while being capable of shock absorption, and is expected to be used as a skin for a robot in the future. The results of this research, which Dr. Hyosang Lee participated as the 1st author, were published online in the January 25 issue of Nature’s sister journal, Scientific Report. Skin is the organ that occupies the most part in the human body. It protects major organs from external impacts and measures and divides sensitive tactile information and transmits it to the nervous system. Currently, robotic sensory technology is close to human ability in visual and auditory areas, but in the case of tactile senses, it is much inferior to skin ability to detect environmental changes in the whole body. In order to apply human-like skin to robots, it is essential to develop skin sensor technology that absorbs shocks with high elasticity. The technology of connecting many sensors distributed throughout the body through electrical wiring is also a problem to be solved. The team combined silicone elastomer and carbon nanotubes (CNTs) to create a composite material, and combined it with a medical imaging technique called electrical impedance tomography (EIT). This has led to the development of technologies that can distinguish various types of forces applied to a large area without electrical wiring. The robot skin developed through this can withstand the strong impact of the level hit by the hammer. Even if part of the sensor is damaged, it can be reused by filling the damaged part with the composite material and hardening it. It can also be fabricated by filling silicone-nanotube composite material into a 3D shaped frame made of 3D printer. It is possible to create a new type of computer interface by making various 3D curved surfaces as well as existing 2D flat plates. This technology is expected to be applicable to the skin of a robot capable of absorbing shocks, a three-dimensional computer interface, and a tactile sensor, which can tactically distinguish other positions and sizes. In particular, the research was conducted jointly by Prof. Inkyu Park, an expert in nanostructures and sensors, and Prof. Jung Kim, an expert in bio-robotics. Prof. Kim said, “Flexible tactile sensors can be attached directly to the human body and can provide information on multidimensional deformation states. We will contribute to the field of soft robot industry including robotic skin and wearable medical devices.” Prof. Inkyu Park said, “The fusion of functional nanocomposites and computed tomography has enabled the next generation user interface.” This research was carried out through the collaboration of the first author Dr. Hyosang Lee, Mr. Dongwuk Kwon, and Mr. Jiseung Cho, and supported by National Research Foundation of Korea."</em> <a href="http://me.kaist.ac.kr/mekaist-en/?p=102533">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_MarineScientistsUsingDronesFor.jpg" alt="Marine scientists using drones for measurements" class="lefter"></p>

<h2><a href="http://www.geomar.de/en/news/article/drohneneinsatz-in-der-meeresforschung/">Marine scientists using drones for measurements</a></h2>

<p><em>"For the first time a team of scientists from GEOMAR Helmholtz Center for Ocean Research Kiel has successfully used a drone to collect marine air and water samples. The objective of the study is to better understand the role of coastal waters as a source of reactive trace gases, which are important for chemical processes in the atmosphere and the climate. The project "LASSO" is funded by the Kiel Cluster of Excellence "The Future Ocean". Unmanned aerial vehicles, so-called drones, are used not only for the production of photos and videos but increasingly for more complex tasks. These mobile platforms are increasingly used in research as well. A team of scientists from GEOMAR Helmholtz Center for Ocean Research Kiel has now for the first time used a medium-sized drone for the collection of air and water samples in the area of the surf zone. The project is funded by the Kiel Cluster of Excellence “The Future Ocean”. At the beginning of April, a DJI Matrice 600 drone was used to take samples on the west coast of the island of Sylt. “We had very variable weather conditions with wind speeds of more than 10 m/s, where the drone proved to be very good”, explains the project manager Dr. Birgit Quack from GEOMAR. “On the first mild day, a stroller asked if it wouldn’t be easier to do this is summer with a swimmer. On the following stormy days with high surf waves no one asked again, in fact except for us, almost nobody was there”, Dr. Quack remarks."</em> <a href="http://www.geomar.de/en/news/article/drohneneinsatz-in-der-meeresforschung/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_AOnceForgottenElementHoldsProm.jpg" alt="A once forgotten element holds promise for the future of electronics" class="lefter"></p>

<h2><a href="http://news.yale.edu/2017/04/19/once-forgotten-element-holds-promise-future-electronics">A once forgotten element holds promise for the future of electronics</a></h2>

<p><em>"Discovered more than 100 years ago, black phosphorus was soon forgotten when there was no apparent use for it. In what may prove to be one of the great comeback stories of electrical engineering, it now stands to play a crucial role in the future of electronic and optoelectronic devices. With a research team’s recent discovery, the material could possibly replace silicon as the primary material for electronics. The team’s research, led by Fengnian Xia, Yale’s Barton L. Weller Associate Professor in Engineering and Science, is published in the journal Nature Communications April 19. With silicon as a semiconductor, the quest for ever-smaller electronic devices could soon reach its limit. With a thickness of just a few atomic layers, however, black phosphorus could usher in a new generation of smaller devices, flexible electronics, and faster transistors, say the researchers. That’s due to two key properties. One is that black phosphorus has a higher mobility than silicon — that is, the speed at which it can carry an electrical charge. The other is that it has a bandgap, which gives a material the ability to act as a switch; it can turn on and off in the presence of an electric field and act as a semiconductor. Graphene, another material that has generated great interest in recent years, has a very high mobility, but it has no bandgap. However, finding a way to control the bandgap of black phosphorus is critical to realizing its potential applications. To that end, the researchers have discovered that the material’s bandgap is most controllable at a certain thickness. By applying a vertical electric field to the material at that thickness, the researchers can “tune” the bandgap, essentially shrinking the moderate gap to the point where it nearly closes. That opens up many potential applications for black phosphorus, such as imaging tools, night vision devices, mid-infrared optical modulators, on-chip spectroscopy tools, and other optoelectronic technologies."</em> <a href="http://news.yale.edu/2017/04/19/once-forgotten-element-holds-promise-future-electronics">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT103_ResearchersWorkingTowardIndoor.jpg" alt="Researchers working toward indoor location detection" class="lefter"></p>

<h2><a href="http://news.rice.edu/2017/04/17/researchers-working-toward-indoor-location-detection/">Researchers working toward indoor location detection</a></h2>

<p><em>"Rice University computer scientists are mapping a new solution for interior navigational location detection by linking it to existing sensors in mobile devices. Their results were presented in a paper at last month’s 2017 Design, Automation and Test in Europe (DATE) Conference in Lausanne, Switzerland. Six months ago, the same researchers published a paper on their first technology for a new indoor mobile positioning system called CaPSuLe. The navigational location detection system began as a solution for mobile device users inside large indoor spaces like office complexes or shopping malls where GPS navigation falters under poor signals that quickly deplete battery life. Both CaPSuLe and the DATE paper technology rely on machine learning for location detection. Both increase the speed of calculations and decrease energy expenditure in comparison with existing location technologies. But CaPSuLe depends on image matching techniques and uploaded data, while the new technology taps into sensors that already exist in most mobile devices. Chen Luo, a graduate student working with assistant professor of computer science Anshumali Shrivastava, said the team was not satisfied with the initial performance metrics of its sensor-driven technology."</em> <a href="http://news.rice.edu/2017/04/17/researchers-working-toward-indoor-location-detection/">[...]</a>
 </SPAN></DIV></p>

<h1 id="Modelos-3D">Modelos 3D</h1>

<p>Com a disponibilidade de ferramentas que permitem dar azo a nossa imaginação na criação de peças 3D e espaços como o <a href="http://www.thingiverse.com/">thingiverse</a> para as publicar, esta rubrica apresenta alguns modelos selecionados que poderão ser úteis.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="MP103_CustomizableStackableBoxSystem.jpg" alt="Customizable Stackable Box System" class="lefter"></p>

<h2><a href="http://www.thingiverse.com/thing:2177853">Customizable Stackable Box System</a></h2>

<p><em>"Taking advantage of the generator of trays that I uploaded previously I have created a stackable and customizable system that allows to use any container for the trays and to be able to extract them easily with a flap to be able to lift them all at the same time. It is a way to take advantage of the tuppers that we have without use but we can use them to keep small things but really it can be to generate trays for any container."</em> <a href="http://www.thingiverse.com/thing:2177853">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="MP103_MoabMotherOfAllFanBrackets.jpg" alt="MOAB - MOther of All fan Brackets" class="lefter"></p>

<h2><a href="http://www.thingiverse.com/thing:166045">MOAB - MOther of All fan Brackets</a></h2>

<p><em>"An easy way to generate brackets to attach any fan to any PCB board. A list of pre-defined brackets included. The script was initially meant to generate fan brackets for the RAMPS board but I decided to make it fully customizable: it now allows you to create brackets that take fans of any size, snap onto PCB of any size, can have any height, but probably best of all features is that you can generate both mini-brackets (2 holes) as well as full brackets (4 holes, fully enclosed on two sides), to balance between saving plastic vs. rigidity and improved air flow. While this was meant for PCBs, feel free to experiment it could probably be used for many other scenarios, for example to attach a fan to a NEMA17 motor or to space two PCBs by attaching brackets back to back, etc."</em> <a href="http://www.thingiverse.com/thing:166045">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="MP103_FourWhistlesVersion2.jpg" alt="Four Whistles Version 2" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Four-Whistles-Version-2/">Four Whistles Version 2</a></h2>

<p><em>"Four Whistles Version 2 is my first attempt at a "calliope" (well, sort of calliope) design utilizing the primitive knowledge I gained from the original Four Whistles Instructable (https://www.instructables.com/id/Four-Whistles/). Not being a musician and being "slightly more than hard" at hearing, while it may not sound like it this model is attempting to play "Mary Had A Little Lamb" using a balloon to power the whistles and a hand crank to power a cylindrical sequencer. In order to play "Mary Had A Little Lamb", I incorporated four whistles in the design of this model, each controlled by one of four air valves. Each of the air valves are controlled by a rotating cylinder containing small 2.5mm "bumps" that activate the valves in the correct sequence (the "cylinder sequencer"). In order to minimize air loss and maximize play time, I designed the valves with a 3 degree preload (to increase the compression of the valve gaskets on the valve body valve plates), designed the valve "axles" using a virtually airtight membrane with torsion bars, and as a last defense against air leaks, used clear silicon caulk to seal the valve body assembly (see below). The caulk is not necessary, but will assist in producing a marked improvement in the models performance. In order to complete this model, you will need to purchase a "punch balloon", one roll of .7mm thick rubber electrical tape (you will only need 3 inches or so, I used Scotch 2242), a bottle of "thick" cyanoacrylate glue and a small tube of clear silicone or acrylic caulk. I also used scissors, a single bevel razor blade, a modeling knife, a needle file set, a small slip joint plier, a jewelers screwdriver set, a rubber mallet and a vise for assembly. And as usual, I probably forgot a file or two or who knows what else, so if you have any questions, please do not hesitate to ask as I do make mistakes in plenty. Designed using Autodesk Fusion 360, sliced using Cura 2.3.1, and printed in PLA on an Ultimaker 2+ Extended and an Ultimaker 3 Extended."</em> <a href="http://www.instructables.com/id/Four-Whistles-Version-2/">[...]</a>
 </SPAN></DIV></p>

<h1 id="Projetos-Maker">Projetos Maker</h1>

<p>Diversos Projetos interessantes.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ArduinoAddonsBatteryLevelIndic.jpg" alt="Arduino Addons : Battery Level Indicator" class="lefter"></p>

<h2><a href="https://www.hackster.io/thearduinoworld/arduino-addons-battery-level-indicator-756b76">Arduino Addons : Battery Level Indicator</a></h2>

<p><em>"Several Times I Had Wished I Have a Battery Indicator In My Project That Is Powered By Battery But It Uses So Many Custom Characters In the LCD And Sacrifice Analog Input For Voltage Indication And Components And Connections , So We Decided To Do That The Smart Way And Push The Arduino To Its Limits "As We Always Do" And Get The Maximum Out Of It. In This Project We Use Only One Custom Character From The LCD So You Still Have Seven Free Custom Characters to Use In Your Project And We Also Used The Trick Of Reff Voltage to Get The Input Voltage From The Arduino Without Using Any Analog Inputs Or Components , Looks Like The Complete Package. All You Have To Is Add the function That displays The Indicator In The Loop Function And Add The Place Where You Wanted To Display It And You are Ready To Have It ."</em> <a href="https://www.hackster.io/thearduinoworld/arduino-addons-battery-level-indicator-756b76">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_3DPrintedPrankVibratingCup.jpg" alt="3D-Printed Prank Vibrating Cup" class="lefter"></p>

<h2><a href="https://www.hackster.io/AlexWulff/3d-printed-prank-vibrating-cup-033e3b">3D-Printed Prank Vibrating Cup</a></h2>

<p><em>"Picture the following: you have an nice white cup in front of you. It's filled to the brim with sparkling, cool, and refreshing H20. Your fingers curl around the nicely curved handle, and you bring the cup to your lips. Suddenly, a strong vibration assaults the nerves in your hand, causing you to drop the cup and spill water all over every surrounding surface, including yourself. This might not sound too fun for the participant, but I can personally guarantee you that it will elicit much more than a chuckle from any bystanders. Let's get started making it!"</em> <a href="https://www.hackster.io/AlexWulff/3d-printed-prank-vibrating-cup-033e3b">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_EnglishPronunciationTrainingMa.jpg" alt="English Pronunciation Training Machine" class="lefter"></p>

<h2><a href="https://www.hackster.io/H0meMadeGarbage/english-pronunciation-training-machine-7e0859">English Pronunciation Training Machine</a></h2>

<p><em>"I made Pronunciation Training Machine using Google Speech API. Because it is difficult for the Japanese to distinguish "L" and "R" pronunciations. If you talk to the USB microphone connected to the Raspberry Pi by speaking to "right" or "light" and recognize it correctly, the servo motor points to the right when "right" and the LED lights if it is "light"."</em> <a href="https://www.hackster.io/H0meMadeGarbage/english-pronunciation-training-machine-7e0859">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_8X8MatrixLedSnakeGameHtml5WebS.jpg" alt="8X8 matrix LED Snake game (HTML5 web socket)" class="lefter"></p>

<h2><a href="https://www.hackster.io/hmkim/8x8-matrix-led-snake-game-html5-web-socket-67e679">8X8 matrix LED Snake game (HTML5 web socket)</a></h2>

<p><em>"I added a web page to PHPoC Shield for Arduino(P4S-347/348) to control a snake on the 8X8 Matrix LED. If a user presses one of direction buttons, the direction value is sent to Arduino through HTML5 Web socket. Then the snake changes its direction. For someone who doesn't know about the Snake game. I will introduce rule of this game. The snake moves to have a fruit. Whenever the snake eats a fruit, it gets longer. If the snake bites itself, the game is over. but if it eats 15 fruits, the user wins the game."</em> <a href="https://www.hackster.io/hmkim/8x8-matrix-led-snake-game-html5-web-socket-67e679">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ArduinoGadgetsYoutubeSubscribe.jpg" alt="Arduino Gadgets : Youtube Subscribers Counter" class="lefter"></p>

<h2><a href="https://www.hackster.io/thearduinoworld/arduino-gadgets-youtube-subscribers-counter-49f125">Arduino Gadgets : Youtube Subscribers Counter</a></h2>

<p><em>"As A New YouTuber I Am Always Opening My channel To Check How Many Subscribers Now , So I Thought Why Not Create A Gadget That Is Always Keeping Tracking Of How Many Subscribers I Have , And I Did That , With Small Software I Have Created It Can Sync The Subscribers Every 1 Min To Give You A Live Feed Of How Many Subscribers In Your Channel."</em> <a href="https://www.hackster.io/thearduinoworld/arduino-gadgets-youtube-subscribers-counter-49f125">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ArtificialIntelligenceWithArdu.jpg" alt="Artificial Intelligence With Arduino" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Artificial-Intelligence-With-Arduino/">Artificial Intelligence With Arduino</a></h2>

<p><em>"This robot was mainly built for understanding artificial intelligence with Arduino. And who doesn't want to have a pet robot? I could have bought a beautiful tracked chassis but making it from scratch teaches you more and gives you more pride. The robot is capable of, obstacle avoidance, voice control, chatting with humans, Bluetooth control as well as gesture control. It is mainly based on Android functions such as accelerometer, voice recognition and Bluetooth."</em> <a href="http://www.instructables.com/id/Artificial-Intelligence-With-Arduino/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_MakeYourOwnSpirometer.jpg" alt="Make Your Own Spirometer" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Make-Your-Own-Spirometer/">Make Your Own Spirometer</a></h2>

<p><em>"The following are instructions on how to build your very own spirometer!! We had to build this for an engineering class at my university. Our project uses a pressure transducer, arduino, and a switch to compute the change in breath volume through a tube with two different diameters. We used a simple circuit in order to cut down on possible complications."</em> <a href="http://www.instructables.com/id/Make-Your-Own-Spirometer/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_SmartGameBoard.jpg" alt="Smart game board" class="lefter"></p>

<h2><a href="http://www.bogdanberg.com/2017/04/08/smart-game-board-checkers-chess/">Smart game board</a></h2>

<p><em>"The idea for this project was born from a conversation with a friend – he was wondering if creating such game board could help in teaching kids how to play Chess. And I loved the fact that both making the project, as well as then playing using it sound fun 😉 And what a great opportunity to try out some new things that I didn’t have experience with before (i.e. PCB design)."</em> <a href="http://www.bogdanberg.com/2017/04/08/smart-game-board-checkers-chess/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_AutonomousRcCarWallE.jpg" alt="Autonomous RC Car (Wall-E)" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Autonomous-RC-Car-Wall-E/">Autonomous RC Car (Wall-E)</a></h2>

<p><em>"We have created this page as part of our final project in Robotics at Mount Royal University. My partner and I will go through instructions on how to create your very own Autonomous RC Car from Scratch. We will provide all the steps and code necessary."</em> <a href="http://www.instructables.com/id/Autonomous-RC-Car-Wall-E/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_MightywattRevision3BrandNewAnd.jpg" alt="MightyWatt Revision 3: Brand New and Seriously Improved" class="lefter"></p>

<h2><a href="http://kaktuscircuits.blogspot.pt/2017/03/mightywatt-revision-3-brand-new-and.html">MightyWatt Revision 3: Brand New and Seriously Improved</a></h2>

<p><em>"I have developed a new version of MightyWatt, the R3! It looks almost the same on the outside but is very different on the inside. It addresses shortcomings of the revision 2 and adds some new functions. But first, what is MightyWatt R3 (skip to Hardware changes if you already know…): MightyWatt R3 is a programmable electronic load. That means you can use it for testing batteries, power supplies, fuel cells, solar cells and other sources of electrical power. You can also make a programmable power supply from a fixed-voltage power supply and MightyWatt R3 and use it for example as an intelligent battery charger. MightyWatt R3 is made as an Arduino shield. Simply put it on an Arduino, upload the control sketch, open Windows control program and you are ready to go. In its heart, MightyWatt R3 has a special FET designed for linear operation that acts as a programmable resistor. It is controlled by an analog feedback loop that is able to keep either constant current or constant voltage (constant power and resistance is kept by a software loop). The current or voltage is set using a DAC, the actual voltage and current is read by an ADC so MightyWatt R3 has an integrated ammeter and voltmeter, both of which have two ranges with very fast autoranging. For the voltage measurement to be as precise as possible, MightyWatt R3 offers 4-wire (Kelvin) measurement where voltage is sensed by a dedicated pair of connections. This removes the effect of cable resistance from the measured value. It is of course possible to measure the voltage at the input terminals too (2-wire measurement). The power is dissipated in a force-cooled heatsink that is able to, with its fan, dissipate up to 70 Watts continuously. Current range is up to 24A and voltage up to 30V. MightyWatt R3 is 100% open source – hardware, firmware, software – so you can make your own one."</em> <a href="http://kaktuscircuits.blogspot.pt/2017/03/mightywatt-revision-3-brand-new-and.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ArduinoMenuOnANokia5110LcdUsin.jpg" alt="Arduino Menu on a Nokia 5110 Lcd Using a Rotary Encoder" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Menu-on-a-Nokia-5110-Lcd-Using-a-Rotary-En/">Arduino Menu on a Nokia 5110 Lcd Using a Rotary Encoder</a></h2>

<p><em>"Dear friends welcome to another tutorial! In this video we are going learn how to build ourown menu for the popular Nokia 5110 LCD display, in order to make our projects more user friendly and more capable. Let’s get started! This is the project we are going to build. In the display a simple menu appears, and with the help of the rotary encoder I can navigate up, or down and select a menu item by pressing the rotary encoder button. When the middle button of the rotary encoder is pressed, another screen appears and we can change the value of a variable. If we press the rotary encoder button once more, we go back to the main menu screen. The menu has 6 items, and we can scroll down or up the menu and the items on the display will change accordingly. Watch the attached video to see exactly how this menu works. Of course you can modify it to build your own more complex menus if you wish. Let’s now see how to build this project."</em> <a href="http://www.instructables.com/id/Arduino-Menu-on-a-Nokia-5110-Lcd-Using-a-Rotary-En/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_AnElectronicLedRouletteYouCanS.jpg" alt="An Electronic LED Roulette you can self build" class="lefter"></p>

<h2><a href="https://www.open-electronics.org/an-electronic-led-roulette-you-can-self-build/">An Electronic LED Roulette you can self build</a></h2>

<p><em>"Let’s call back an electronic version of one of the most famous casino games: no tricks and no cheats… The “roulette” is without a doubt one of the most famous and practiced casino games in the word, and it is surely one of the most widely employed, along with poker, in famous movies from all genres: from Westerns to police movies, from spy stories to comedy. Among the various versions available in the world, known as French roulette, English roulette and American roulette, we took inspiration from the first one, which is definitely the most famous; the main difference amongst various versions mainly focuses on the presence of the double “0” or lack thereof and on the disposition of black and white numbers. Obviously, we couldn’t but present an electronic interpretation of our roulette, therefore we thought about how to design a circuit capable of reproducing the rotating movement of the ball thanks to the sequential lightning of a set number of LEDs. In the solution we designed and that we are going to describe in the following paragraphs, the ball’s circular movement can be obtained by piloting 37 colored LEDs in an appropriate manner and the final number can be outputted through unilateral lighting of one of those LEDs."</em> <a href="https://www.open-electronics.org/an-electronic-led-roulette-you-can-self-build/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_FpgaBasedHeartDiseasesDetector.jpg" alt="FPGA Based Heart Diseases Detector" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/FPGA-Based-Heart-Diseases-Detector/">FPGA Based Heart Diseases Detector</a></h2>

<p><em>"This tutorial shows a way of designing a Heart Diseases Detector using Nexys Video board. This project combines electronics and medicine in order to obtain a product that detects hearth diseases. The results of this project don't compare with an examination and therefore the resuls cannot be considered valid - this is a project made for a contest and not for medical purposes. The aim of the project is to compare signals from MIT-BIT database with the signals acquired from the patients and returns a response to the tested person."</em> <a href="http://www.instructables.com/id/FPGA-Based-Heart-Diseases-Detector/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_UltrasonicSensoryDeviceForTheV.jpg" alt="Ultrasonic Sensory Device for the Visually Impaired" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Ultrasonic-Sensory-Device-for-the-Visually-Impaire/">Ultrasonic Sensory Device for the Visually Impaired</a></h2>

<p><em>"This project was done as a final exam for a college class. Both my lab partner, Chris and myself spent several weeks on this project and we're fairly happy with the results. The idea behind this project is to assist the visually impaired with getting around without the need for a big long cane that just gets in the way. This device is compact and still allows the user to have use of their hands and without having to fold up and stow away a cane. This instructable will teach you how to create a device that uses an ultrasonic sensor to detect the distance of objects, and based on that distance, give an output of your desired intensity of vibration to help the user "feel" their surroundings using vibrations. This project is fairly complicated and requires some background in circuitry, soldering, and coding."</em> <a href="http://www.instructables.com/id/Ultrasonic-Sensory-Device-for-the-Visually-Impaire/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_BinaryKeyboard.jpg" alt="Binary Keyboard" class="lefter"></p>

<h2><a href="https://github.com/Chris-Johnston/BinaryKeyboard">Binary Keyboard</a></h2>

<p><em>"A two-button backlit mechanical keyboard that types ASCII values, one bit at a time."</em> <a href="https://github.com/Chris-Johnston/BinaryKeyboard">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ElectronicPaperRockScissorsGam.jpg" alt="Electronic Paper Rock Scissors Game" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Electronic-Paper-Rock-Scissors-Game/">Electronic Paper Rock Scissors Game</a></h2>

<p><em>"Paper, Rock, Scissors is an old, simple game. Basically each player takes turns to make a shape with their hands and depending on the combination one player wins each round. A more detailed description of the game can be found here. The game is usually played between two people with no equipment but this instructable shows you how to modernize the game and automate the reading and scoring of rounds with gloves that sense the shapes!!"</em> <a href="http://www.instructables.com/id/Electronic-Paper-Rock-Scissors-Game/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_RaspberryPiZeroHdmiWifiSolderi.jpg" alt="Raspberry Pi Zero HDMI / WiFi Soldering Microscope" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Raspberry-Pi-Zero-HDMIWiFi-Soldering-Microscope/">Raspberry Pi Zero HDMI / WiFi Soldering Microscope</a></h2>

<p><em>"Soldering SMD components can sometimes be a bit of a challenge, especially when it comes to things like 0.4mm pin pitch TQFP chips with 100 or more pins. In such cases, having access to some kind of magnification could be really helpful. In an attempt to address this issue, I decided to build my own soldering microscope based on a Raspberry Pi Zero W and a camera module. The microscope is capable of streaming Full HD video directly to an HDMI monitor with practically no latency, which is perfect for soldering. But also over WiFi with a latency of less than half a second, which is pretty good for board inspection. Optionally, with a bit of an extra cost the microscope can also be made portable, which combined with its WiFi video streaming capabilities opens up an extra dimension of potential use cases."</em> <a href="http://www.instructables.com/id/Raspberry-Pi-Zero-HDMIWiFi-Soldering-Microscope/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_PowerAndTemperatureDataLoggerW.jpg" alt="Power and Temperature Data Logger With ESP32 and AWS IOT" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Power-and-Temperature-Data-Logger-With-ESP32-and-A/">Power and Temperature Data Logger With ESP32 and AWS IOT</a></h2>

<p><em>"In this tutorial we will see how to build a simple IOT Industrial Data Logger(IDL) to log the device temperature and current to AWS IOT and display it on Hornbill IO. The IDL connects to Wi-Fi and then to the clould. We will be using the MAX6675 for measuring the temperature and Non-invasive YHDC SCT-013-050 AC current sensor to measure electric energy consumed. The measured temperature and current along with power is logged to server using Hornbill AWS IOT library. This data could later be used to determine device specific events like operating duration, total power consumption etc., Combing this with the device temperature can be useful in understanding operating health of the machine. We have attached Hornbill Industrial Data Logger to a bench top drill machine, you may add it any machine where power and temperature measurements can result in useful insights."</em> <a href="http://www.instructables.com/id/Power-and-Temperature-Data-Logger-With-ESP32-and-A/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ArduinoDroneQuadcopter3DPrinte.jpg" alt="Arduino Drone | Quadcopter (3D Printed)" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Drone-Quadcopter-3D-Printed/">Arduino Drone | Quadcopter (3D Printed)</a></h2>

<p><em>"Some time ago (over 8 months) I was thinking about what I can build. I wanted to make an interesting robot/device that will be challenge for me and will encourage me to learn new things. I thought about the lot of robots but a lot of them were posted on the internet. And i thought about making a drone completly by myself, including flight controller, pilot, program and frame design. This is by far the longest build i have made, it takes a lot of time and effort to make it but finaly after over 8 months it's ready and i am here to share it with you as completly open source project."</em> <a href="http://www.instructables.com/id/Arduino-Drone-Quadcopter-3D-Printed/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_AdvancedAdjustableDualModeDcVo.jpg" alt="Advanced Adjustable Dual Mode DC Voltage Regulator" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Advanced-Adjustable-Dual-Mode-DC-Voltage-Regulator/">Advanced Adjustable Dual Mode DC Voltage Regulator</a></h2>

<p><em>"Got projects to work on and don't have a voltage regulator? Here a simple yet efficient DC voltage regulator. Its simple in design, yet efficient in output, but still cheap for your pocket. Key features; Adjustable positive DC voltage regulator for all most powering up any circuits; Adjustable negative DC voltage regulator for op-amps &amp; amplifiers. A USB fast charger for your phone; A USB port to power up your microcontrollers Arduino etc. This is my first instructable, so there might be a lot of missing here and there. Just let me know about it what's missing and I'll update."</em> <a href="http://www.instructables.com/id/Advanced-Adjustable-Dual-Mode-DC-Voltage-Regulator/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_AnimationsWithArduinoUnoAndNok.jpg" alt="Animations with Arduino Uno and Nokia 3310 LCD" class="lefter"></p>

<h2><a href="https://www.hackster.io/guillengap/animations-with-arduino-uno-and-nokia-3310-lcd-9c36ff">Animations with Arduino Uno and Nokia 3310 LCD</a></h2>

<p><em>"The main goal is to make animations and using Arduino UNO board and a NOKIA 3310 LCD."</em> <a href="https://www.hackster.io/guillengap/animations-with-arduino-uno-and-nokia-3310-lcd-9c36ff">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_EnginursdayI2Considerations.jpg" alt="Enginursday: I2Considerations" class="lefter"></p>

<h2><a href="https://www.sparkfun.com/news/2366">Enginursday: I2Considerations</a></h2>

<p><em>"When it comes to microcontrollers, it’s easy to run out of IO pins before you run out of programming space. Back in 1982, NXP Semiconductor (formerly known as Philips Semiconductor) came up with a solution called Inter-Integrated Circuit, or I2C. With this technology, designers are able to connect up to 127 devices using just two pins for clock and data. I2C not only frees up I/O pins but also maintains the measurement from the source to the device reading the measurement. With analog outputs, the output is susceptible to noise, which will need to be filtered through hardware or software. Because I2C is digital, noise can often be ignored, but that doesn’t mean it’s problem free, and there are design considerations that need be addressed — no pun intended."</em> <a href="https://www.sparkfun.com/news/2366">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_HowToBuildABb8Robot.jpg" alt="How to Build a BB-8 Robot" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/How-to-Build-a-BB-8-Robot/">How to Build a BB-8 Robot</a></h2>

<p><em>"That’s right, the robot I teach you to make this time is the BB-8 in the Star Wars: The Force Awakens. Ever since the first official trailer was released in October, the adorable BB-8 in its peculiar design has attracted a large number of fans and its popularity is comparable to some main characters. Of course, it itself is a leading character who played many parts in the film. At the world premiere in Los Angeles, BB-8 also‘rolled over’red carpet as one of the major characters."</em> <a href="http://www.instructables.com/id/How-to-Build-a-BB-8-Robot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_RetroElectronicsDiyResistorTra.jpg" alt="Retro Electronics: DIY Resistor-Transistor Logic Gates" class="lefter"></p>

<h2><a href="https://diyhacking.com/diy-resistor-transistor-logic-gates/">Retro Electronics: DIY Resistor-Transistor Logic Gates</a></h2>

<p><em>"We all love our modern devices ranging from smartphones to smart cars and all of it is made possible thanks to the transistor! The technology we use has only been around for a few decades, so how did engineers in the past create complex digital circuits? This also brings up the question “how did NASA build a computer that was small enough to fit on the Apollo modules?” The answer lies in RTL which stands for resistor-transistor logic which for a while was one of the most popular logic families."</em> <a href="https://diyhacking.com/diy-resistor-transistor-logic-gates/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_MachineToMachineTalkUsingEsp82.jpg" alt="Machine to Machine Talk Using ESP8266" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Machine-to-Machine-Talk-Using-ESP8266/">Machine to Machine Talk Using ESP8266</a></h2>

<p><em>"Machine to Machine talk is a subpart of IoT(Internet Of Things) in which a machine gives a command or signal to another machine for doing some task.And in this article, I’ll be teaching you how you can make a simple yet useful project on M2M technology using you very own ESP8266 01 module."</em> <a href="http://www.instructables.com/id/Machine-to-Machine-Talk-Using-ESP8266/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ArduinoFlexSensorGlove.jpg" alt="Arduino Flex Sensor Glove" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Flex-Sensor-Glove/">Arduino Flex Sensor Glove</a></h2>

<p><em>"Created by: Jonathan Cates, Nobufumi Takahashi, and Ryan Barton for Mount Royal University's COMP 3012 Robotics course. This tutorial will teach how to make a glove with 5 flex sensors, so that when you bend your fingers a RGB light will light up, according to which finger you bent. This glove can be used to control various other things as well with some slight modifications!"</em> <a href="http://www.instructables.com/id/Arduino-Flex-Sensor-Glove/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_PabloOdysseus.jpg" alt="Pablo Odysseus" class="lefter"></p>

<h2><a href="https://hackaday.io/project/20884-pablo-odysseus">Pablo Odysseus</a></h2>

<p><em>"I love the beach. I can stay for a long time to contemplate the waves, the sun, the ocean ... I want to create a surprise for the morning walkers who discover on the beach very large drawings of animals, portraits, texts ...  The drawings are fading, they are effaced by the tide.  : What's the point? A: What is art used for?  Before departure, the mission of the rover is prepared in advance by placing the image to be drawn on a map. Once on the spot, the robot aims to trace the path on the sand with the help of the map, a GNSS receiver and sensors like compass and odometer. The rover don't need any hardware tags that define the work area, so it can work on large areas. It is located on the ground knowing its geographical coordinates using its sensors. The tool used to draw is still in development, Odysseus can already draw figures. However it still needs to improve accuracy with more sensitive sensors."</em> <a href="https://hackaday.io/project/20884-pablo-odysseus">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_TheMultitaskingFinalCountdownT.jpg" alt="The Multitasking "Final Countdown" Timer With Wireless Programming" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/The-Multitasking-Final-Countdown-Timer-With-Wirele/">The Multitasking "Final Countdown" Timer With Wireless Programming</a></h2>

<p><em>"While playing a game called slither.io, Nathan Ramanathan was asked by his father to turn on a wet grinder for “exactly 45 minutes.” As explained, this device uses stones to grind rice into dough, producing material for delicious-looking Dosa cakes. Deliciousness aside, Ramanathan would rather have the grinder stop automatically than wait around for it, and came up with his own Arduino Uno-based outlet timer controlled via smartphone over Bluetooth. As a bonus, it plays “The Final Countdown” by Europe when only a few seconds remain. "</em> <a href="http://www.instructables.com/id/The-Multitasking-Final-Countdown-Timer-With-Wirele/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ProgrammableAutomaticBlindOpen.jpg" alt="Programmable Automatic Blind Opener" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Programmable-Automatic-Blind-Opener/">Programmable Automatic Blind Opener</a></h2>

<p><em>"A while ago I changed my room around, which made opening and closing the roller blind harder. Like most people, I close the blinds when it gets dark and I have to put the lights on. Similarly, I open the blind in the morning when I wake to let the sun in. The way in which I have changed my room around makes accessing the pull-cord for the blind difficult. I therefore decided that I needed an automatic way of opening and closing the blind. Although not part of my original design concept it can be used as a security device. i.e when on holiday, use the automatic function to open and close the blind to give the impression of being home. The solution was to create a way of automatically opening or closing the blind, when needed, or at predetermined times."</em> <a href="http://www.instructables.com/id/Programmable-Automatic-Blind-Opener/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_ArduinoUltrasonicAlarm.jpg" alt="Arduino Ultrasonic Alarm" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Ultrasonic-Alarm/">Arduino Ultrasonic Alarm</a></h2>

<p><em>"Using an Arduino UNO, an Ultrasonic Sensor, and a RFID Reader, you can create a simple alarm which when placed near a door, senses if that door has been opened or if someone has come in and triggers an alarm which would sound a buzzer and flash a set of LEDs until its shut off. With an Ultrasonic Sensor, the alarm goes off when the individual or object passes the sensor at less than a certain distance set in the Arduino (ie. 36 inches), thus creating a restricted perimeter near the door rather that detects an object going in. Once the alarm has been triggered, it remain on until either the alarm is deactivated, power is cut to the Arduino, or a certain amount of time passes (ex. 10 minutes), whichever comes first. Activation of the alarm is controlled using an RFID Reader which renders the alarm on and off when the appropriate tag/card is flashed in front of the reader. If an unauthorized tag/card is detected, the reader will reject it, and the alarm's state will not change. The tag/card can be used to activate and deactivate the alarm when entering or leaving, as well as deactivate the alarm when triggered."</em> <a href="http://www.instructables.com/id/Arduino-Ultrasonic-Alarm/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM103_4InARowConnect4.jpg" alt="4 in a Row / Connect 4" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/4-in-a-Row-Connect-4/">4 in a Row / Connect 4</a></h2>

<p><em>"I try to make things which are useful, but, for a change, I decided to make a game! Its an electronic version of Connect 4 / 4 In A Row. The component count is minimal (if you don't count each individual led), but the wiring takes a little patience."</em> <a href="http://www.instructables.com/id/4-in-a-Row-Connect-4/">[...]</a>
 </SPAN></DIV></p>

<hr />

<p>That's all Folks!</p>

<script data-cfasync="false" src="../../../../../../cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>SHB.build({elementID: 'shb', pref: { btnSizeClass: 'btn-md', btnClass: 'btn my-btn'}, buttons: { fbLike: true, fbShare:true, tweet: true, plusOne: true, plusShare: true,linkedInShare:true}});</script>

					</div>
				</section>
				</div> <!-- Container -->

				<footer id="footer" class="panel-footer">
					<div class="inner">
						<a href="https://github.com/PhileCMS/Phile">Phile</a> was made by <a href="https://github.com/PhileCMS">The PhileCMS Community</a>.
					</div>
				</footer>
			</div>
		</div>
</div>
		<script type="text/javascript">
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-20725619-1']);
            _gaq.push(['_trackPageview']);
            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
        </script>
		<!-- Matomo -->
<script type="text/javascript">
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//matomo.altlab.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '2']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
	</body>
</html>
