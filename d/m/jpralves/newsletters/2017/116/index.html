<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

		<!-- <base href="https://altlab.org/d/" />  -->
		<title>Newsletter altLab - 2017-07-20 - Nº 116 | altLab Documenta</title>
				<meta name="description" content="Newsletter altLab Nº116 de 20 de julho de 2017">
				<meta property="og:type" content="article" />
		<meta property="og:title" content="Newsletter altLab - 2017-07-20 - Nº 116 | altLab Documenta" />
		<meta property="og:description" content="Newsletter altLab Nº116 de 20 de julho de 2017" />
		<meta property="og:url" content="https://altlab.org/d/m/jpralves/newsletters/2017/116/" />
		<meta property="og:site_name" content="altLab Documenta" />

		<!-- Bootstrap -->
		<link href="../../../../../themes/altlab/css/bootstrap.min.css" rel="stylesheet">
		<link href="../../../../../themes/altlab/override-test.css" rel="stylesheet">
		<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
		<script src="../../../../../themes/altlab/js/jquery-1.12.4.min.js"></script>
		<!-- Include all compiled plugins (below), or include individual files as needed -->
		<script src="../../../../../themes/altlab/js/bootstrap.min.js"></script>

	</head>
	<body>
<div class="container">
<div class="container-fluid">
      <div class="page-header hidden-xs" id="brand-logo">
        <h1><a href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-gradoverwhite.png" width="180" height="120" alt="Home" style="vertical-align:text-bottom" /></a> Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></h1>

      </div>
			<nav class="navbar navbar-inverse">

				<div class="container-fluid">
					<div class="navbar-header">
						<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#myNavbar">
							<span class="sr-only">Toggle navigation</span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
<div class="visible-xs">
<a class="navbar-brand" href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-documenta.png" width="58" height="35" alt="Home" style="margin-top: -7px;"></a>
						<a class="navbar-brand" href="../../../../../index.html">Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></a></div>
					</div>
					<div class="collapse navbar-collapse" id="myNavbar">
						<ul class="nav navbar-nav">

           	<li id="dropdown.1" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Membros <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../index.html">Index</a>
</li>
   
           	<li id="dropdown.101" class="dropdown">
		<a href="../../../index.html">João Alves <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.102" class="dropdown">
		<a href="../../../../sislog/index.html">Fernando Carvalho <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.103" class="dropdown">
		<a href="../../../../pangelo/index.html">Pedro Ângelo <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.104" class="dropdown">
		<a href="../../../../dinix/index.html">Dinix <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../funke/funke.html">m/funke/funke</a>
  
   	</li>
            	<li id="dropdown.106" class="dropdown">
		<a href="../../../../afonsom/index.html">Afonso Muralha <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.107" class="dropdown">
		<a href="../../../../x3msnake/index.html">X3msnake <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../ampmendes/index.html">António Mendes</a>
  
   	</li>
            	<li>
		<a href="../../../../guardajoao/index.html">GuardaJoao</a>
  
   	</li>
            	<li>
		<a href="../../../../jac/index.html">JAC</a>
  
   	</li>
            	<li>
		<a href="../../../../nini/index.html">Nuno Nini</a>
  
   	</li>
 
</ul>
    	</li>
            	<li id="dropdown.2" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Documentação Partilhada <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../../s/index.html">Index</a>
</li>
   
                         	<li id="dropdown.203" class="dropdown">
		<a href="../../../../../s/workshops/index.html">Workshops <span class="caret"></span></a>
  
      	</li>
                   	<li>
		<a href="../../../../../s/documenta/index.html">Documenta DevMap</a>
  
   	</li>
                   	<li>
		<a href="../../../../../s/processos/index.html">Processos do Lab (draft)</a>
  
   	</li>
            	<li id="dropdown.208" class="dropdown">
		<a href="../../../../../s/recursos/index.html">Recursos <span class="caret"></span></a>
  
      	</li>
 
</ul>
    	</li>
 
						</ul>
					</div>
				</div>
			</nav>

			<div class="container">
				<div class="container">
				<section id="content">
					<div class="inner">
						<p><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
<link rel="stylesheet" href="../res/_shb.css"></p>

<script src="../res/_shb.min.js" type="text/javascript"></script>

<div style="text-align: center;">
<button class="btn my-btn btn-md disabled">Share:</button>
<div class="btn-group" id="shb"></div>
</div>

<p><br></p>

<h1 id="topo"><img src="../res/__Titulo.png" alt="Newsletter altLab" /></h1>

<p>2017-07-20 - Nº 116</p>

<div style="position: fixed; z-index: 65535; right: 10px; bottom: 10px;">
<a href='#topo' title='Go to Top'><img src="../res/_gotop.png" alt="go to top image" /></a>
</div>

<div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'pt', layout: google.translate.TranslateElement.FloatPosition.TOP_LEFT, multilanguagePage: true}, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<p><DIV class="articledetail"><SPAN class="articledetail"></p>

<p><img src="Newsletter116.jpg" alt="Newsletter116Cover" /></p>

<h2>Editorial</h2>

<p>Esta é a Newsletter Nº 116 que se apresenta com o mesmo formato que as anteriores. Se gostar da Newsletter partilhe-a!</p>

<p>Todas as Newsletters encontram-se indexadas no <a href="../../index.html">link</a>.</p>

<p>Esta Newsletter tem os seguintes tópicos:</p>

<ul>
<li><a href="#Novidades-da-Semana">Novidades da Semana</a></li>
<li><a href="#Ciencia-e-Tecnologia">Ciência e Tecnologia</a></li>
<li><a href="#Documentacao">Documentação</a></li>
<li><a href="#Projetos-Maker">Projetos Maker</a></li>
</ul>

<p>Faz hoje anos que nascia, em 1836, <a href="https://en.wikipedia.org/wiki/Clifford_Allbutt">Clifford Allbutt</a>. Este médico inglês ficou conhecido pela sua invenção do termómetro clinico.
Faz também anos hoje que nascia, em 1924, <a href="https://en.wikipedia.org/wiki/Robert_D._Maurer">Robert D. Maurer</a>. Este físico Norte-americano ficou conhecido pela invenção da fibra-optica. Em 1970, Maurer e seus colegas Donald Keck e Peter C. Schultz projectaram e produziram a primeira fibra com poucas perdas ópticas, o suficiente para uso em telecomunicações por um novo processo de deposição de dióxido de silício dopado com titânio num tubo de quartzo usando a hidrólise de uma chama com sinterização, fundindo o material para formar a fibra.
Por fim, faz hoje anos que nascia, em 1947, <a href="https://en.wikipedia.org/wiki/Gerd_Binnig">Gerd Binnig</a>. Este físico alemão ficou conhecido pela sua invenção do microscópio de corrente de tunelamento (STM).</p>

<p>Esta semana o Bluetooth Special Interest Group (SIG) anunciou que a tecnologia Bluetooth®, o padrão global para conectividade sem fio simples e segura, agora suporta redes mesh. A nova capacidade mesh permite comunicações de dispositivos muitos-para-muitos (m: m) e é otimizada para criar redes de dispositivos em grande escala.
A Adafruit anunciou a disponibilidade da versão 1.0 do seu CircuitPython. Trata-se de uma versão derivada de código aberto do MicroPython para uso em placas de desenvolvimento educacional como o ESP8266 ou o SAMD21.
A Intel acabou de lançar a Movidius Neural Compute Stick com o objectivo de democratizar o acesso ao desenvolvimento de aplicações Deep Learning. Desenhada para programadores, cientistas e makers, o Movidius Neural Compute Stick visa reduzir as barreiras para o desenvolvimento, ajuste e implantação de aplicações de IA, oferecendo um processamento dedicado de redes neuronais de alto desempenho num formato de pen USB.
Faz hoje exactamente 48 anos que a 20 de Julho de 1969 a Apollo 11 aterrou na Lua. Lançada a 16 de Julho a bordo de um foguetão Saturn V a sonda espacial levou os três astronautas à superfície da Lua. Neil Armstrong, proferiu a frase que ficou para a história, "... umm pequeno passo para o homem, um passo de gigante para a humanidade. Acompanhado por Buzz Aldrin e Michael Collins foram os primeiros homens a pousar na Lua. Voltaram à Terra no dia 24. Estima-se que cerca de 600 milhões de pessoas viram a aterragem "Live" na televisão. Estima-se que o programa espacial Apollo custou cerca de 25.4 mil milhões de dólares, cerca de 150 mil milhões em moeda actual.</p>

<p>Na Newsletter desta semana apresentamos diversos projetos de maker. É apresentado também um livro intitulado "The Signal" que explica sobre electrónica analógica.</p>

<p><img src="../res/_jpralves.jpg" alt="jpralves" /> João Alves (<a href="https://altlab.org/d/m/jpralves/newsletters/2017/116/&#x6d;&#97;&#105;&#x6c;&#116;&#111;&#x3a;&#x6a;&#112;&#114;&#x61;&#108;&#118;&#x65;&#x73;&#64;g&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;o&#x6d;#x6d;&a&i&l&t&o&:&j&p&r&a&l&v&e&s&@g&m&a&i&l&.&co&m"><span class="__cf_email__" data-cfemail="375d4745565b41524477505a565e5b1954585a">[email&#160;protected]</span></a>)</p>

<p>O conteúdo da Newsletter encontra-se sob a licença <img src="../res/_by-nc-sa4.0.png" alt="by-nc-sa4.0" /> <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>

<p></SPAN></DIV></p>

<hr />

<h1 id="Novidades-da-Semana">Novidades da Semana</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS116_BluetoothSigAnnouncesMeshNetwo.jpg" alt="Bluetooth SIG Announces Mesh Networking Capability" class="lefter"></p>

<h2><a href="https://www.bluetooth.com/news/pressreleases/2017/07/bluetooth-sig-announces-mesh-networking-capability">Bluetooth SIG Announces Mesh Networking Capability</a></h2>

<p><em>"The Bluetooth Special Interest Group (SIG) announced today that Bluetooth® technology, the global standard for simple, secure wireless connectivity, now supports mesh networking. The new mesh capability enables many-to-many (m:m) device communications and is optimized for creating large-scale device networks. It is ideally suited for building automation, sensor networks and other IoT solutions where tens, hundreds, or thousands of devices need to reliably and securely communicate with one another. “By adding support for mesh networking, the Bluetooth member community is continuing a long history of focused innovation to help new, up-and-coming markets flourish,” said Mark Powell, executive director for Bluetooth SIG, Inc. “In the same way the connected device market experienced rapid growth after the introduction of Bluetooth Low Energy, we believe Bluetooth mesh networking can play a vital role in helping early stage markets, such as building automation and wireless sensor networks, experience more rapid growth.” Commercial building and factory automation represent major market opportunities for wireless mesh networking technologies. These markets demand true industrial-grade solutions, which Bluetooth mesh uniquely delivers."</em> <a href="https://www.bluetooth.com/news/pressreleases/2017/07/bluetooth-sig-announces-mesh-networking-capability">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS116_Circuitpython100.jpg" alt="CircuitPython 1.0.0!" class="lefter"></p>

<h2><a href="https://blog.adafruit.com/2017/07/19/circuitpython-1-0-0/">CircuitPython 1.0.0!</a></h2>

<p><em>"This is the first stable release of CircuitPython! That means we believe everything works well and that the APIs are largely fixed. This release was made from the stable branch. The master branch is now working towards the 2.0.0 release. Thanks to everyone who has contributed including those to upstream MicroPython. @dpgeorge and @pfalcon are the core devs of MicroPython. Thanks to @deshipu, @dhalbert, @ladyada, @tdicola, @hukuzatuna, @mindforger, @cyborg5, @robomike, @ianrrees, @bobricius, @g-ollivier, @rmd6502, @willingc, @fede2cr, @cversek, @turbinenreiter, @ptorrone and @jerryneedell for their testing and code contributions. Thanks to Adafruit for making this possible. This release is based on MicroPython 1.8.7. Support upstream MicroPython by purchasing a PyBoard (from Adafruit here)."</em> <a href="https://blog.adafruit.com/2017/07/19/circuitpython-1-0-0/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS116_IntelDemocratizesDeepLearningA.jpg" alt="Intel Democratizes Deep Learning Application Development with Launch of Movidius Neural Compute Stick" class="lefter"></p>

<h2><a href="https://newsroom.intel.com/news/intel-democratizes-deep-learning-application-development-launch-movidius-neural-compute-stick/">Intel Democratizes Deep Learning Application Development with Launch of Movidius Neural Compute Stick</a></h2>

<p><em>"Today, Intel launched the Movidius™ Neural Compute Stick, the world’s first USB-based deep learning inference kit and self-contained artificial intelligence (AI) accelerator that delivers dedicated deep neural network processing capabilities to a wide range of host devices at the edge. Designed for product developers, researchers and makers, the Movidius Neural Compute Stick aims to reduce barriers to developing, tuning and deploying AI applications by delivering dedicated high-performance deep-neural network processing in a small form factor."</em> <a href="https://newsroom.intel.com/news/intel-democratizes-deep-learning-application-development-launch-movidius-neural-compute-stick/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS116_July201969OneGiantLeapForManki.jpg" alt="July 20, 1969: One Giant Leap For Mankind" class="lefter"></p>

<h2><a href="https://www.nasa.gov/mission_pages/apollo/apollo11.html">July 20, 1969: One Giant Leap For Mankind</a></h2>

<p><em>"July 1969. It's a little over eight years since the flights of Gagarin and Shepard, followed quickly by President Kennedy's challenge to put a man on the moon before the decade is out. It is only seven months since NASA's made a bold decision to send Apollo 8 all the way to the moon on the first manned flight of the massive Saturn V rocket. Now, on the morning of July 16, Apollo 11 astronauts Neil Armstrong, Buzz Aldrin and Michael Collins sit atop another Saturn V at Launch Complex 39A at the Kennedy Space Center. The three-stage 363-foot rocket will use its 7.5 million pounds of thrust to propel them into space and into history. At 9:32 a.m. EDT, the engines fire and Apollo 11 clears the tower. About 12 minutes later, the crew is in Earth orbit. After one and a half orbits, Apollo 11 gets a "go" for what mission controllers call "Translunar Injection" - in other words, it's time to head for the moon. Three days later the crew is in lunar orbit. A day after that, Armstrong and Aldrin climb into the lunar module Eagle and begin the descent, while Collins orbits in the command module Columbia. Collins later writes that Eagle is "the weirdest looking contraption I have ever seen in the sky," but it will prove its worth. When it comes time to set Eagle down in the Sea of Tranquility, Armstrong improvises, manually piloting the ship past an area littered with boulders. During the final seconds of descent, Eagle's computer is sounding alarms. It turns out to be a simple case of the computer trying to do too many things at once, but as Aldrin will later point out, "unfortunately it came up when we did not want to be trying to solve these particular problems." When the lunar module lands at 4:18 p.m EDT, only 30 seconds of fuel remain. Armstrong radios "Houston, Tranquility Base here. The Eagle has landed." Mission control erupts in celebration as the tension breaks, and a controller tells the crew "You got a bunch of guys about to turn blue, we're breathing again." Armstrong will later confirm that landing was his biggest concern, saying "the unknowns were rampant," and "there were just a thousand things to worry about." At 10:56 p.m. EDT Armstrong is ready to plant the first human foot on another world. With more than half a billion people watching on television, he climbs down the ladder and proclaims: "That's one small step for a man, one giant leap for mankind." Aldrin joins him shortly, and offers a simple but powerful description of the lunar surface: "magnificent desolation." They explore the surface for two and a half hours, collecting samples and taking photographs. They leave behind an American flag, a patch honoring the fallen Apollo 1 crew, and a plaque on one of Eagle's legs. It reads, "Here men from the planet Earth first set foot upon the moon. July 1969 A.D. We came in peace for all mankind." Armstrong and Aldrin blast off and dock with Collins in Columbia. Collins later says that "for the first time," he "really felt that we were going to carry this thing off." The crew splashes down off Hawaii on July 24. Kennedy's challenge has been met. Men from Earth have walked on the moon and returned safely home."</em> <a href="https://www.nasa.gov/mission_pages/apollo/apollo11.html">[...]</a>
 </SPAN></DIV></p>

<h2>Outras Notícias</h2>

<ul>
<li><a href="http://www.tyrepress.com/2017/07/linglong-tire-partners-in-chinas-first-3d-printed-tyre-project/">Linglong Tire partners in China’s first 3D printed tyre project</a></li>
<li><a href="https://news.samsung.com/global/samsung-debuts-worlds-first-cinema-led-display">Samsung Debuts World’s First Cinema LED Display</a></li>
<li><a href="https://sputniknews.com/environment/201707141055554624-environmentally-friendly-plastic-bags/">Bye-Bye, Landfills! Russian Scientists Create Biodegradable Polyethylene</a></li>
<li><a href="http://iss.jaxa.jp/en/kiboexp/news/170714_int_ball_en.html">First disclosure of images taken by the JEM Kibo's internal drone "Int-Ball"</a></li>
<li><a href="https://catboost.yandex/">CatBoost is an open-source gradient boosting library with categorical features support</a></li>
<li><a href="http://www.allegromicro.com/en/About-Allegro/News-Room/2017/A5990-Press-Release.aspx">Allegro MicroSystems, LLC Introduces New Quad DMOS Full Bridge PWM Motor Driver IC</a></li>
<li><a href="http://newscenter.ti.com/2017-07-18-TI-introduces-single-chip-buck-boost-battery-charge-controllers-enabling-USB-Type-C-TM-and-USB-Power-Delivery-support">TI introduces single-chip buck-boost battery charge controllers enabling USB Type-C™ and USB Power Delivery support</a></li>
<li><a href="https://research.googleblog.com/2017/07/using-deep-learning-to-create.html">Using Deep Learning to Create Professional-Level Photographs</a></li>
<li><a href="https://www.apnews.com/f226a7a28f4a4e23bfffa3069ac0b437/Swimming-robot-probes-Fukushima-reactor-to-find-melted-fuel">Swimming robot probes Fukushima reactor to find melted fuel</a></li>
<li><a href="https://www.theverge.com/2017/7/20/16003766/elon-musk-boring-company-hyperloop-nyc-philadelphia-baltimore-dc">Elon Musk says he has a green light to build a NY–Philly–Baltimore–DC hyperloop</a></li>
</ul>

<h1 id="Ciencia-e-Tecnologia">Ciência e Tecnologia</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_TestingASoftArtificialHeart.jpg" alt="Testing a soft artificial heart" class="lefter"></p>

<h2><a href="https://www.ethz.ch/en/news-and-events/eth-news/news/2017/07/artificial_heart.html">Testing a soft artificial heart</a></h2>

<p><em>"ETH researchers from the Functional Materials Laboratory have developed a silicone heart that beats almost like a human heart. In collaboration with colleagues from the Product Development Group Zurich, they have tested how well it works. It looks like a real heart. And this is the goal of the first entirely soft artificial heart: to mimic its natural model as closely as possible. The silicone heart has been developed by Nicholas Cohrs, a doctoral student in the group led by Wendelin Stark, Professor of Functional Materials Engineering at ETH Zurich. The reasoning why nature should be used as a model is clear. Currently used blood pumps have many disadvantages: their mechanical parts are susceptible to complications while the patient lacks a physiological pulse, which is assumed to have some consequences for the patient. “Therefore, our goal is to develop an artificial heart that is roughly the same size as the patient’s own one and which imitates the human heart as closely as possible in form and function,” says Cohrs. A well-functioning artificial heart is a real necessity: about 26 million people worldwide suffer from heart failure while there is a shortage of donor hearts.  Artificial blood pumps help to bridge the waiting time until a patient receives a donor heart or their own heart recovers. The soft artificial heart was created from silicone using a 3D-printing, lost-wax casting technique; it weighs 390 grams and has a volume of 679 cm3. “It is a silicone monoblock with complex inner structure,” explains Cohrs. This artificial heart has a right and a left ventricle, just like a real human heart, though they are not separated by a septum but by an additional chamber. This chamber is in- and deflated by pressurized air and is required to pump fluid from the blood chambers, thus replacing the muscle contraction of the human heart."</em>  <a href="https://www.ethz.ch/en/news-and-events/eth-news/news/2017/07/artificial_heart.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_UltraHighContrastDigitalSensin.jpg" alt="Ultra-high-contrast digital sensing" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/ultra-high-contrast-digital-sensing-cameras-0714">Ultra-high-contrast digital sensing</a></h2>

<p><em>"Virtually any modern information-capture device — such as a camera, audio recorder, or telephone — has an analog-to-digital converter in it, a circuit that converts the fluctuating voltages of analog signals into strings of ones and zeroes. Almost all commercial analog-to-digital converters (ADCs), however, have voltage limits. If an incoming signal exceeds that limit, the ADC either cuts it off or flatlines at the maximum voltage. This phenomenon is familiar as the pops and skips of a “clipped” audio signal or as “saturation” in digital images — when, for instance, a sky that looks blue to the naked eye shows up on-camera as a sheet of white. Last week, at the International Conference on Sampling Theory and Applications, researchers from MIT and the Technical University of Munich presented a technique that they call unlimited sampling, which can accurately digitize signals whose voltage peaks are far beyond an ADC’s voltage limit. The consequence could be cameras that capture all the gradations of color visible to the human eye, audio that doesn’t skip, and medical and environmental sensors that can handle both long periods of low activity and the sudden signal spikes that are often the events of interest. The paper’s chief result, however, is theoretical: The researchers establish a lower bound on the rate at which an analog signal with wide voltage fluctuations should be measured, or “sampled,” in order to ensure that it can be accurately digitized. Their work thus extends one of the several seminal results from longtime MIT Professor Claude Shannon’s groundbreaking 1948 paper “A Mathematical Theory of Communication,” the so-called Nyquist-Shannon sampling theorem. Ayush Bhandari, a graduate student in media arts and sciences at MIT, is the first author on the paper, and he’s joined by his thesis advisor, Ramesh Raskar, an associate professor of media arts and sciences, and Felix Krahmer, an assistant professor of mathematics at the Technical University of Munich."</em> <a href="http://news.mit.edu/2017/ultra-high-contrast-digital-sensing-cameras-0714">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_WhyYouMightTrustAQuantumComput.jpg" alt="Why you might trust a quantum computer with secrets – even over the internet" class="lefter"></p>

<h2><a href="http://www.quantumlah.org/highlight/170712_quantum_computing.php">Why you might trust a quantum computer with secrets – even over the internet</a></h2>

<p><em>"Researchers in Singapore and Australia suggest you could operate a quantum computer in the cloud without revealing your data or the program you're running. Here's the scenario: you have sensitive data and a problem that only a quantum computer can solve. You have no quantum devices yourself. You could buy time on a quantum computer, but you don't want to give away your secrets. What can you do? Writing in Physical Review X on 11 July, researchers in Singapore and Australia propose a way you could use a quantum computer securely, even over the internet. The technique could hide both your data and program from the computer itself. Their work counters earlier hints that such a feat is impossible. The scenario is not far-fetched. Quantum computers promise new routes to solving problems in cryptography, modelling and machine learning, exciting government and industry. Such problems may involve confidential data or be commercially sensitive. Technology giants are already investing in building such computers – and making them available to users. For example, IBM announced on 17 May this year that it is making a quantum computer with 16 quantum bits accessible to the public for free on the cloud, as well as a 17-qubit prototype commercial processor. Seventeen qubits are not enough to outperform the world's current supercomputers, but as quantum computers gain qubits, they are expected to exceed the capabilities of any machine we have today. That should drive demand for access. "We're looking at what's possible if you're someone just interacting with a quantum computer across the internet from your laptop. We find that it's possible to hide some interesting computations," says Joseph Fitzsimons, a Principal Investigator at the Centre for Quantum Technologies (CQT) at the National University of Singapore and Associate Professor at Singapore University of Technology and Design (SUTD), who led the work. Quantum computers work by processing bits of information stored in quantum states. Unlike the binary bits found in our regular (i.e., classical) computers, each a 0 or 1, qubits can be in superpositions of 0 and 1. The qubits can also be entangled, which is believed to be crucial to a quantum computer's power. The scheme designed by Joseph and his colleagues brings secrecy to a form of quantum computing driven by measurements. In this scheme, the quantum computer is prepared by putting all its qubits into a special type of entangled state. Then the computation is carried out by measuring the qubits one by one. The user provides step-wise instructions for each measurement: the steps encode both the input data and the program. Researchers have shown previously that users who can make or measure qubits to convey instructions to the quantum computer could disguise their computation. The new paper extends that power to users who can only send classical bits – i.e. most of us, for now. This is surprising because some computer science theorems imply that encrypted quantum computation is impossible when only classical communication is available. The hope for security comes from the quantum computer not knowing which steps of the measurement sequence do what. The quantum computer can't tell which qubits were used for inputs, which for operations and which for outputs."</em> <a href="http://www.quantumlah.org/highlight/170712_quantum_computing.php">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_MiniaturizingTheBrainOfADrone.jpg" alt="Miniaturizing the brain of a drone" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/miniaturizing-brain-smart-drones-0712">Miniaturizing the brain of a drone</a></h2>

<p><em>"In recent years, engineers have worked to shrink drone technology, building flying prototypes that are the size of a bumblebee and loaded with even tinier sensors and cameras. Thus far, they have managed to miniaturize almost every part of a drone, except for the brains of the entire operation — the computer chip. Standard computer chips for quadcoptors and other similarly sized drones process an enormous amount of streaming data from cameras and sensors, and interpret that data on the fly to autonomously direct a drone’s pitch, speed, and trajectory. To do so, these computers use between 10 and 30 watts of power, supplied by batteries that would weigh down a much smaller, bee-sized drone. Now, engineers at MIT have taken a first step in designing a computer chip that uses a fraction of the power of larger drone computers and is tailored for a drone as small as a bottlecap. They will present a new methodology and design, which they call “Navion,” at the Robotics: Science and Systems conference, held this week at MIT. The team, led by Sertac Karaman, the Class of 1948 Career Development Associate Professor of Aeronautics and Astronautics at MIT, and Vivienne Sze, an associate professor in MIT's Department of Electrical Engineering and Computer Science, developed a low-power algorithm, in tandem with pared-down hardware, to create a specialized computer chip. The key contribution of their work is a new approach for designing the chip hardware and the algorithms that run on the chip. “Traditionally, an algorithm is designed, and you throw it over to a hardware person to figure out how to map the algorithm to hardware,” Sze says. “But we found by designing the hardware and algorithms together, we can achieve more substantial power savings.” “We are finding that this new approach to programming robots, which involves thinking about hardware and algorithms jointly, is key to scaling them down,” Karaman says. The new chip processes streaming images at 20 frames per second and automatically carries out commands to adjust a drone’s orientation in space. The streamlined chip performs all these computations while using just below 2 watts of power — making it an order of magnitude more efficient than current drone-embedded chips."</em> <a href="http://news.mit.edu/2017/miniaturizing-brain-smart-drones-0712">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_NewMaterialReducesEnergyConsum.jpg" alt="New material reduces energy consumption to a minimum" class="lefter"></p>

<h2><a href="http://www.uab.cat/web/newsroom/news-detail/new-material-reduces-energy-consumption-to-a-minimum-1345668003610.html?noticiaid=1345733270829">New material reduces energy consumption to a minimum</a></h2>

<p><em>"In order to store information in the conventional magnetic memories of electronic devices, the materials' small magnetic domains are oriented “up” or “down” by using externally applied magnetic fields. To generate these fields it is necessary to produce electric currents, but these currents heat up materials and a large amount of energy is needed to be spent to cool them. Practically 40% of the electrical energy used by computers (or “Big Data” servers) is dissipated as heat. In 2007, French scientists observed that when magnetic materials are grown as ultra-thin layers and voltage is applied, the amount of current and energy needed to orient the magnetic domains was reduced by 4%. However, this slight reduction was not significant enough to be of interest for practical devices. A research team led by Jordi Sort, ICREA Research Professor and Lecturer of the Department of Physics at the Universitat Autònoma de Barcelona, with the collaboration of the Catalan Institute for Nanoscience and Nanotechnology (ICN2), has searched for a solution based on the magnetic properties of a new nanoporous material with very high surface area. The new material, which is featured this week in the Advanced Functional Materials journal, consists in nanoporous copper-nickel alloy films, organised in a way that the interior forms surfaces and holes similar to that of the inside of a sponge, but with a separation between pores (i.e., thickness of the pore walls) of only 5 or 10 nanometres. In other words, the walls of the pores contain room for only a few dozens of atoms. “There are many researchers using nanoporous materials to improve physical-chemical processes, such as in the development of new gas sensors or catalysts, but we studied what these materials could provide to electromagnetism”, Prof. Jordi Sort explains. “The nanopores found on the inside of nanoporous materials offer a great amount of surface. With this vast surface concentrated in a very small space we can apply a small voltage and enormously reduce the energy needed to orient the magnetic domains and record data. This represents a new paradigm in the energy saving of computers and in computing and handling magnetic data in general”, says Jordi Sort. UAB researchers have built the first prototypes of nanoporous magnetic memories based on copper-nickel (CuNi) alloys and have reached very satisfactory results, with a reduction of 35% in magnetic coercivity, a magnitude related to the magnetic field (i.e., energy consumption) needed to switch the orientation of magnetic bits. In these first prototypes, the UAB researchers applied the voltage using liquid electrolytes, but they are now working on developing solid dieletrics which could prompt the use of these devices in the market. According to Jordi Sort, “Implementing this material into the memories of computers and mobile devices can offer many advantages, mainly in direct energy saving for computers and considerable increase in the autonomy of mobile devices”. The development of new nanoelectronic devices with improved energy efficiency is one of the strategic lines included in the European Union's Horizon 2020 programme. According to some estimations, if electric current is completely substituted by voltage in data processing systems, energy costs could be reduced by a factor of 1/500.In fact, computer servers of large companies such as Google and Facebook are located underwater, or in Nordic countries in which temperatures are very low, with the aim of reducing heating and energy consumption."</em> <a href="http://www.uab.cat/web/newsroom/news-detail/new-material-reduces-energy-consumption-to-a-minimum-1345668003610.html?noticiaid=1345733270829">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_UniversityDevelopsNewCheapSust.jpg" alt="University develops new cheap, sustainable water treatment devices for developing countries" class="lefter"></p>

<h2><a href="http://www.bath.ac.uk/research/news/2017/07/12/university-develops-new-cheap-sustainable-water-treatment-devices-for-developing-countries">University develops new cheap, sustainable water treatment devices for developing countries</a></h2>

<p><em>"A multi-disciplinary research project at the University of Bath hopes to develop an efficient, portable and low cost continuous treatment system for contaminated drinking water for poor rural communities in developing countries. The research team want to produce safe, clean drinking water for poor rural communities who don’t have access to a centralised water supply. The researchers are using 3D printing to generate rapid prototypes and test them using a unique indoor solar light that can replicate pure sunlight in the lab. This testing will enable a better understanding of the optimal design of this household water treatment (HWT) system to most efficiently produce safe drinking water."</em> <a href="http://www.bath.ac.uk/research/news/2017/07/12/university-develops-new-cheap-sustainable-water-treatment-devices-for-developing-countries">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_NewCrisprTechnologyTakesCellsT.jpg" alt="New CRISPR technology takes cells to the movies" class="lefter"></p>

<h2><a href="http://news.harvard.edu/gazette/story/2017/07/taking-cells-out-to-the-movies-with-new-crispr-technology/">New CRISPR technology takes cells to the movies</a></h2>

<p><em>"Researchers use expensive machinery to develop ways to harness DNA as a synthetic raw material to store large amounts of digital information outside of living cells. But what if they could coerce living cells, such as large populations of bacteria, to use their own genomes as a biological hard drive that can record information scientists could tap anytime? That approach not only could open entirely new possibilities of data storage, it could also be engineered into an effective memory device able to create a chronological record of cells’ molecular experiences during development or under exposure to stresses or pathogens. In 2016, a team at the Wyss Institute for Biologically Inspired Engineering and Harvard Medical School (HMS) led by Wyss core faculty member George Church built the first molecular recorder based on the CRISPR system. The recorder allows cells to acquire bits of chronologically provided, DNA-encoded information that generate a memory in a bacterium’s genome. The information is stored as an array of sequences in the CRISPR locus and can be recalled and used to reconstruct a timeline of events. “As promising as this was, we did not know what would happen when we tried to track about 100 sequences at once, or if it would work at all. This was critical since we are aiming to use this system to record complex biological events as our ultimate goal,” said Seth Shipman, a postdoctoral fellow working with Church and the study’s first author. Now they know. In a study published today in Nature, the same team shows in foundational proof-of-principle experiments that developed further as a first-of-its-kind approach, the CRISPR system can encode information in living cells that is as complex as a digitized image of a human hand, reminiscent of early humans’ paintings on cave walls and a sequence of one of the first motion pictures made ever, Eadweard Muybridge’s film of a galloping horse."</em> <a href="http://news.harvard.edu/gazette/story/2017/07/taking-cells-out-to-the-movies-with-new-crispr-technology/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_FindingLeaksWhileTheyreEasyToF.jpg" alt="Finding leaks while they’re easy to fix" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/robot-finds-leaks-water-pipes-0718">Finding leaks while they’re easy to fix</a></h2>

<p><em>"Access to clean, safe water is one of the world’s pressing needs, yet today’s water distribution systems lose an average of 20 percent of their supply because of leaks. These leaks not only make shortages worse but also can cause serious structural damage to buildings and roads by undermining foundations. Unfortunately, leak detection systems are expensive and slow to operate — and they don’t work well in systems that use wood, clay, or plastic pipes, which account for the majority of systems in the developing world. Now, a new system developed by researchers at MIT could provide a fast, inexpensive solution that can find even tiny leaks with pinpoint precision, no matter what the pipes are made of. The system, which has been under development and testing for nine years by professor of mechanical engineering Kamal Youcef-Toumi, graduate student You Wu, and two others, will be described in detail at the upcoming IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) in September. Meanwhile, the team is carrying out tests this summer on 12-inch concrete water-distribution pipes under the city of Monterrey, Mexico. The system uses a small, rubbery robotic device that looks something like an oversized badminton birdie. The device can be inserted into the water system through any fire hydrant. It then moves passively with the flow, logging its position as it goes. It detects even small variations in pressure by sensing the pull at the edges of its soft rubber skirt, which fills the diameter of of the pipe. The device is then retrieved using a net through another hydrant, and its data is uploaded. No digging is required, and there is no need for any interruption of the water service. In addition to the passive device that is pushed by the water flow, the team also produced an active version that can control its motion. Monterrey itself has a strong incentive to take part in this study, since it loses an estimated 40 percent of its water supply to leaks every year, costing the city about $80 million in lost revenue. Leaks can also lead to contamination of the water supply when polluted water backs up into the distribution pipes. The MIT team, called PipeGuard, intends to commercialize its robotic detection system to help alleviate such losses. In Saudi Arabia, where most drinking water is provided through expensive desalination plants, some 33 percent is lost through leakage. That’s why that desert nation’s King Fahd University of Petroleum and Minerals has sponsored and collaborated on much of the MIT team’s work, including successful field tests there earlier this year that resulted in some further design improvements to the system, Youcef-Toumi says. Those tests, in a mile-long section of 2-inch rusty pipe provided by Pipetech LLC, a pipeline service company in Al Khobar, Saudi Arabia, that frequently uses the same pipe system for validating and certifying pipeline technologies. The tests, in pipes with many bends, T-joints, and connections, involved creating an artificial leak for the robot to find. The robot did so successfully, distinguishing the characteristics of the leak from false alarms caused by pressure variations or changes in pipe size, roughness, or orientation."</em> <a href="http://news.mit.edu/2017/robot-finds-leaks-water-pipes-0718">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_TransformerRobotsCanBePrintedO.jpg" alt="Transformer robots can be printed on demand in just 13 minutes" class="lefter"></p>

<h2><a href="https://www.newscientist.com/article/2140403-transformer-robots-can-be-printed-on-demand-in-just-13-minutes/">Transformer robots can be printed on demand in just 13 minutes</a></h2>

<p><em>"From wire to finished product in less than 13 minutes: a new robot-builder is faster than most takeaways. It works by bending wire that already has motors attached into different shapes, using a process its designers call 1D printing. Once the robot has performed its job, it can simply be flattened and fed back into the system to be recycled into a new type of robot. “The idea is that you analyse the current situation, then make a robot on the fly that can deal with it,” says Sebastian Risi at the IT University of Copenhagen in Denmark, a member of the team that came up with the system. If you need a robot that can fit through a small space or around an odd-shaped corner, you input those constraints into the software and it will deliver something suitable. The system uses evolutionary algorithms that improve their designs bit by bit until they reach one that satisfies all the constraints. This means that the system doesn’t have to come up with the best design on its first attempt, but can keep evolving the design until it works."</em> <a href="https://www.newscientist.com/article/2140403-transformer-robots-can-be-printed-on-demand-in-just-13-minutes/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_WheelchairsGetRoboticRetrofitT.jpg" alt="Wheelchairs get robotic retrofit to become self-driving" class="lefter"></p>

<h2><a href="http://news.engineering.utoronto.ca/wheelchairs-get-robotic-retrofit-become-self-driving/">Wheelchairs get robotic retrofit to become self-driving</a></h2>

<p><em>"A new academic-industry collaboration at U of T Engineering is harnessing improved sensors and artificial intelligence to make electric wheelchairs self-driving. The technology could greatly simplify the lives of more than 5 million power wheelchair users across North America, and millions more worldwide. Since electric wheelchairs were first pioneered by inventors such as George Klein (MechE 2T8) in the 1950s, the fundamental technology has remained much the same. Most are controlled by joysticks, which may seem simple to use, but can be frustratingly cumbersome for many everyday tasks — from docking at a desk to traversing a narrow door frame. “Imagine parking a car in a tight space using only a tiny joystick,” says Professor Jonathan Kelly (UTIAS), who is leading the new collaboration. “That would be annoying for anyone.” The problem is compounded for users with multiple sclerosis, amytrophic lateral sclerosis (ALS, also known as Lou Gherig’s disease) or spinal cord injuries, who often lack upper body control, or those with Parkinson’s disease, who often have hand tremors. Some of these users employ devices known as the Sip-and-Puff (SNP) controllers, in which they input commands by sipping or puffing air using a plastic straw. They are an alternative to joysticks, but they can make complex tasks even more overwhelming. Robotic automation could address those challenges. Several groups around the world are working on self-driving wheelchairs, but most rely on high-end sensors that are priced out of reach of a typical consumer. Kelly, an expert in robotic sensing and perception, believes that the task could be accomplished for much less, thanks to a recent explosion in mass-produced sensor technology. He points to the Microsoft Kinect, which contains both a visible-spectrum camera and an infrared laser to detect distances. “Sensors like that used to cost thousands of dollars, but now you can buy them for less than $200,” says Kelly. “It has been a game-changer for robotics.” Automation could also help with tasks that are less complex, but more routine. For example, an autonomous wheelchair could use sensors to map a space and tag certain key locations, such as the kitchen, bedroom, etc. The user could then navigate to those spaces with a single command. Two years ago, Kelly was approached by Vivek Burhanpurkar, the CEO of Cyberworks Robotics, Inc. The company has a long history in autonomous robotics, including self-driving industrial cleaning machines, but Burhanpurkar saw an opportunity to move into assistive devices."</em> <a href="http://news.engineering.utoronto.ca/wheelchairs-get-robotic-retrofit-become-self-driving/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_LabScientistsExploreElectronic.jpg" alt="Lab scientists explore electronic properties of liquid electrolytes for energy technologies" class="lefter"></p>

<h2><a href="https://www.llnl.gov/news/lab-scientists-explore-electronic-properties-liquid-electrolytes-energy-technologies">Lab scientists explore electronic properties of liquid electrolytes for energy technologies</a></h2>

<p><em>"Liquid electrolytes are essential components in a variety of emerging energy technologies, including batteries, supercapacitors and solar-to-fuel devices. "To predict and optimize the performance of these devices, a detailed understanding of the electrolytes, particularly their electronic properties such as the ionization potential and electron affinity, is critical," said Anh Pham, a Lawrence Livermore National Laboratory (LLNL) Lawrence Fellow in the Quantum Simulations Group, and the lead author of a paper in the June 23 edition of Science Advances (link is external). As an example, Pham pointed to how proper energy alignment at the electrode-electrolyte interface of photoelectrochemical (PEC) cells is key to achieving efficient hydrogen production. Pham, along with LLNL researcher Eric Schwegler, Robert Seidel and Steven Bradforth from the University of Southern California, and Marco Govoni and Giulia Galli from the Argonne National Laboratory and the University of Chicago, have presented an experimentally validated simulation strategy for computing the electronic properties of aqueous electrolytes. The team directly simulated and measured the electronic excitation of various solvated ions in liquid water. By combining first-principles molecular dynamics simulations with state-of-the-art electronic structure methods, the team could predict the excitation energies of the solvents and solutes, such as the ionization potentials of the solvated ions. The team also demonstrated that the coupling of this theoretical framework with advanced spectroscopy techniques provides a powerful tool for the identification of chemical species and reactions that occur in solutions. The new method opens up the possibility to predict the electronic response in complex electrolytes for a range of applications. For example, the research provided a theoretical foundation for understanding and engineering the electronic properties of liquid electrolytes in PEC cells for hydrogen production and ionic liquid for batteries. "The proposed computational framework is general and applicable to non-metallic liquids, offering great promise in understanding and engineering solutions and liquid electrolytes for a variety of important energy technologies," Pham said. In a broader sense, the new simulation capability represents the first step toward a unified method for the simulation of realistic, heterogeneous interfaces in electrochemical systems."</em> <a href="https://www.llnl.gov/news/lab-scientists-explore-electronic-properties-liquid-electrolytes-energy-technologies">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_FluorineGrantsWhiteGrapheneNew.jpg" alt="Fluorine grants white graphene new powers" class="lefter"></p>

<h2><a href="http://news.rice.edu/2017/07/14/fluorine-grants-white-graphene-new-powers-2/">Fluorine grants white graphene new powers</a></h2>

<p><em>"A little fluorine turns an insulating ceramic known as white graphene into a wide-bandgap semiconductor with magnetic properties. Rice University scientists said that could make the unique material suitable for electronics in extreme environments. A proof-of-concept paper from Rice researchers demonstrates a way to turn two-dimensional hexagonal boron nitride (h-BN) – aka white graphene – from an insulator to a semiconductor. The magnetism, they said, is an unexpected bonus. Rice University graduate student Sruthi Radhakrishnan shows samples of pure hexagonal boron nitride and fluorinated hexagonal boron nitride. Fluorination turns the material known as white graphene, a common insulator, into a magnetic semiconductor that may be suitable for electronics and sensors in extreme environments. Because the atomically thin material is an exceptional conductor of heat, the researchers suggested it may be useful for electronics in high-temperature applications, perhaps even as magnetic memory devices. The discovery appears this week in Science Advances. “Boron nitride is a stable insulator and commercially very useful as a protective coating, even in cosmetics, because it absorbs ultraviolet light,” said Rice materials scientist Pulickel Ajayan, whose lab led the study. “There has been a lot of effort to try to modify its electronic structure, but we didn’t think it could become both a semiconductor and a magnetic material. “So this is something quite different; nobody has seen this kind of behavior in boron nitride before,” he said. The researchers found that adding fluorine to h-BN introduced defects into its atomic matrix that reduced the bandgap enough to make it a semiconductor. The bandgap determines the electrical conductivity of a material. “We saw that the gap decreases at about 5 percent fluorination,” said Rice postdoctoral researcher and co-author Chandra Sekhar Tiwary. The gap gets smaller with additional fluorination, but only to a point. “Controlling the precise fluorination is something we need to work on. We can get ranges but we don’t have perfect control yet. Because the material is atomically thin, one atom less or more changes quite a bit. “In the next set of experiments, we want to learn to tune it precisely, atom by atom,” he said."</em> <a href="http://news.rice.edu/2017/07/14/fluorine-grants-white-graphene-new-powers-2/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_NewMaterialsAtTheTouchOfAButto.jpg" alt="New materials at the touch of a button" class="lefter"></p>

<h2><a href="http://www.manchester.ac.uk/discover/news/new-materials-at-the-touch-of-a-button/">New materials at the touch of a button</a></h2>

<p><em>"The rapidly developing science and technology of graphene and atomically-thin materials has taken another step forward with new research from The University of Manchester. This research, published in Science, shows how a variety of different electronic properties – essentially new materials - can be realised simply by applying a magnetic field. Electrons inside materials move quite differently from a free electron in vacuum: their properties are strongly affected by the electric potential of ions comprising the crystal lattice. This interaction changes the mass of electrons and makes materials either metals, semiconductors or insulators, depending on the detailed atomic structure. This provides the great variety of material properties we know and work with. Earlier, the researchers at The University of Manchester have found ways to create new materials with bespoke electronic properties by placing one electronic material (in this case graphene) on top of another crystal, hexagonal boron nitride. Now, they demonstrate how to create a whole sequence of different electronic materials by simply tuning the applied magnetic field. In this combination of materials, boron nitride atoms create a periodic pattern for electrons in graphene known as a superlattice. Such a superlattice is characterised by the length scale of the periodic pattern, whereas the strength of applied magnetic field can be counted in so-called flux quanta, elementary units of magnetic field. A matching condition is achieved each time when an integer fraction of the flux quantum penetrates through an area given by the elementary superlattice. At these special values of magnetic field, the researchers observed that electrons started moving along straight lines, as if the magnetic field were absent. This is in stark contrast to the known behaviour of electrons in a magnetic field where electrons must move along curved trajectories known as cyclotron orbits. As a result of these changes from straight to curved trajectories and back at many matching conditions, the researchers found oscillations in electrical conductivity of graphene superlattices."</em> <a href="http://www.manchester.ac.uk/discover/news/new-materials-at-the-touch-of-a-button/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_ResearchMakesRobotsBetterAtFol.jpg" alt="Research makes robots better at following spoken instructions" class="lefter"></p>

<h2><a href="https://news.brown.edu/articles/2017/07/language">Research makes robots better at following spoken instructions</a></h2>

<p><em>"A new software system helps robots to more effectively act on instructions from people, who by nature give commands that range from simple and straightforward to those that are more complex and imply a myriad of subtasks. A new system based on research by Brown University computer scientists makes robots better at following spoken instructions, no matter how abstract or specific those instructions may be. The development, which was presented this week at the Robotics: Science and Systems 2017 conference in Boston, is a step toward robots that are able to more seamlessly communicate with human collaborators. The research was led by Dilip Arumugam and Siddharth Karamcheti, both undergraduates at Brown when the work was performed (Arumugam is now a Brown graduate student). They worked with graduate student Nakul Gopalan and postdoctoral researcher Lawson L.S. Wong in the lab of Stefanie Tellex, a professor of computer science at Brown. “The issue we’re addressing is language grounding, which means having a robot take natural language commands and generate behaviors that successfully complete a task,” Arumugam said. “The problem is that commands can have different levels of abstraction, and that can cause a robot to plan its actions inefficiently or fail to complete the task at all.” For example, imagine someone in a warehouse working side-by-side with a robotic forklift. The person might say to the robotic partner, “Grab that pallet.” That’s a highly abstract command that implies a number of smaller sub-steps — lining up the lift, putting the forks underneath and hoisting it up. However, other common commands might be more fine-grained, involving only a single action: “Tilt the forks back a little,” for example. Those different levels of abstraction can cause problems for current robot language models, the researchers say. Most models try to identify cues from the words in the command as well as the sentence structure and then infer a desired action from that language. The inference results then trigger a planning algorithm that attempts to solve the task. But without taking into account the specificity of the instructions, the robot might overplan for simple instructions, or underplan for more abstract instructions that involve more sub-steps. That can result in incorrect actions or an overly long planning lag before the robot takes action. But this new system adds an additional level of sophistication to existing models. In addition to simply inferring a desired task from language, the new system also analyzes the language to infer a distinct level of abstraction."</em> <a href="https://news.brown.edu/articles/2017/07/language">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_HelpingRobotsLearnToSeeIn3D.jpg" alt="Helping Robots learn to see in 3-D" class="lefter"></p>

<h2><a href="https://today.duke.edu/2017/07/helping-robots-learn-see-3-d">Helping Robots learn to see in 3-D</a></h2>

<p><em>"Autonomous robots can inspect nuclear power plants, clean up oil spills in the ocean, accompany fighter planes into combat and explore the surface of Mars. Yet for all their talents, robots still can’t make a cup of tea. That’s because tasks such as turning the stove on, fetching the kettle and finding the milk and sugar require perceptual abilities that, for most machines, are still a fantasy. Among them is the ability to make sense of 3-D objects. While it’s relatively straightforward for robots to “see” objects with cameras and other sensors, interpreting what they see, from a single glimpse, is more difficult. Duke University graduate student Ben Burchfiel says the most sophisticated robots in the world can’t yet do what most children do automatically, but he and his colleagues may be closer to a solution. Burchfiel and his thesis advisor George Konidaris, now an assistant professor of computer science at Brown University, have developed new technology that enables machines to make sense of 3-D objects in a richer and more human-like way. A robot that clears dishes off a table, for example, must be able to adapt to an enormous variety of bowls, platters and plates in different sizes and shapes, left in disarray on a cluttered surface. Humans can glance at a new object and intuitively know what it is, whether it is right side up, upside down or sideways, in full view or partially obscured by other objects. Even when an object is partially hidden, we mentally fill in the parts we can’t see. Their robot perception algorithm can simultaneously guess what a new object is, and how it’s oriented, without examining it from multiple angles first. It can also “imagine” any parts that are out of view. A robot with this technology wouldn’t need to see every side of a teapot, for example, to know that it probably has a handle, a lid and a spout, and whether it is sitting upright or off-kilter on the stove. The researchers say their approach, which they presented July 12 at the 2017 Robotics: Science and Systems Conference in Cambridge, Massachusetts, makes fewer mistakes and is three times faster than the best current methods. This is an important step toward robots that function alongside humans in homes and other real-world settings, which are less orderly and predictable than the highly controlled environment of the lab or the factory floor, Burchfiel said. With their framework, the robot is given a limited number of training examples, and uses them to generalize to new objects."</em> <a href="https://today.duke.edu/2017/07/helping-robots-learn-see-3-d">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_NoBatteryNoWireNoProblem.jpg" alt="No battery, no wire, no problem" class="lefter"></p>

<h2><a href="https://wyss.harvard.edu/no-battery-no-wire-no-problem/">No battery, no wire, no problem</a></h2>

<p><em>"The traditional Japanese art of origami transforms a simple sheet of paper into complex, three-dimensional shapes through a very specific pattern of folds, creases, and crimps. Folding robots based on that principle have emerged as an exciting new frontier of robotic design, but generally require onboard batteries or a wired connection to a power source, making them bulkier and clunkier than their paper inspiration and limiting their functionality. A team of researchers at the Wyss Institute for Biologically Inspired Engineering and the John A. Paulson School of Engineering and Applied Sciences (SEAS) at Harvard University has created battery-free folding robots that are capable of complex, repeatable movements powered and controlled through a wireless magnetic field. “Like origami, one of the main points of our design is simplicity,” says co-author Je-sung Koh, Ph.D., who conducted the research as a Postdoctoral Fellow at the Wyss Institute and SEAS and is now an Assistant Professor at Ajou University in South Korea. “This system requires only basic, passive electronic components on the robot to deliver an electric current – the structure of the robot itself takes care of the rest.” The research is reported in Science Robotics. The research team’s robots are flat and thin (resembling the paper on which they’re based) plastic tetrahedrons, with the three outer triangles connected to the central triangle by hinges, and a small circuit on the central triangle. Attached to the hinges are coils made of a type of metal called shape-memory alloy (SMA) that can recover its original shape after deformation by being heated to a certain temperature. When the robot’s hinges lie flat, the SMA coils are stretched out in their “deformed” state; when an electric current is passed through the circuit and the coils heat up, they spring back to their original, relaxed state, contracting like tiny muscles and folding the robots’ outer triangles in toward the center. When the current stops, the SMA coils are stretched back out due to the stiffness of the flexure hinge, thus lowering the outer triangles back down."</em> <a href="https://wyss.harvard.edu/no-battery-no-wire-no-problem/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_BringingNeuralNetworksToCellph.jpg" alt="Bringing neural networks to cellphones" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/bringing-neural-networks-cellphones-0718">Bringing neural networks to cellphones</a></h2>

<p><em>"In recent years, the best-performing artificial-intelligence systems — in areas such as autonomous driving, speech recognition, computer vision, and automatic translation — have come courtesy of software systems known as neural networks. But neural networks take up a lot of memory and consume a lot of power, so they usually run on servers in the cloud, which receive data from desktop or mobile devices and then send back their analyses. Last year, MIT associate professor of electrical engineering and computer science Vivienne Sze and colleagues unveiled a new, energy-efficient computer chip optimized for neural networks, which could enable powerful artificial-intelligence systems to run locally on mobile devices. Now, Sze and her colleagues have approached the same problem from the opposite direction, with a battery of techniques for designing more energy-efficient neural networks. First, they developed an analytic method that can determine how much power a neural network will consume when run on a particular type of hardware. Then they used the method to evaluate new techniques for paring down neural networks so that they’ll run more efficiently on handheld devices. The researchers describe the work in a paper they’re presenting next week at the Computer Vision and Pattern Recognition Conference. In the paper, they report that the methods offered as much as a 73 percent reduction in power consumption over the standard implementation of neural networks, and as much as a 43 percent reduction over the best previous method for paring the networks down."</em> <a href="http://news.mit.edu/2017/bringing-neural-networks-cellphones-0718">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_ManipulatingElectronSpinsWitho.jpg" alt="Manipulating Electron Spins Without Loss of Information" class="lefter"></p>

<h2><a href="https://www.unibas.ch/en/News-Events/News/Uni-Research/Manipulating-Electron-Spins-Without-Loss-of-Information.html">Manipulating Electron Spins Without Loss of Information</a></h2>

<p><em>"Physicists have developed a new technique that uses electrical voltages to control the electron spin on a chip. The newly-developed method provides protection from spin decay, meaning that the contained information can be maintained and transmitted over comparatively large distances, as has been demonstrated by a team from the University of Basel’s Department of Physics and the Swiss Nanoscience Institute. The results have been published in Physical Review X. For several years, researchers have been trying to use the spin of an electron to store and transmit information. The spin of each electron is always coupled to its motion, i.e. its orbit within the chip. This spin-orbit coupling allows targeted manipulation of the electron spin by an external electric field, but it also causes the spin’s orientation to decay, which leads to a loss of information. In an international collaboration with colleagues from the US and Brazil, scientists from the University of Basel’s Department of Physics and the Swiss Nanoscience Institute, headed by Professor Dominik Zumbühl, have developed a new method that allows for targeted spin manipulation without the accompanying decay."</em> <a href="https://www.unibas.ch/en/News-Events/News/Uni-Research/Manipulating-Electron-Spins-Without-Loss-of-Information.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_A100YearOldPhysicsProblemHasBe.jpg" alt="A 100-year-old physics problem has been solved at EPFL" class="lefter"></p>

<h2><a href="https://actu.epfl.ch/news/a-100-year-old-physics-problem-has-been-solved-at-/">A 100-year-old physics problem has been solved at EPFL</a></h2>

<p><em>"EPFL researchers have found a way around what was considered a fundamental limitation of physics for over 100 years. They were able to conceive resonant systems that can store electromagnetic waves over a long period of time while maintaining a broad bandwidth. Their study, which has just been published in Science, opens up a number of doors, particularly in telecommunications. At EPFL, researchers challenge a fundamental law and discover that more electromagnetic energy can be stored in wave-guiding systems than previously thought. The discovery has implications in telecommunications. Working around the fundamental law, they conceived resonant and wave-guiding systems capable of storing energy over a prolonged period while keeping a broad bandwidth. Their trick was to create asymmetric resonant or wave-guiding systems using magnetic fields. The study, which has just been published in Science, was led by Kosmas Tsakmakidis, first at the University of Ottawa and then at EPFL’s Bionanophotonic Systems Laboratory run by Hatice Altug, where the researcher is now doing post-doctoral research. This breakthrough could have a major impact on many fields in engineering and physics. The number of potential applications is close to infinite, with telecommunications, optical detection systems and broadband energy harvesting representing just a few examples. Resonant and wave-guiding systems are present in the vast majority of optical and electronic systems. Their role is to temporarily store energy in the form of electromagnetic waves and then release them. For more than 100 hundred years, these systems were held back by a limitation that was considered to be fundamental: the length of time a wave could be stored was inversely proportional to its bandwidth. This relationship was interpreted to mean that it was impossible to store large amounts of data in resonant or wave-guiding systems over a long period of time because increasing the bandwidth meant decreasing the storage time and quality of storage. This law was first formulated by K. S. Johnson in 1914, at Western Electric Company (the forerunner of Bell Telephone Laboratories). He introduced the concept of the Q factor, according to which a resonator can either store energy for a long time or have a broad bandwidth, but not both at the same time. Increasing the storage time meant decreasing the bandwidth, and vice versa. A small bandwidth means a limited range of frequencies (or ‘colors’) and therefore a limited amount of data. Until now, this concept had never been challenged. Physicists and engineers had always built resonant systems – like those to produce lasers, make electronic circuits and conduct medical diagnoses – with this constraint in mind. But that limitation is now a thing of the past. The researchers came up with a hybrid resonant / wave-guiding system made of a magneto-optic material that, when a magnetic field is applied, is able to stop the wave and store it for a prolonged period, thereby accumulating large amounts of energy. Then when the magnetic field is switched off, the trapped pulse is released. With such asymmetric and non-reciprocal systems, it was possible to store a wave for a very long period of time while also maintaining a large bandwidth. The conventional time-bandwidth limit was even beaten by a factor of 1,000. The scientists further showed that, theoretically, there is no upper ceiling to this limit at all in these asymmetric (non-reciprocal) systems."</em> <a href="https://actu.epfl.ch/news/a-100-year-old-physics-problem-has-been-solved-at-/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_NewExperimentConfirmsViolation.jpg" alt="New experiment confirms violation of Bell’s inequality" class="lefter"></p>

<h2><a href="http://www.en.uni-muenchen.de/news/newsarchiv/2017/weinfurter_bellsinequality.html">New experiment confirms violation of Bell’s inequality</a></h2>

<p><em>"Physicists led by Professor Harald Weinfurter and Dr. Wenjamin Rosenfeld have carried out measurements to test Bell’s inequality. Their results clearly contradict certain fundamental assumptions of classical physics. The study appears in the journal Physical Review Letters. “Nature is different from what we observe with our five senses”, says Harald Weinfurter. Bell’s inequality, introduced by the Irish physicist John Bell in 1964 can be used to test the validity of classical physics and their inconsistencies with quantum mechanics. In the world view of classical physics properties of objects exist independent of being observed (realism), and no information or physical influence can propagate faster than the speed of light (locality). However, the world of quantum particles is ruled by laws that are quite the opposite: two particles can be connected in a non-local way over large distances, and the property of a particle may not be defined until the instant it is being measured. Though all experiments so far have confirmed the predictions of quantum mechanics, advocates of local realism still found loopholes for their classical interpretation. The locality loophole concerns the strict spacelike separation of the two observers. In the Munich experiment, this is warranted by the fact that one of the laboratories is located in the basement of the physics department (Schellingstraße), the other one in the basement of the economics department of the LMU (Schackstraße). In each lab, a single rubidium atom is stored in an optical trap and excited to emit a single photon. That way, the spin-state of the atom and the polarization state of the photon are being entangled. The photons are coupled into optical fibres and guided to a set-up where they are brought to interference. “Our two observer stations are independently operated and are equipped with their own laser and control systems”, Wenjamin Rosenfeld, leader of the project, points out. “Because of the 400 metres distance between the laboratories, communication from one to the other would take 1328 nanoseconds, which is much more than the duration of the measurement process. So, no information on the measurement in one lab can be used in the other lab. That’s how we close the locality loophole.” “Simultaneous registration of the photons that were brought to interference heralds the entanglement of the two rubidium atoms,” Harald Weinfurter explains. Quantum entanglement of two particles implies a strong correlation of their properties. As a consequence, the spins of the two trapped rubidium atoms are expected to point into the same direction, or into the opposite direction, depending on the kind of entanglement. In a measurement run of eight days the scientists collected around 10.000 events. The analysis of the data showed, that far more atoms were in the same state (or in the opposite state respectively) than would be expected for a classical distribution. In fact, a violation of Bell’s inequality of more than 6 standard deviations was obtained. “We were able to determine the spin-state of the atoms very fast and very efficiently. Thereby we closed a second potential loophole: the assumption, that the observed violation is caused by an incomplete sample of detected atom pairs”, says Wenjamin Rosenfeld."</em>  <a href="http://www.en.uni-muenchen.de/news/newsarchiv/2017/weinfurter_bellsinequality.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT116_ArtificialIntelligenceSuggests.jpg" alt="Artificial intelligence suggests recipes based on food photos" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/artificial-intelligence-suggests-recipes-based-on-food-photos-0720">Artificial intelligence suggests recipes based on food photos</a></h2>

<p><em>"There are few things social media users love more than flooding their feeds with photos of food. Yet we seldom use these images for much more than a quick scroll on our cellphones. Researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) believe that analyzing photos like these could help us learn recipes and better understand people's eating habits. In a new paper with the Qatar Computing Research Institute (QCRI), the team trained an artificial intelligence system called Pic2Recipe to look at a photo of food and be able to predict the ingredients and suggest similar recipes. “In computer vision, food is mostly neglected because we don’t have the large-scale datasets needed to make predictions,” says Yusuf Aytar, an MIT postdoc who co-wrote a paper about the system with MIT Professor Antonio Torralba. “But seemingly useless photos on social media can actually provide valuable insight into health habits and dietary preferences.” The paper will be presented later this month at the Computer Vision and Pattern Recognition conference in Honolulu. CSAIL graduate student Nick Hynes was lead author alongside Amaia Salvador of the Polytechnic University of Catalonia in Spain. Co-authors include CSAIL postdoc Javier Marin, as well as scientist Ferda Ofli and research director Ingmar Weber of QCRI."</em> <a href="http://news.mit.edu/2017/artificial-intelligence-suggests-recipes-based-on-food-photos-0720">[...]</a>
 </SPAN></DIV></p>

<h1 id="Documentacao">Documentação</h1>

<p>A documentação é parte essencial do processo de aprendizagem e a Internet além de artigos interessantes de explorar também tem alguma documentação em formato PDF interessante de ler. Todos os <em>links</em> aqui apresentados são para conteúdo disponibilizado livremente pelo editor do livro.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB116_TheSignal.jpg" alt="The Signal" class="lefter"></p>

<h2><a href="http://www.ti.com/lit/sg/slyt701/slyt701.pdf">The Signal</a></h2>

<p><em>"Learning analog seems like a daunting task. Analog engineers do not generally acquire their experience in a linear path from start to finish: They zigzag a path through an obstacle course of hurdles. They acquire insights in small pieces – a bit here and a bite (not a byte) there. Slowly, puzzle pieces fit into place, and hazy concepts come into focus. We will never have the satisfaction of jumping a final hurdle or tapping the final puzzle piece into place; that just won’t happen. Colleagues much smarter than I am cannot answer all of my questions … and I cannot answer all of yours. So this assemblage of little analog lessons is hopelessly incomplete. Still, I think you will find it helpful. It may fill some gaps in your knowledge or stimulate your thinking. Each topic addressed in this book was originally published as a post on my blog, “The Signal,” which you can still visit on TI’s E2E™ Community. As such, you’ll find that the lessons are short and to the point; practical and intuitive; bite-sized and easy to digest. I needed it to be that way because I’m a simple guy with little patience. Most of my blog posts sparked questions and other dialogue. I have included links at the end of each topic to the original post when comments were posted. I think you will find some valuable lessons taught there. Furthermore, this compendium does not include all of my blogs. I’ve included links to other topics, at the end. If you have any questions about the topics I cover here, or any other precision-amplifier questions for that matter, I hope you will submit them to the Precision Amplifiers forum on TI’s E2E Community. For reference, I created most of the images in this e-book using TI’s TINA-TI™ free software tool, downloadable from TI’s website."</em> <a href="http://www.ti.com/lit/sg/slyt701/slyt701.pdf">[...]</a>
 </SPAN></DIV></p>

<h1 id="Projetos-Maker">Projetos Maker</h1>

<p>Diversos Projetos interessantes.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_DiyBoneConductionHeadphones.jpg" alt="DIY Bone Conduction Headphones" class="lefter"></p>

<h2><a href="http://wesleythoneycutt.com/diy-bone-conduction-headphones/">DIY Bone Conduction Headphones</a></h2>

<p><em>"I discovered something fascinating while browsing around the other day: headphones that transmit sound directly to your skull.  This method of sound transfer has been dubbed bone conduction.  All you do is press the little transducers up to your temple, jaw, or skull, and the vibrations in the little electrical device transfer to the waves through the solid bone medium to your inner ear.  This way you can listen to things without blocking your ears with big cans or buds.  Rather than go out and purchase one of the little premade units, I decided to make my own DIY bone conduction headphones. I have my own issues with headphones.  I am the type who strongly prefers earbuds.  Sure, you can get better sound out of headphones, but I find that the large strap and bulky padding smashes my ears and glasses together in an uncomfortable way.  Furthermore, the shape of my skull with causes the applied pressure of the headphones to pull my glasses out of alignment.  That puts pressure on one side of my nose or the other, and it makes my vision all out of alignment.  To make things just that much worse, my very fine hair is easily molded, a quality that makes it easy to get ready in the morning but causes instant hat hair.  Headphone bands give me this weird wave in my perfect, voluminous follicle coif.  If you look at the bone conductivity headphones available on the market, they all use a strap to keep them in place like a normal pair of headphones.  With the extra pressure required to push the transducers up to my jaw, I can only imagine that they would have even more issues. So I thought to myself: how can I make a set of DIY bone conduction headphones with properties closer to earbuds? Answer: use the straps that you wear every day, your glasses."</em> <a href="http://wesleythoneycutt.com/diy-bone-conduction-headphones/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_HydroDipping3DPrints.jpg" alt="Hydro Dipping 3D Prints" class="lefter"></p>

<h2><a href="https://learn.adafruit.com/hydro-dip-3d-prints/hydro-dipping">Hydro Dipping 3D Prints</a></h2>

<p><em>"Add Full color graphics to 3D Printed parts! In this week’s project, we’re hydro dipping 3d printed parts. Hydro dipping also know as Water Drape Film, Water Transfer or Inkjet Water Slide Decal Transfer, is a post-processing technique that allows you to wrap graphics around objects. So with this method, you can add some pretty cool textures and full color graphics to your projects. Hydro dipping is commonly used on machined and injection molded parts, but we found it also works great on 3d printed parts. So you’re able to add high quality textures and graphics without lots of post processing. It even works with visible layer lines that you get with 3d printed parts."</em> <a href="https://learn.adafruit.com/hydro-dip-3d-prints/hydro-dipping">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_KeyChainUsbPowerSupplyForBread.jpg" alt="Key Chain USB Power Supply (For Bread Board Projects)" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Key-Chain-USB-Power-Supply-For-Bread-Board-Project/">Key Chain USB Power Supply (For Bread Board Projects)</a></h2>

<p><em>"Hi everyone ,In this instructable, i am gonna share with you how i made these simple key chain USB power supplies that gives separate outputs from 1 to 5 V DC.These can be used for bread board experiments that need low voltage dc supplies."</em> <a href="http://www.instructables.com/id/Key-Chain-USB-Power-Supply-For-Bread-Board-Project/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_SmartLampWithEsp8266AmazonEcho.jpg" alt="Smart Lamp With ESP8266 & Amazon Echo" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Smart-Lamp-With-ESP8266-Amazon-Echo/">Smart Lamp With ESP8266 &amp; Amazon Echo</a></h2>

<p><em>"This Instructable guides you along with me in upgrading a vintage lamp with voice-control using an ESP8266 microntroller and Amazon Echo/Alexa. The Arduino code emulates a Belkin WeMo device using the fauxmoESP library, which makes setup a breeze.For a full primer on the Arduino ESP8266 workflow, check out my free Instructables Internet of Things Class, and check out Paige's Lamps Class for more lighting inspiration and know-how. If you're new to Arduino, we have an intro class for that, too.This project uses AC electricity, which could harm you or start a fire-- don't leave this project connected to power unattended, and if you don't know what you're doing, work under the supervision of someone who does."</em> <a href="http://www.instructables.com/id/Smart-Lamp-With-ESP8266-Amazon-Echo/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_RetroPrototypingGreatForTeachi.jpg" alt="Retro Prototyping, Great for Teaching" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Retro-Prototyping-Great-for-Teaching/">Retro Prototyping, Great for Teaching</a></h2>

<p><em>"Have you ever wondered where the term "Breadboard" came from? Here's an example of what breadboards were all about. In the early days of electronics, components were large and cumbersome. They didn't have transistors or integrated circuits, only vacuum tubes. So it was common practice to build prototype circuits on a block of wood using nails or screws as circuit tie points. Tube sockets could be screwed down with standoffs, transformers and larger components were also screwed to the board. Resistors, capacitors and coils could be soldered to nailheads.This technique is still useful for some circuits. This is an example of a project I had for kids who wanted to learn electronics. They could build the circuit, following a schematic. When finished, they could take the circuit home and keep it. It did not have to be disassembled for the next user, as is the case with modern solderless breadboards. The circuit here is a simple astable multivibrator. The red and green LEDs alternate. The flashing rate is determined by the RC time constant of the resistors and capacitors."</em> <a href="http://www.instructables.com/id/Retro-Prototyping-Great-for-Teaching/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_RaspberryPiTumblrGifPhotoBooth.jpg" alt="Raspberry Pi Tumblr GIF Photo Booth" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Raspberry-Pi-Tumblr-GIF-Photo-Booth/">Raspberry Pi Tumblr GIF Photo Booth</a></h2>

<p><em>"This beginner Raspberry Pi project shows you how to use Python code to turn your Pi camera into a GIF-making, Tumblr-posting photo booth! This project is an except from my free Raspberry Pi Class, so definitely check that out for more in-depth info on the system setup!I've attached the final Python program for my photo booth. I'll go over this script later in the process.If you download the optional sound files to your Pi, move them to a sounds directory in the same directory as the Python script."</em> <a href="http://www.instructables.com/id/Raspberry-Pi-Tumblr-GIF-Photo-Booth/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_Esp8266Esp12EArduinoClockWOuts.jpg" alt="ESP8266 ESP-12E Arduino Clock W/ Outside Temp & LEGOS & NeoPixel Ring" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/ESP8266-ESP-12E-Arduino-Clock-W-Outside-Temp-LEGOS/">ESP8266 ESP-12E Arduino Clock W/ Outside Temp &amp; LEGOS &amp; NeoPixel Ring</a></h2>

<p><em>"We went all 'cord-cutter' and ditched our Cable box and realized something was now missing in our family room...the oh so familiar LCD clock that was always present. I decided to get to work on a replacement and had some fun with it. If you're like me you've ordered an Arduino kit here and there when the price was right and have parts hiding all over your abode. And...odds are you have leftover Legos from all of those theme kits you've bought for your kids over the years. Who needs a 3D printer...HAVE SOME FUN...IT'S GEEKOUT LEGO TIME!This project grabs your local time from an NTP server and your local temp from Wunderground. Mine is powered by one of our TV's USB ports. Read on get CREATIVE and have fun!"</em> <a href="http://www.instructables.com/id/ESP8266-ESP-12E-Arduino-Clock-W-Outside-Temp-LEGOS/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_ArduinoControlledUsbTrackpad.jpg" alt="Arduino Controlled USB Trackpad" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Controlled-USB-Trackpad/">Arduino Controlled USB Trackpad</a></h2>

<p><em>"Every time a new raspberry pi comes out I take a look at the specs and think to myself "I really want to make a laptop out of that" but one issue always arises and that is that I can never find a stand alone USB trackpad for the laptop. So in this project, we will be salvaging a trackpad from an old broken laptop and converting it to USB device using an Arduino pro micro."</em> <a href="http://www.instructables.com/id/Arduino-Controlled-USB-Trackpad/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_SmartParkingUsingArduinoUno.jpg" alt="Smart Parking Using Arduino Uno " class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Smart-Parking-Using-Arduino-Uno/">Smart Parking Using Arduino Uno </a></h2>

<p><em>"Imagine a parking lot with 100 parking spaces, what you donowadays is physically check the status(vacant/Busy) of each and every parking space resulting to loss of fuel as well as time. But what if I provide you with a solution in which the status of each and every parking space is visible to you as soon as you enter the parking lot telling you which parking space is free and which is not (like Site 1 is free, Site 83 is Free), plus if the site is free a green led would glow and if not, a red one would."</em> <a href="http://www.instructables.com/id/Smart-Parking-Using-Arduino-Uno/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_Esp8266PublicFreeMqttBrokerHiv.jpg" alt="ESP8266 & Public "Free" MQTT Broker HiveMQ & Node-RED" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/ESP8266-Public-Free-MQTT-Broker-HiveMQ-Node-RED/">ESP8266 &amp; Public "Free" MQTT Broker HiveMQ &amp; Node-RED</a></h2>

<p><em>"The MQTT protocol has taken great strength in recent years since it is simple, safe, practical and lightweight perfect for IoT and M2M applications.Thanks to the contribution of developers and developers of MQTT applications, there are public MQTT Broker for Internet monitoring and control tests, are available to connect from any MQTT client in this case we will use HIVEMQ, which has dashboard to view MQTT connections and Web sockets, since it is public should have some considerations that we will see below."</em> <a href="http://www.instructables.com/id/ESP8266-Public-Free-MQTT-Broker-HiveMQ-Node-RED/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_IotPowerConsumptionConcern.jpg" alt="IoT Power Consumption Concern" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/IoT-Power-Consumption-Concern/">IoT Power Consumption Concern</a></h2>

<p><em>"This instructables show how to measure the power consumption in an IoT project.And also show some well known methods how to reduce the power consumption. Most IoT is not wired but connecting the Internet, so power consumption is a big concern. Subsequent to my previous instructables - ATtinyPowerMeter, its time to use it measure the power consumption."</em> <a href="http://www.instructables.com/id/IoT-Power-Consumption-Concern/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_OffGridVanPowerInformationSyst.jpg" alt="Off Grid Van Power Information System" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Off-Grid-Van-Power-Information-System/">Off Grid Van Power Information System</a></h2>

<p><em>"This off grid solar power information system is perfect for your Van or RV. It gives you a complete view of your Van’s power consumption and solar panel generation, it also predicts how long your batteries are going to last for and how much power is being generated by your solar panels. That's one less thing to worry about!A quick look at the indicator lights tells you when your solar panels are charging your batteries, when they are generating more power than you are using as well as when your batteries are almost flat. An alarm sounds if your batteries are then further discharged to the point where they are at risk of being damaged.The LCD provides you with detailed information on how much power your batteries have stored, how much is being used, how much is being generated by your solar panels and how long your batteries will last for. The circuit is really simple to assemble and doesn’t require much soldering, it can be assembled on a breadboard if you are not confident soldering. You will need to know the basics of programming an Arduino, if you haven’t done this before – here is a useful guide to getting started with Arduino. You will also need to know roughly how to connect an LCD screen to an Arduino. If you like this Instructable, please vote for it in the Van Life contest using the Vote button on the top right of the guide."</em> <a href="http://www.instructables.com/id/Off-Grid-Van-Power-Information-System/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_GatewayNodeRedEsp8266ModbusRtu.jpg" alt="Gateway:  Node-RED + ESP8266 Modbus RTU MQTT + HMI Industrial Panasonic" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Gateway-Node-RED-ESP8266-Modbus-RTU-MQTT-HMI-Indus/">Gateway:  Node-RED + ESP8266 Modbus RTU MQTT + HMI Industrial Panasonic</a></h2>

<p><em>"Given the growth of IoT applications using the MQTT protocol as a base and the Node-RED platform, we have created a possibility for industrial devices or devices using Modbus RTU protocol (RS232 or RS485) to interact with applications or IoT platforms that use MQTT in This Node-RED case.In the industry there is a large number of Monitoring and Control Devices that have Modbus RTU such as Counters, Meters (Flow, Electrical, Temperature, Humidity, etc.), Industrial Controllers PLC, PAC, HMI Screens, Speed Inverters, For which the only possibility of extracting and concentrating data through OPC servers.Some of the components required for building &amp; testing:ESP8266 12E Node MCU MAX232 (RS232 to TTL)HMI GT05 Panasonic RS232 (Any device or PLC controller that supports Modbus RTU RS232)Power supply Meanwell 5vNote:You could use any ESP8266, but in this case it is used (softwareserial), if you want to use ESP8266 01 you must modify the Modbus library to replace the "SoftwareSerial" port with the "Serial" port by default."</em> <a href="http://www.instructables.com/id/Gateway-Node-RED-ESP8266-Modbus-RTU-MQTT-HMI-Indus/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_UltimateDiyBreadboardPowerSupp.jpg" alt="Ultimate DIY Breadboard Power Supply" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Ultimate-DIY-Breadboard-Power-Supply/">Ultimate DIY Breadboard Power Supply</a></h2>

<p><em>"For prototyping, nothing beats a breadboard! But how to provide power to the little black and red rails that fuel our designs? There are a couple of conventional options:A bench/lab variable power supply. A must-have to be sure, but expensive, big and (arguably) overkill for low power circuit design and general hobbyists.Jumping power from an Arduino. Useful for testing, but it adds to the jumper clutter. Also, it can be useful to save those 5V / 3.3V rails for powering something else, rather than just feeding a breadboard.Batteries. Nothing kills maker-mojo faster than battery anxiety! So I decided to design something that could do one job - power any breadboard - and do it really well, with enough options to make it indispensable for small prototyping projects."</em> <a href="http://www.instructables.com/id/Ultimate-DIY-Breadboard-Power-Supply/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_ArduinoMpu6050Gy5216AxisAccele.jpg" alt="Arduino - MPU6050 GY521 - 6 Axis Accelerometer + Gyro (3D Simulation With Processing)" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-MPU6050-GY521-6-Axis-Accelerometer-Gyro-3D/">Arduino - MPU6050 GY521 - 6 Axis Accelerometer + Gyro (3D Simulation With Processing)</a></h2>

<p><em>"In this tutorial we will learn how to use MPU6050 6 Axis Accelerometer + Gyro module and GY 521 breakout boards. * Also we will install the necessary libraries to Arduino IDE. * And last, we would run the simple simulation with this module using the Processing. * We can make Quadcopter Drone, RC Plane and Robotic projects using with the MPU6050 module."</em> <a href="http://www.instructables.com/id/Arduino-MPU6050-GY521-6-Axis-Accelerometer-Gyro-3D/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_GlowingPolishHorseshoesBeersbe.jpg" alt="Glowing Polish Horseshoes (Beersbee) Outdoor Arduino Game" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Glowing-Polish-Horseshoes-Beersbee-Outdoor-Arduino/">Glowing Polish Horseshoes (Beersbee) Outdoor Arduino Game</a></h2>

<p><em>"This outdoor game is the perfect combination of all things summer. Specifically, it combines Frisbee, Glow-in-the-Dark, backyard games, and (most importantly) ice cold beverages. This game goes by many names (Polish Horseshoes, French Darts), but its most endearing title is Beersbee. Before you hop into this project (yes, that was a terrible beer pun [ don't worry I won't do it again]), I would recommend familiarizing yourself with the rules of Beersbee. If you haven't played Beersbee before or would like a refresher on the rules I would recommend reading the Wikipedia article on Polish Horseshoes (here's a link to the article: https://en.wikipedia.org/wiki/Polish_horseshoes ). In a nutshell, two teams of two people take turns tossing the disk at their opponents' pole in an attempt to knock over the bottle. The LEDs within the pole allow for the outdoor fun to continue after the sun goes down. There are six green LED's in each pole that are programed to flash in a pattern. A white LED is placed at the top of the pole to make the bottle glow. If the pole or bottle is hit, Piezo sensors will trigger the Ardiuno Nano. The pole will begin flashing and a red LED will turn on. In addition, a Piezo buzzer provides audio feedback."</em> <a href="http://www.instructables.com/id/Glowing-Polish-Horseshoes-Beersbee-Outdoor-Arduino/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_DistanceMeasurementVehicleViaW.jpg" alt="Distance Measurement Vehicle via Websocket" class="lefter"></p>

<h2><a href="https://www.hackster.io/kbcloud/distance-measurement-vehicle-via-websocket-c312bc">Distance Measurement Vehicle via Websocket</a></h2>

<p><em>"A vehicle measures distance with its an encoder on its wheel. It is remotely controlled and transmits the distance via Websocket. When you measure distance between two point general way is to use a ruler. But you can use a lot of other ways: by laser, map, foot or walking meter. The walking meter is very useful when you are measuring curved (not straight) distance. But it might be very tired because you should walk the entire distance."</em> <a href="https://www.hackster.io/kbcloud/distance-measurement-vehicle-via-websocket-c312bc">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_ControllingNeopixelsWithAWebse.jpg" alt="Controlling NeoPixels with a Webserver on an ESP8266" class="lefter"></p>

<h2><a href="https://www.hackster.io/remnis/controlling-neopixels-with-a-webserver-on-an-esp8266-0381c7">Controlling NeoPixels with a Webserver on an ESP8266</a></h2>

<p><em>"Using the ESP8266 to control a Neopixel with a Webserver on the ESP. I always wanted one of those fancy LED stripes that you can control with your mobile or tablet. Should be easy to install, lightweight and customiseable. Well, my brother-in-law is fascinated of this topic as I am. And Christmas was at our doorstep. So what better to do than try to build him a DIY-light. Well getting started with it was quite frustrating. And it took me quite a while to figure out how it is done since this was my fist contact with the ESP8266. After I posted a video of the result on FB, I was getting many requests for a manual to this."</em> <a href="https://www.hackster.io/remnis/controlling-neopixels-with-a-webserver-on-an-esp8266-0381c7">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_IotBasedSurveillanceCameraRasp.jpg" alt="IOT Based Surveillance Camera || Raspberry Pi + Pan-Tilt Arrangement + Cayenne + Webcam Server" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/IOT-Based-Surveillance-Camera-Raspberry-Pi-Pan-Til/">IOT Based Surveillance Camera || Raspberry Pi + Pan-Tilt Arrangement + Cayenne + Webcam Server</a></h2>

<p><em>"Hey, guys. Due to our tight schedule, we weren't able to post any Raspberry Pi video in our channel. So, sorry for that. :(Finally, we are back with a project based on Raspberry Pi and IoT. We have done quite a few projects based on IoT. If you haven't seen any of then do watch those videos whose links are given below. Now, coming back to this tutorial. We will be making a kind of surveillance camera with some pretty useful features.The camera set up will be attached to a pan-tilt arrangement that will be controlled by two metal gear servos. Now those servos will be controlled wirelessly over the internet. So IoT or Internet Of Things concept will be playing a part here. Similar to our previous home security video, this project will be based on an IoT platform named Cayenne. The video feed will be transmitted over internet or Local network to your display, whether it is a laptop, desktop, or your smartphone. So now you can monitor the condition of your house from anywhere in the world using the internet."</em> <a href="http://www.instructables.com/id/IOT-Based-Surveillance-Camera-Raspberry-Pi-Pan-Til/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_NatoAdoptsNewProtocolStandardF.jpg" alt="NATO Adopts New Protocol Standard for Underwater Communications" class="lefter"></p>

<h2><a href="https://www.allaboutcircuits.com/news/janus-nato-new-protocol-standard-underwater-communications/">NATO Adopts New Protocol Standard for Underwater Communications</a></h2>

<p><em>"Underwater transmission protocols may finally be unified as NATO adopts a new standard, JANUS. NATO announced recently that it's adopting a standard protocol for underseas communication. What's JANUS and how does undersea communication differ from in-air data transmission? Thanks to standardized communication protocols, devices can communicate effectively. Wi-Fi, 4G, and Li-Fi are all examples of protocols that allow for reliable data transmission, enabling the growth of the mobile industry and the ubiquitous Internet of Things. The intersection of the electronics industry and maritime industry—an intersection that includes buoys, submarines, and other autonomous underwater devices—heavily relies on wireless communication. This is partly because of the vastness of our oceans and the untethered nature of most seacraft. For example, a submersible craft that needs to map the bottom of a trench in the ocean at a depth of 8km and then explore crevices and caves cannot reliably use a cable. In this scenario, wireless communication would be ideal as it would allow for complete freedom of movement and would not require the host (a ship for example) to carry 10km of cable. However, there is a serious problem with traditional wireless communication technologies: they rely on electromagnetic waves to transmit data. We tend to take for-granted that electromagnetic radiation does very well in the atmosphere (primarily due to the fact that air is mostly empty space) and, as a result, we can get radio signals to travel great distances with decent reliability. For a matter of perspective, the ESP8266 module can transmit a Wi-Fi signal up to 5km (with the aid of a telescopic antenna) while traditional radio stations can broadcast their signals up to 50 miles. The radio equipment current aboard the Voyager 1 and 2 probes are transmitting their data over a distance larger than the size of the solar system! So if EM waves can travel such distances, why can they not be used for underwater communication?"</em> <a href="https://www.allaboutcircuits.com/news/janus-nato-new-protocol-standard-underwater-communications/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_BinaryToDecimalLearnerKit.jpg" alt="Binary to Decimal Learner Kit" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Binary-to-Decimal-Learner-Kit/">Binary to Decimal Learner Kit</a></h2>

<p><em>"Are you a newbie to binary-decimal number systems?If yes then you must use the circuit to understand electronically the binary-decimal conversion.This project is intended for beginners who are new to binary number systems and to understand the conversion with more fun and deeper understanding.This will let them to learn circuit making on breadboard and using the 7-segment display.This is based on CD4511 ,BCD to 7 segment latch decoder driver IC. So let's get started."</em> <a href="http://www.instructables.com/id/Binary-to-Decimal-Learner-Kit/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_SensorPlatformRobotWithIrContr.jpg" alt="Sensor Platform Robot With IR Control" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Sensor-Platform-Robot-With-IR-Control/">Sensor Platform Robot With IR Control</a></h2>

<p><em>"Hi thereThis is my electronic robot project that I started because I wanted to learn more about interfacing sensor electronics with microcontrollers as well as build a platform that I could use to test out some of my programs, since it's always more satisfying to see a program make something move. For perhaps this reason or maybe more, some would like to build this or something similar. Hopefully this instructable will be able to help out with that.Most robots are designed with a purpose and some specifications. I however started with some sensors that I wanted to use and just ended up with this so it's a bit of a mess. Some parts of this project may get a bit heavy on the theory side but should still be easy enough to follow and you could always read up if you'd like to know more. I definitely recommend that you have some experience working with arduino, at least the basics. I also recommend that you be comfortable working with electronics and applying some basic electronics principles. These are not requirements for this project but it would make it easier. If you are doing some things for the first time you may need to do some extra research but that just means you'll benefit more from doing this project. I'll try to leave some further reading links where I can."</em> <a href="http://www.instructables.com/id/Sensor-Platform-Robot-With-IR-Control/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_TheArduinoRobotAWobblyPenguin.jpg" alt="The Arduino Robot: a Wobbly Penguin" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/The-Arduino-Robot-a-Wobbly-Penguin/">The Arduino Robot: a Wobbly Penguin</a></h2>

<p><em>"Summer comes with increasing heat, as a diligent DIY fan how could I do nothing but just eat ice creamI need to design a small present to you and myself, something cute and interesting, how about a small penguin? Guess that it stands in front of you and winks, sayin‘May I help you?’Besides its look, one of important features is the special penguin step, which makes the robot lovely. Therefore, I stress the wobbly step a lot. Fortunately, I found here comes with chirps when the robot shakes its head, the friction between gear and wooden structure during the working progress. The natural penguin-style sound helps me a lot.Come to check my work!I used to choose normal Arduino UNO as the main board in the beginning. However, Arduino UNO does not have in-built motor drive chip and it is too large, I have to buy an extra motor drive expansion board, which is expensive and hard to connect. Luckily, I found Romeo BLE mini board is so appropriate for my project. The mini board is fully compatible with Aruino UNO and with in-built motor drive chip, small and easy to install. In the result, I chose Romeo BLE mini board as the core board without any hesitation."</em> <a href="http://www.instructables.com/id/The-Arduino-Robot-a-Wobbly-Penguin/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_GrecoArduinoObjectAvoidingRobo.jpg" alt=""GRECO" - Arduino Object Avoiding Robotfor Beginners" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/GRECO-Arduino-Object-Avoiding-Robotfor-Beginners/">"GRECO" - Arduino Object Avoiding Robotfor Beginners</a></h2>

<p><em>"Well, if you are a beginner, here you will find the easiest way to build your own object avoiding robot!We will use a mini round robot chassis with two dc motors to build it easier. For one more time we choose to use the famous Arduino UNO board.Our tiny robot "GRECO" will scan for object in front of it by using a Ultrasonic sensor. If an object is detected, the robot will stop and "look" right and left for the best escape route!Official project page and future updates: http://www.ardumotive.com/greco-roboten.htmlAre you ready? Let's get started!"</em> <a href="http://www.instructables.com/id/GRECO-Arduino-Object-Avoiding-Robotfor-Beginners/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_DiyArduinoMoodLamp.jpg" alt="DIY Arduino Mood Lamp" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-Arduino-Mood-Lamp/">DIY Arduino Mood Lamp</a></h2>

<p><em>"This is project How-ToDo and today I'm going to show you how I build this arduino based mood lamp. I saw a couple similar projects made with wood and acrylic glass, and disided to make my own but a little bit smarter."</em> <a href="http://www.instructables.com/id/DIY-Arduino-Mood-Lamp/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_ControlAllYourIrAppliancesThro.jpg" alt="Control all your IR appliances through Bluetooth (or internet)" class="lefter"></p>

<h2><a href="https://www.open-electronics.org/control-all-your-ir-appliances-through-bluetooth-or-internet/">Control all your IR appliances through Bluetooth (or internet)</a></h2>

<p><em>"A Bluetooth enabled remote that will help you control one or more IR-controlled electric payloads. In this post, we are going to present a project for emulating an IR remote control composed of a RandA board (an Arduino that has connectors to interface with Raspberry Pi on one side and connectors for Arduino shield on the other) and a dedicated shield (ArdIR), that allows to control house appliances by reproducing the signals emitted by respective controllers. The peculiarity of this project is the possibility to control them remotely, via the internet, thanks to a dedicated web interface that can be accessed via the browser of devices connecting to it. Given that we had used an Arduino shield for that project, we thought it could be a good idea to use it again by reviewing the entire project from an Arduino perspective, that is by taking off Raspberry Pi and RandA and applying the shield directly to an Arduino Uno board. And…voilà! In these pages we will see how to control the ArdIR shield through a Bluetooth connection, therefore a close range one; this means that the “remote” controlling device will have to operate inside the same building of the system’s, at a distance not over a few meters, especially if there are big walls interposed between transmitter and receiver. This requirement may appear as a limitation and may lead to asking why did we choose this system. Well, if one needs to manage some devices inside one’ house although out of line of sight of classic IR remotes (e.g. if you want to listen to the music on your Hi-Fi which is in another room, and you want to be able to control volume, track, etc.), Bluetooth communication may be the most convenient because it doesn’t need an active LAN (with router and Wi-Fi to connect to mobile devices); connection between devices is direct (point-to-point), provided that each is equipped with Bluetooth interface. This is (almost) always true nowadays for tablets and smartphones, which in this project act as controlling devices; in the controlled device, that is the system composed of Arduino and the ArdIR shield, this is not the case because generally, Arduino doesn’t have this interface. We opted for a shield available as a kit (code FT1032M)."</em> <a href="https://www.open-electronics.org/control-all-your-ir-appliances-through-bluetooth-or-internet/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_GuardianRobotZeldaBotw.jpg" alt="Guardian Robot – Zelda BOTW" class="lefter"></p>

<h2><a href="https://learn.adafruit.com/guardian-robot-zelda-botw/">Guardian Robot – Zelda BOTW</a></h2>

<p><em>"Since the last Guardian Robot project, we've gotten a number of requests to add a servo and LED to the head – In this project, we'll show you how to do that! Mounted to the eye is a 10mm blue LED. The head itself is attached to a servo horn and mounted to a micro servo. The head can freely rotate while the eye blink randomly. Surrounding the body are 5mm blue LEDs that illuminate the various surface details. The random motion of the servo and eye blinks give the illusion of the robot "searching". It's appears quite organic and live like, adding much more dimension to this replica."</em> <a href="https://learn.adafruit.com/guardian-robot-zelda-botw/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_APsocBasedDigitalLoadBox.jpg" alt="A PSoC-Based Digital Load Box" class="lefter"></p>

<h2><a href="https://www.sparkfun.com/news/2434">A PSoC-Based Digital Load Box</a></h2>

<p><em>"If you’ve ever had to build a power supply, you may have needed to test it to a certain current limit. Too often, the way to do this is by stacking up large wattage resistors in series and parallel until you’ve got something that approximates the load you want. I got tired of doing this, and whipped up this little tool to help me test my power supplies with a little more aplomb. I’m a big fan of the Cypress PSoC line of processors, which is on our FreeSoC2 Development Board, so I decided I’d use a FreeSoC2 to implement my load. The PSoC has a huge advantage over other systems in that it has a lot of onboard analog circuitry (four op-amps), true 8-bit DAC outputs (instead of PWM), a high-accuracy 16-bit differential sigma-delta ADC and a couple of channels of SAR ADC. With all of this onboard power, I was able to reduce the external circuitry down to a few resistors and a FET as a load element."</em> <a href="https://www.sparkfun.com/news/2434">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM116_Esp8266BasementMonitor.jpg" alt="ESP8266 Basement Monitor" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/ESP8266-Basement-Monitor/">ESP8266 Basement Monitor</a></h2>

<p><em>"My basement gets wet when it rains a lot so I wanted a way to monitor it. I decided to try using an ESP8266 as it has built in WiFi. I paired that with a DHT22 Humidity &amp; Temperature Sensor and a float sensor to monitor my sump pump. Using the ESP8266 is easy enough as you can just use the Arduino IDE to program it. Besides the parts below you will need access to WiFi Dweet.io and Freeboard.io. These two web services make it easy to create a dashboard with your data."</em> <a href="http://www.instructables.com/id/ESP8266-Basement-Monitor/">[...]</a>
 </SPAN></DIV></p>

<hr />

<p>That's all Folks!</p>

<script data-cfasync="false" src="../../../../../../cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>SHB.build({elementID: 'shb', pref: { btnSizeClass: 'btn-md', btnClass: 'btn my-btn'}, buttons: { fbLike: true, fbShare:true, tweet: true, plusOne: true, plusShare: true,linkedInShare:true}});</script>

					</div>
				</section>
				</div> <!-- Container -->

				<footer id="footer" class="panel-footer">
					<div class="inner">
						<a href="https://github.com/PhileCMS/Phile">Phile</a> was made by <a href="https://github.com/PhileCMS">The PhileCMS Community</a>.
					</div>
				</footer>
			</div>
		</div>
</div>
		<script type="text/javascript">
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-20725619-1']);
            _gaq.push(['_trackPageview']);
            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
        </script>
		<!-- Matomo -->
<script type="text/javascript">
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//matomo.altlab.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '2']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
	</body>
</html>
