<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

		<!-- <base href="https://altlab.org/d/" />  -->
		<title>Newsletter altLab - 2017-08-10 - Nº 119 | altLab Documenta</title>
				<meta name="description" content="Newsletter altLab Nº119 de 10 de agosto de 2017">
				<meta property="og:type" content="article" />
		<meta property="og:title" content="Newsletter altLab - 2017-08-10 - Nº 119 | altLab Documenta" />
		<meta property="og:description" content="Newsletter altLab Nº119 de 10 de agosto de 2017" />
		<meta property="og:url" content="https://altlab.org/d/m/jpralves/newsletters/2017/119/" />
		<meta property="og:site_name" content="altLab Documenta" />

		<!-- Bootstrap -->
		<link href="../../../../../themes/altlab/css/bootstrap.min.css" rel="stylesheet">
		<link href="../../../../../themes/altlab/override-test.css" rel="stylesheet">
		<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
		<script src="../../../../../themes/altlab/js/jquery-1.12.4.min.js"></script>
		<!-- Include all compiled plugins (below), or include individual files as needed -->
		<script src="../../../../../themes/altlab/js/bootstrap.min.js"></script>

	</head>
	<body>
<div class="container">
<div class="container-fluid">
      <div class="page-header hidden-xs" id="brand-logo">
        <h1><a href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-gradoverwhite.png" width="180" height="120" alt="Home" style="vertical-align:text-bottom" /></a> Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></h1>

      </div>
			<nav class="navbar navbar-inverse">

				<div class="container-fluid">
					<div class="navbar-header">
						<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#myNavbar">
							<span class="sr-only">Toggle navigation</span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
<div class="visible-xs">
<a class="navbar-brand" href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-documenta.png" width="58" height="35" alt="Home" style="margin-top: -7px;"></a>
						<a class="navbar-brand" href="../../../../../index.html">Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></a></div>
					</div>
					<div class="collapse navbar-collapse" id="myNavbar">
						<ul class="nav navbar-nav">

           	<li id="dropdown.1" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Membros <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../index.html">Index</a>
</li>
   
           	<li id="dropdown.101" class="dropdown">
		<a href="../../../index.html">João Alves <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.102" class="dropdown">
		<a href="../../../../sislog/index.html">Fernando Carvalho <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.103" class="dropdown">
		<a href="../../../../pangelo/index.html">Pedro Ângelo <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.104" class="dropdown">
		<a href="../../../../dinix/index.html">Dinix <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../funke/funke.html">m/funke/funke</a>
  
   	</li>
            	<li id="dropdown.106" class="dropdown">
		<a href="../../../../afonsom/index.html">Afonso Muralha <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.107" class="dropdown">
		<a href="../../../../x3msnake/index.html">X3msnake <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../ampmendes/index.html">António Mendes</a>
  
   	</li>
            	<li>
		<a href="../../../../guardajoao/index.html">GuardaJoao</a>
  
   	</li>
            	<li>
		<a href="../../../../jac/index.html">JAC</a>
  
   	</li>
            	<li>
		<a href="../../../../nini/index.html">Nuno Nini</a>
  
   	</li>
 
</ul>
    	</li>
            	<li id="dropdown.2" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Documentação Partilhada <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../../s/index.html">Index</a>
</li>
   
                         	<li id="dropdown.203" class="dropdown">
		<a href="../../../../../s/workshops/index.html">Workshops <span class="caret"></span></a>
  
      	</li>
                   	<li>
		<a href="../../../../../s/documenta/index.html">Documenta DevMap</a>
  
   	</li>
                   	<li>
		<a href="../../../../../s/processos/index.html">Processos do Lab (draft)</a>
  
   	</li>
            	<li id="dropdown.208" class="dropdown">
		<a href="../../../../../s/recursos/index.html">Recursos <span class="caret"></span></a>
  
      	</li>
 
</ul>
    	</li>
 
						</ul>
					</div>
				</div>
			</nav>

			<div class="container">
				<div class="container">
				<section id="content">
					<div class="inner">
						<p><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
<link rel="stylesheet" href="../res/_shb.css"></p>

<script src="../res/_shb.min.js" type="text/javascript"></script>

<div style="text-align: center;">
<button class="btn my-btn btn-md disabled">Share:</button>
<div class="btn-group" id="shb"></div>
</div>

<p><br></p>

<h1 id="topo"><img src="../res/__Titulo.png" alt="Newsletter altLab" /></h1>

<p>2017-08-10 - Nº 119</p>

<div style="position: fixed; z-index: 65535; right: 10px; bottom: 10px;">
<a href='#topo' title='Go to Top'><img src="../res/_gotop.png" alt="go to top image" /></a>
</div>

<div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'pt', layout: google.translate.TranslateElement.FloatPosition.TOP_LEFT, multilanguagePage: true}, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<p><DIV class="articledetail"><SPAN class="articledetail"></p>

<p><img src="Newsletter119.jpg" alt="Newsletter119Cover" /></p>

<h2>Editorial</h2>

<p>Esta é a Newsletter Nº 119 que se apresenta com o mesmo formato que as anteriores. Se gostar da Newsletter partilhe-a!</p>

<p>Todas as Newsletters encontram-se indexadas no <a href="../../index.html">link</a>.</p>

<p>Esta Newsletter tem os seguintes tópicos:</p>

<ul>
<li><a href="#Novidades-da-Semana">Novidades da Semana</a></li>
<li><a href="#Ciencia-e-Tecnologia">Ciência e Tecnologia</a></li>
<li><a href="#Documentacao">Documentação</a></li>
<li><a href="#Projetos-Maker">Projetos Maker</a></li>
</ul>

<p>Faz hoje anos que nascia, em 1856, <a href="https://en.wikipedia.org/wiki/William_Willett">William Willett</a>. Este construtor inglês inventou o horário de verão. Ele afirmou ter tido a ideia enquanto fazia uma viagem de manhã no início do verão em Petts Wood perto de sua casa em Chislehurst, em Londres. Ele observou que muitas das persianas ainda estavam baixas, embora já existisse boa luz do dia. Ele usou sua riqueza como um proeminente construtor de casas para fazer campanha para um esquema de ajuste de relógios com a temporada e publicou um panfleto em 1907. A sua ideia original era fazer quatro mudanças semanais de 20 minutos cada, para um total de 80 minutos.
Faz também anos hoje que nascia, em 1902, <a href="https://en.wikipedia.org/wiki/Arne_Tiselius">Arne Tiselius</a>. Foi um bioquímico sueco que ganhou o Prémio Nobel de Química em 1948 "pela sua pesquisa sobre eletroforese e análise de adsorção, especialmente pelas suas descobertas sobre a natureza complexa das proteínas séricas."
Faz igualmente anos hoje que nascia, em 1909, <a href="https://en.wikipedia.org/wiki/Leo_Fender">Leo Fender</a>. Este inventor norte-americano fundador da Fender Electric Instrument Manufacturing Company, ou "Fender" como ficou conhecida, desenhou e construiu diversos equipamento musical, nomeadamente guitarras e baixos assim como amplificadores.
Por fim, faz anos hoje que nascia, em 1913, <a href="https://en.wikipedia.org/wiki/Wolfgang_Paul">Wolfgang Paul</a>. Este físico alemão co-desenvolveu com Hans Georg Dehmelt o filtro de massa quadripolar não-magnético que estabeleceu as bases para o que agora é chamado de armadilha de iões ou de "Paul trap". O dispositivo consiste em três eléctrodos - duas extremidades e um anel circundante. O anel está conectado a um potencial oscilante. A direcção do campo eléctrico alterna; Durante metade do tempo, o eléctron é empurrado das pontas para o anel e para a outra metade é puxado do anel e empurrado para as pontas.</p>

<p>Esta semana a Intel apresentou a família de processadores de 14 a 18 Cores, designada por X-series e que estará disponível em Setembro.
A AMD lançou hoje o seu processador de Desktop de topo o Ryzen™ Threadripper™. Pelos vistos a concorrência até faz bem e observamos a Intel e a AMD a mostrarem o que valem.
A Sonda Cassini vai iniciar as ultimas cinco orbitas a Saturno. O ponto da aproximação mais próximo da Saturno durante as aproximações será entre 1.630 e 1.710 quilómetros acima das nuvens de Saturno.</p>

<p>Na Newsletter desta semana apresentamos diversos projetos de maker. É apresentada a revista newelectronics de 8 de Agosto e um livro sobre Transformadas de Fourier.</p>

<p><img src="../res/_jpralves.jpg" alt="jpralves" /> João Alves (<a href="https://altlab.org/d/m/jpralves/newsletters/2017/119/&#x6d;&#97;&#105;&#x6c;&#116;&#111;&#x3a;&#x6a;&#112;&#114;&#x61;&#108;&#118;&#x65;&#x73;&#64;g&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;o&#x6d;#x6d;&a&i&l&t&o&:&j&p&r&a&l&v&e&s&@g&m&a&i&l&.&co&m"><span class="__cf_email__" data-cfemail="fc968c8e9d908a998fbc9b919d9590d29f9391">[email&#160;protected]</span></a>)</p>

<p>O conteúdo da Newsletter encontra-se sob a licença <img src="../res/_by-nc-sa4.0.png" alt="by-nc-sa4.0" /> <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>

<p></SPAN></DIV></p>

<hr />

<h1 id="Novidades-da-Semana">Novidades da Semana</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS119_IntelUnveilsFullIntelCoreXSeri.jpg" alt="Intel Unveils Full Intel Core X-series Processor Family Specs; 14- to 18-Core Processors Available Starting in September" class="lefter"></p>

<h2><a href="https://newsroom.intel.com/news/intel-unveils-full-intel-core-x-series-processor-family-specs-14-18-core-processors-available-starting-september/">Intel Unveils Full Intel Core X-series Processor Family Specs; 14- to 18-Core Processors Available Starting in September</a></h2>

<p><em>"Today, Intel is releasing the specifications for the 12- to 18-core processors: Intel® Core™ i9-7920X, Intel Core i9-7940X, Intel Core i9-7960X and the Extreme Edition Intel Core i9-7980XE processors. Announced at Computex 2017, the Intel Core X-series processor family is the most powerful, scalable and accessible high-end desktop platform1 offered by Intel, designed to deliver the performance needed to meet extreme computing demands for virtual reality (VR), content creation, gaming and overclocking. The new X-series processor family is the ultimate platform for content creators and gamers. Multitasking becomes extreme mega-tasking with simultaneous, compute-intensive, multithreaded workloads aligned in purpose, powered by up to 18 cores and 36 threads. And, with up to 68 PCIe 3.0 lanes on the platform, people have the ability to expand their systems with fast SSDs, up to four discrete GFX cards and ultrafast Thunderbolt™ 3 solutions. Content creators can expect up to 20 percent better performance for VR content creation2 and up to 30 percent faster 4K video editing3 over the previous generation. This means less time waiting and more time designing new worlds and experiences. Gamers and enthusiasts will experience up to 30 percent faster extreme mega-tasking for gaming4 over the previous generation."</em> <a href="https://newsroom.intel.com/news/intel-unveils-full-intel-core-x-series-processor-family-specs-14-18-core-processors-available-starting-september/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS119_CassiniToBeginFinalFiveOrbitsA.jpg" alt="Cassini to Begin Final Five Orbits Around Saturn" class="lefter"></p>

<h2><a href="https://www.jpl.nasa.gov/news/news.php?feature=6916">Cassini to Begin Final Five Orbits Around Saturn</a></h2>

<p><em>"NASA's Cassini spacecraft will enter new territory in its final mission phase, the Grand Finale, as it prepares to embark on a set of ultra-close passes through Saturn's upper atmosphere with its final five orbits around the planet. Cassini will make the first of these five passes over Saturn at 9:22 p.m. PDT Sunday, Aug. 13 (12:22 a.m. EDT Monday, Aug. 14). The spacecraft's point of closest approach to Saturn during these passes will be between about 1,010 and 1,060 miles (1,630 and 1,710 kilometers) above Saturn's cloud tops. The spacecraft is expected to encounter atmosphere dense enough to require the use of its small rocket thrusters to maintain stability -- conditions similar to those encountered during many of Cassini's close flybys of Saturn's moon Titan, which has its own dense atmosphere."</em> <a href="https://www.jpl.nasa.gov/news/news.php?feature=6916">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS119_AmdLaunchesTheHighestPerforman.jpg" alt="AMD Launches the Highest-Performance Desktop Processor, Ever, with Ryzen™ Threadripper™ High End Desktop Processors" class="lefter"></p>

<h2><a href="http://www.amd.com/en-us/press-releases/Pages/amd-launches-the-2017aug10.aspx">AMD Launches the Highest-Performance Desktop Processor, Ever, with Ryzen™ Threadripper™ High End Desktop Processors</a></h2>

<p><em>"Today, AMD (NASDAQ: AMD) released two models of its highly anticipated, Ryzen™ Threadripper™ high-end desktop processors, AMD Ryzen™ Threadripper ™1950X and AMD Ryzen™ Threadripper™ 1920X. During an already record-setting year for the company through the successful launch of several award-winning Ryzen™ desktop processors for the AM4 platform, today's release of Ryzen Threadripper marks a major step forward in performance and features for the high-end desktop market, with the new processor exceeding the expectations of even the most demanding developers, researchers, prosumers, creators, and multi-tasking gamers. Built around the new AMD x86 "Zen" core architecture, Ryzen Threadripper delivers overwhelming power, unrestrained potential, and indisputable supremacy over comparable products in the market. "The level of global support and excitement built-up around AMD Ryzen processors has been incredible to watch these last few months, and with today's Ryzen Threadripper launch, we deliver a new level of computing power to the world's fastest ultra-premium desktop systems via an entirely new platform and set of multi-core processors," said Jim Anderson, senior vice president and general manager, Computing and Graphics Group, AMD. "Ryzen Threadripper is the jolt of innovation that the high-end desktop customer was waiting for, providing the long-awaited ability to choose a processor that best fulfills their computing needs at a competitive price.""</em> <a href="http://www.amd.com/en-us/press-releases/Pages/amd-launches-the-2017aug10.aspx">[...]</a>
 </SPAN></DIV></p>

<h2>Outras Notícias</h2>

<ul>
<li><a href="http://news.mit.edu/2017/tess-mission-discover-new-planets-moves-toward-launch-0804">TESS mission to discover new planets moves toward launch</a></li>
<li><a href="https://3dr.com/blog/announcing-opensolo/">Announcing OpenSolo</a></li>
<li><a href="http://media.daimler.com/marsMediaSite/en/instance/ko/Premiere-at-Mercedes-Benz-Trucks-New-from-the-3D-printer-the-first-spare-part-for-trucks-made-of-metal.xhtml?oid=23666435">Premiere at Mercedes-Benz Trucks: New from the 3D printer: the first spare part for trucks made of metal</a></li>
<li><a href="http://research.nvidia.com/publication/facial-performance-capture-deep-neural-networks">Production-Level Facial Performance Capture Using Deep Convolutional Neural Networks</a></li>
<li><a href="http://anuc.edu.gh/home/latestnewsmore.html?newsId=58">GhanaSat-1 Releases into Orbit</a></li>
<li><a href="https://code.facebook.com/posts/289921871474277/transitioning-entirely-to-neural-machine-translation/">Transitioning entirely to neural machine translation</a></li>
<li><a href="https://news.samsung.com/global/samsung-introduces-far-reaching-v-nand-memory-solutions-to-tackle-data-processing-and-storage-challenges">Samsung Introduces Far-reaching V-NAND Memory Solutions to Tackle Data Processing and Storage Challenges</a></li>
<li><a href="http://www.nanoscribe.de/en/media-press/press-releases/additive-manufacturing-micro-optics/">Additive Manufacturing of Micro-Optics</a></li>
<li><a href="https://www.imec-int.com/en/articles/imec-reports-record-conversion-efficiency-of-23-9-percent-on-a-4cm2-perovskite-silicon-solar-module">Imec Reports Record Conversion Efficiency of 23.9 Percent on a 4cm2 Perovskite/Silicon Solar Module</a></li>
<li><a href="http://www.renishaw.com/en/renishaw-and-aeromet-work-to-optimise-high-performance-alloy--42645">Renishaw and Aeromet work to optimise high-performance alloy</a></li>
<li><a href="https://www.microchip.com/pressreleasepage/microchip-launches-sam-d5x-e5x-microcontroller-families">Microchip Launches Two New SAM Microcontroller Families with Extensive Connectivity Interface Options</a></li>
<li><a href="https://newsroom.intel.com/news/intel-mobileye-integration-plans-build-fleet-autonomous-test-cars/">Intel Kick-Starts Mobileye Integration with Plans to Build Fleet of 100 L4 Autonomous Test Cars</a></li>
<li><a href="https://blogs.nvidia.com/blog/2017/08/10/gastrointestinal-examination/">20,000 Leagues Into Your Bowels: How GPUs Are Helping to Diagnose Gastrointestinal Anomalies</a></li>
</ul>

<h1 id="Ciencia-e-Tecnologia">Ciência e Tecnologia</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_HeatConductingPlasticCouldLead.jpg" alt="Heat-conducting plastic could lead to lighter electronics, cars" class="lefter"></p>

<h2><a href="http://ns.umich.edu/new/releases/24994-heat-conducting-plastic-could-lead-to-lighter-electronics-cars">Heat-conducting plastic could lead to lighter electronics, cars</a></h2>

<p><em>"Advanced plastics could usher in lighter, cheaper, more energy-efficient product components, including those used in vehicles, LEDs and computers—if only they were better at dissipating heat. A new technique that can change plastic's molecular structure to help it cast off heat is a promising step in that direction. Developed by a team of University of Michigan researchers in materials science and mechanical engineering and detailed in a new study published in Science Advances, the process is inexpensive and scalable. The concept can likely be adapted to a variety of other plastics. In preliminary tests, it made a polymer about as thermally conductive as glass—still far less so than metals or ceramics, but six times better at dissipating heat than the same polymer without the treatment. "Plastics are replacing metals and ceramics in many places, but they're such poor heat conductors that nobody even considers them for applications that require heat to be dissipated efficiently," said Jinsang Kim, U-M materials science and engineering professor. "We're working to change that by applying thermal engineering to plastics in a way that hasn't been done before." The process is a major departure from previous approaches, which have focused on adding metallic or ceramic fillers to plastics. This has met with limited success; a large amount of fillers must be added, which is expensive and can change the properties of the plastic in undesirable ways. Instead, the new technique uses a process that engineers the structure of the material itself. Plastics are made of long chains of molecules that are tightly coiled and tangled like a bowl of spaghetti. As heat travels through the material, it must travel along and between these chains—an arduous, roundabout journey that impedes its progress. The team—which also includes U-M associate professor of mechanical engineering Kevin Pipe, mechanical engineering graduate researcher Chen Li and materials science and engineering graduate student Apoorv Shanker—used a chemical process to expand and straighten the molecule chains. This gave heat energy a more direct route through the material. To accomplish this, they started with a typical polymer, or plastic. They first dissolved the polymer in water, then added electrolytes to the solution to raise its pH, making it alkaline."</em> <a href="http://ns.umich.edu/new/releases/24994-heat-conducting-plastic-could-lead-to-lighter-electronics-cars">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_DesigningTheMicrostructureOfPr.jpg" alt="Designing the microstructure of printed objects" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/designing-microstructure-3-d-printed-objects-0804">Designing the microstructure of printed objects</a></h2>

<p><em>"Today’s 3-D printers have a resolution of 600 dots per inch, which means that they could pack a billion tiny cubes of different materials into a volume that measures just 1.67 cubic inches. Such precise control of printed objects’ microstructure gives designers commensurate control of the objects’ physical properties — such as their density or strength, or the way they deform when subjected to stresses. But evaluating the physical effects of every possible combination of even just two materials, for an object consisting of tens of billions of cubes, would be prohibitively time consuming. So researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new design system that catalogues the physical properties of a huge number of tiny cube clusters. These clusters can then serve as building blocks for larger printable objects. The system thus takes advantage of physical measurements at the microscopic scale, while enabling computationally efficient evaluation of macroscopic designs. “Conventionally, people design 3-D prints manually,” says Bo Zhu, a postdoc at CSAIL and first author on the paper. “But when you want to have some higher-level goal — for example, you want to design a chair with maximum stiffness or design some functional soft [robotic] gripper — then intuition or experience is maybe not enough. Topology optimization, which is the focus of our paper, incorporates the physics and simulation in the design loop. The problem for current topology optimization is that there is a gap between the hardware capabilities and the software. Our algorithm fills that gap.”"</em> <a href="http://news.mit.edu/2017/designing-microstructure-3-d-printed-objects-0804">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_BreakthroughSoftwareTeachesCom.jpg" alt="Breakthrough software teaches computer characters to walk, run, even play soccer" class="lefter"></p>

<h2><a href="https://news.ubc.ca/2017/07/31/breakthrough-software-teaches-computer-characters-to-walk-run-even-play-soccer/">Breakthrough software teaches computer characters to walk, run, even play soccer</a></h2>

<p><em>"Computer characters and eventually robots could learn complex motor skills like walking and running through trial and error, thanks to a milestone algorithm developed by a University of British Columbia researcher. “We’re creating physically-simulated humans that learn to move with skill and agility through their surroundings,” said Michiel van de Panne, a UBC computer science professor who is presenting this research today at SIGGRAPH 2017, the world’s largest computer graphics and interactive techniques conference. “We’re teaching computer characters to learn to respond to their environment without having to hand-code the required strategies, such as how to maintain balance or plan a path through moving obstacles. Instead, these behaviors can be learned.” The work, called DeepLoco, offers an alternative way to animate human movement in games and film instead of the current method which makes use of actors and motion capture cameras or animators. DeepLoco allows characters to automatically move in ways that are both realistic and attentive to their surroundings and goals. In the future, two or four-legged robots could learn to navigate through their environment without needing to hand-code the appropriate rules. Using his algorithm, simulated characters have learned to walk along a narrow path without falling off, to avoid running into people or other moving obstacles, and even to dribble a soccer ball towards a goal. The method makes advanced use of deep reinforcement learning, a type of machine learning algorithm in which experience is gained through trial and error and is informed by rewards. Over time, the system progressively identifies better actions to take in given situations. “It’s like learning a new sport,” said van de Panne. “Until you try it, you don’t know what you need to pay attention to. If you’re learning to snowboard, you may not know that you need to distribute your weight in a particular way between your toes and heels. These are strategies that are best learned, as they are very difficult to code or design in any other way.” The motion of humans and animals is governed not just by physics but also control. While humans learn motor control through trial and error, van de Panne says it’s hard to tell how much the algorithm mimics the human learning process. After all, the computer program still learns much more slowly than a human. He began working on this type of motor learning problem when he had children; they are now 17 and 20. “I distinctly remember wondering who will learn agile walking and running skills first: my son, daughter or the algorithm?” he said. “My son and daughter beat me by a long shot.”"</em> <a href="https://news.ubc.ca/2017/07/31/breakthrough-software-teaches-computer-characters-to-walk-run-even-play-soccer/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_ThePowerOfPerovskite.jpg" alt="The Power of Perovskite" class="lefter"></p>

<h2><a href="https://www.oist.jp/news-center/news/2017/8/4/power-perovskite">The Power of Perovskite</a></h2>

<p><em>"Originally a mineral, the perovskite used in today’s technology is quite different from the rock found in the Earth mantle. A “perovskite structure” uses a different combination of atoms but keep the general 3-dimensional structure originally observed in the mineral, which possesses superb optoelectronic properties such as strong light absorption and facilitated charge transport. These advantages qualify the perovskite structure as particularly suited for the design of electronic devices, from solar cells to lights. The accelerating progress in perovskite technology over the past few years suggest new perovskite-based devices will soon outperform current technology in the energy sector. The Energy Materials and Surface Sciences Unit at OIST led by Prof. Yabing Qi is at the forefront of this development, with now two new scientific publications focusing on the improvement of perovskite solar cells and a cheaper and smarter way to produce emerging perovskite-based LED lights."</em> <a href="https://www.oist.jp/news-center/news/2017/8/4/power-perovskite">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_ClarifiyingComplexChemicalProc.jpg" alt="Clarifiying complex chemical processes with quantum computers" class="lefter"></p>

<h2><a href="https://www.ethz.ch/en/news-and-events/eth-news/news/2017/07/clarifiying-complex-chemical-processes-with-quantum-computers.html">Clarifiying complex chemical processes with quantum computers</a></h2>

<p><em>"Specialists expect nothing less than a technological revolution from quantum computers, which they hope will soon allow them to solve problems that are currently too complex for classical supercomputers. Commonly discussed areas of application include data encryption and decryption, as well as special problems in the fields of physics, quantum chemistry and materials research. But when it comes to concrete questions that only quantum computers can answer, experts have remained relatively vague. Researchers from ETH Zurich and Microsoft Research are now presenting a specific application for the first time in the scientific journal PNAS: evaluating a complex chemical reaction. Based on this example, the scientists show that quantum computers can indeed deliver scientifically relevant results. A team of researchers led by ETH professors Markus Reiher and Matthias Troyer used simulations to demonstrate how a complex chemical reaction could be calculated with the help of a quantum computer. To accomplish this, the quantum computer must be of a “moderate size”, says Matthias Troyer, who is Professor for Computational Physics at ETH Zurich and currently works for Microsoft. The mechanism of this reaction would be nearly impossible to assess with a classical supercomputer alone – especially if the results are to be sufficiently precise."</em> <a href="https://www.ethz.ch/en/news-and-events/eth-news/news/2017/07/clarifiying-complex-chemical-processes-with-quantum-computers.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_BuildingAGrapheneBasedNanotube.jpg" alt="Building a graphene-based nanotube biosensor" class="lefter"></p>

<h2><a href="https://actu.epfl.ch/news/building-a-graphene-based-nanotube-biosensor/">Building a graphene-based nanotube biosensor</a></h2>

<p><em>"Biosensors are devices that can detect biological molecules (“analytes”) in air, water, or blood. They are used widely in drug development, medical diagnostics, biological research, and even security. Despite ongoing advancments, there remains a need for improved portable biosensing devices that are easy to use for both doctors and patients. The development of such devices would offer methods for continuous, real-time monitoring of biomarker levels, which is important for a number of diseases such as diabetes. This is where Edward Honein’s summer project comes in: he is developing an optical, microfluidic biosensor that can detect single biomolecules in a scalable, high-throughput manner. The biosensor itself is made up of carbon nanotubes, which are rolled-up sheets of graphene. Nanotubes have diameters as small as 1 nanometer and lengths up to several centimeters, and their unique physical properties have opened up a whole new world of technologies. One of these properties is emitting light in the near-infrared spectrum (700 – 2500 nm wavelength) when excited with a laser. Honein’s project draws from the research of Professor Ardemis Boghossian, who heads the lab and combines nanotube optics and biological molecules to explore a range of emerging capabilities, including near-infrared biosensing. In her research, Boghossian has developed nanotubes wrapped with single-stranded DNA, which acts as the actual sensing molecule for the target analyte. “In our applications we use semiconducting nanotubes that have a specifc energy barrier, called the ‘band gap’,” says Honein. “When we excite the nanotubes with a laser, an electron is excited across this barrier into the conductance band. Eventually this electron relaxes, and in doing so releases a photon – which is what we see as emitted light.” When the DNA - or a protein - detects the presence of a target molecule in the vicinity of a carbon nanotube, the resulting interaction changes the 3D conformation of the DNA or protein, which subsequently affects the surface properties of the nanotube. These modifications impact the near-infrared light emitted by the nanotube and changes its signal. Honein is now trying to streamline the biosensor to make it scalable for commercial use. This entails a lot of work: first to construct the biosensor, then to characterize the sensor’s sensitivity and selectivity, and finally to integrate the sensor into a working device. One possibility he is exploring is using DNA-wrapped nanotubes that have beem immobilized into a gel, and then incorporating this gel into a microfluidic device."</em> <a href="https://actu.epfl.ch/news/building-a-graphene-based-nanotube-biosensor/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_ResearchToAccelerateDevelopmen.jpg" alt="Research To Accelerate Development Of High-Efficiency Graphene-Based Membranes" class="lefter"></p>

<h2><a href="https://news.masdar.ac.ae/explore-news/stories-by-type/transformation/item/9953-research-to-accelerate-development-of-high-efficiency-graphene-based-membranes.html">Research To Accelerate Development Of High-Efficiency Graphene-Based Membranes</a></h2>

<p><em>"Masdar Institute today announced a research breakthrough that provides valuable insights on the development of optimized graphene-based membranes, which aim to make water filtration and desalination more efficient and sustainable. The Masdar Institute is a part of the Khalifa University of Science and Technology. The breakthrough was made by a team of researchers led by Dr. Linda Zou, Professor of Civil Infrastructure and Environmental Engineering, as they worked to develop membranes made of layered reduced graphene-oxide sheets that are able to block the passage of salt ions in a membrane-based seawater desalination process. Seawater desalination is a costly and energy-intensive undertaking that produces over 80% of the UAE’s freshwater. With such a heavy reliance on desalination, there is a critical need for efficient and sustainable technologies that will reduce its environmental and economic costs. One type of technology that may be able to provide those valuable savings is graphene-based membranes. The tiny weight and size of graphene, which is a nanomaterial about 100,000 times thinner than the diameter of a human hair, coupled with its mechanical strength and durability, make it well-suited for an energy-efficient and environmentally-friendly generation of water membranes. In fact, graphene for water purification is increasingly being seen as a significant commercial market for graphene, which is a material that Lux Research believes may have a US$300 million annual market value by 2025. The graphene-based membranes developed in this work are made of multiple of layers of thin reduced graphene oxide sheets. The spacing between the sheets is what ultimately affects the membrane’s efficacy, or its ability to filter impurities like salt ions while still permitting water molecules to pass through. The spaces between sheets must be just right – if they are too large and salt ions are not filtered out, and if they too small and even water molecules are unable to penetrate the membrane. Being able to fine-tune the spacing size between layers is one of the most difficult challenges to developing efficient layered graphene membranes. Previous studies revealed that the optimal space between graphene sheets could be between 0.6nm and 0.7nm. Given this very narrow size range, a slight variation significantly affects the functionality of the membrane. Dr. Zou believes that her research provides a needed tool which will help scientists better fine-tune the size of inter-layer spacing. Dr. Zou’s team used atomic force microscopy (AFM) to probe the edges of each graphene sheet to obtain measurements of the exact height of the spaces between each sheet. They then combined these AFM measurements with statistical analysis to reveal the relationship between the amount of the chemical used to make layered reduced graphene oxide membranes, known as a reducing agent, and the resulting size of the spacing between each graphene layer. They described their research in a paper that was published in the 12 July 2017 print edition of the peer-reviewed journal ACS Applied Materials and Interfaces. Dr. Steve Griffiths, Interim Executive Vice President for Research, Khalifa University of Science and Technology, said: “The research and development of technologies aimed at achieving energy-efficient desalination through the use of advanced materials like graphene is at the core of Masdar Institute’s research agenda. The work conducted by Dr. Zou and her team is an important contribution to the development of cost-effective and environmentally-sustainable technologies for growing clean water demand in the UAE and globally.” Dr. Zou is also leading a collaborative research project with The University of Manchester – credited as the ‘birthplace’ of graphene – that aims to incorporate graphene into membranes for electrically-driven membrane desalination strategies, such as electrodialysis and capacitive deionization. Developing efficient and sustainable technologies for the production of freshwater is one of the most pressing and crucial challenges currently facing the world. That is why Masdar Institute has several research teams pursuing a range of research projects dedicated to the development of next-generation water filtration and desalination technologies needed to make freshwater production affordable and environmentally friendly."</em> <a href="https://news.masdar.ac.ae/explore-news/stories-by-type/transformation/item/9953-research-to-accelerate-development-of-high-efficiency-graphene-based-membranes.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_PicturePerfect.jpg" alt="Picture Perfect" class="lefter"></p>

<h2><a href="http://www.news.ucsb.edu/2017/018169/picture-perfect">Picture Perfect</a></h2>

<p><em>"UCSB and NVIDIA researchers develop a new technique that enables photographers to adjust image compositions after capture. When taking a picture, a photographer must typically commit to a composition that cannot be changed after the shutter is released. For example, when using a wide-angle lens to capture a subject in front of an appealing background, it is difficult to include the entire background and still have the subject be large enough in the frame. Positioning the subject closer to the camera will make it larger, but unwanted distortion can occur. This distortion is reduced when shooting with a telephoto lens, since the photographer can move back while maintaining the foreground subject at a reasonable size. But this causes most of the background to be excluded. In each case, the photographer has to settle for a suboptimal composition that cannot be modified later. As described in a technical paper to be presented July 31 at the ACM SIGGRAPH 2017 conference, UC Santa Barbara Ph.D. student Abhishek Badki and his advisor Pradeep Sen, a professor in the Department of Electrical and Computer Engineering, along with NVIDIA researchers Orazio Gallo and Jan Kautz, have developed a new system that addresses this problem. Specifically, it allows photographers to compose an image post-capture by controlling the relative positions and sizes of objects in the image. Computational Zoom, as the system is called, allows photographers the flexibility to generate novel image compositions — even some that cannot be captured by a physical camera — by controlling the sense of depth in the scene, the relative sizes of objects at different depths and the perspectives from which the objects are viewed."</em> <a href="http://www.news.ucsb.edu/2017/018169/picture-perfect">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_200TerabyteProofDemonstratesTh.jpg" alt="200 Terabyte Proof Demonstrates the Potential of Brute-Force Math" class="lefter"></p>

<h2><a href="https://motherboard.vice.com/en_us/article/padnvm/200-terabyte-proof-demonstrates-the-potential-of-brute-force-math">200 Terabyte Proof Demonstrates the Potential of Brute-Force Math</a></h2>

<p><em>"In computer science, the "brute force" solution is usually the suboptimal solution. It gets there eventually, but also inefficiently and without cleverness. The existence of a brute force solution to a problem usually implies the existence of a more elegant but perhaps less obvious solution. You could take a basic algebra problem as an example: 2x + 100 = 500. To solve this with brute force, we simply check every possible value of x until one works. We know, however, that it is far more efficient to rearrange the given equation using algebraic rules and in just two computations we get an answer. Computer scientists are giving brute force another look, however. In a paper published in the current Communications of the ACM, Marijn Heule and Oliver Kullmann argue that we're entering a new era where brute force may have a key role to play after all, particularly when it comes to security- and safety-critical systems. This is thanks to a newish technology called Satisfiability (SAT) solving, which is a method of generating proofs in propositional logic. Basically, we can put together optimized brute-force problem solving and accessible modern supercomputers and get a reasonable way of solving super-complex problems. Technology is making it so that we don't necessarily need cleverness in problem solving if we have access to a whole bunch of processor cores. "Today, SAT solving on high-performance computing systems enables us to conquer problems of high complexity, driven by practice," Heule and Kullmann write. "This combination of enormous computational power with 'magical brute force' can now solve very hard combinatorial problems, as well as proving safety of systems such as railways." To see this potential, we need to understand a bit about formal logic. In propositional logic, a proposition is just a statement that can be true or false. Crucially, such a statement has the property of being able to be negated. The statement "I am going to get a burrito," for example, in negated form is just "I am not going to get a burrito." So, the statement is a proposition. Propositional logic involves a whole lot proving that statements are true using logical operators such as AND and OR and NOT. As in my algebra example above, really complicated-seeming statements can often be rearranged into statements whose truth value is obvious. Computer science involves a lot of propositions, or true/false statements. That's the essence of the whole thing, really. In formal propositional logic, we can imagine a bunch of individual atomic units of truth (that are either true or false combined using the above logical operators. For example, we might have the statement ((true AND false) OR true) AND NOT (true OR false) and be asked if that's ultimately true or not. It's not, but that's probably not obvious. These things get really hard to evaluate and if you've ever had to wrestle with formal logic you know that reaching a solution sometimes just involves guessing and checking, which is a brute-force method."</em> <a href="https://motherboard.vice.com/en_us/article/padnvm/200-terabyte-proof-demonstrates-the-potential-of-brute-force-math">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_EngineersHarnessThePowerOf3DPr.jpg" alt="Engineers harness the power of 3D printing to help train surgeons, shorten surgery times" class="lefter"></p>

<h2><a href="http://jacobsschool.ucsd.edu/news/news_releases/release.sfe?id=2273">Engineers harness the power of 3D printing to help train surgeons, shorten surgery times</a></h2>

<p><em>"A team of engineers and pediatric orthopedic surgeons are using 3D printing to help train surgeons and shorten surgeries for the most common hip disorder found in children ages 9 to 16. In a recent study, researchers showed that allowing surgeons to prep on a 3D-printed model of the patient’s hip joint cut by about  25 percent the amount of time needed for surgery when compared to a control group. The team, which includes bioengineers from the University of California San Diego and physicians from Rady Children’s Hospital, detailed their findings in a recent issue of the Journal of Children’s Orthopaedics. “Being able to practice on these 3D-models is crucial,” said Dr. Vidyadhar Upasani, pediatric orthopedic surgeon at Rady Children’s and UC San Diego and the paper’s senior author. In this study, Upasani operated on a total of 10 patients. For five of the patients, he planned the surgeries using 3D-printed models. He didn’t use models to plan the other five. In addition, two other surgeons operated on a different group of five patients without using models. In the group where Upasani used 3D-printed models, surgeries were 38-45 minutes shorter compared with the two control groups. These time savings would translate into at least $2700 in savings per surgery, researchers said. By contrast, after the one-time cost of buying a 3D printer for about $2200, physicians can make a model for each surgery for about $10. The results of the study were so positive that Rady Children’s orthopedics department has acquired its own 3D printer, Upasani said. “I’ve seen how beneficial 3D models are,” he said. “It’s now hard to plan surgeries without them.” Slipped capital femoral epiphysis is a condition that affects about 11 in 100,000 children in the United States every year. In this condition, the head of the patient’s femur slips along the bone’s growth plate, deforming it. The main goal of the surgery is to sculpt the femur back into its normal shape and restore hip function. This is difficult because during the surgery, the bone and its growth plate are not directly visible. So the surgeons can’t visualize in 3D how the growth plate is deformed. The condition is associated with obesity and hormonal dysfunction and has become more common as obesity increases among young people. Traditionally, before the surgery, physicians study X-rays of the surgery site taken from different angles, which they use to plan the bone cuts. During surgery, an X-ray fluoroscopy beam also shines periodically on the surgery site to help guide the physician. These methods are time consuming and expose the child to radiation. In addition, physicians don’t have a physical model to educate patients or practice the surgery beforehand."</em>  <a href="http://jacobsschool.ucsd.edu/news/news_releases/release.sfe?id=2273">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_NeedGrapheneGrabASaw.jpg" alt="Need graphene? Grab a saw" class="lefter"></p>

<h2><a href="http://news.rice.edu/2017/07/31/need-graphene-grab-a-saw-2/">Need graphene? Grab a saw</a></h2>

<p><em>"Rice University scientists have made wood into an electrical conductor by turning its surface into graphene. Rice chemist James Tour and his colleagues used a laser to blacken a thin film pattern onto a block of pine. The pattern is laser-induced graphene (LIG), a form of the atom-thin carbon material discovered at Rice in 2014. “It’s a union of the archaic with the newest nanomaterial into a single composite structure,” Tour said. The discovery is detailed this month in Advanced Materials. Previous iterations of LIG were made by heating the surface of a sheet of polyimide, an inexpensive plastic, with a laser. Rather than a flat sheet of hexagonal carbon atoms, LIG is a foam of graphene sheets with one edge attached to the underlying surface and chemically active edges exposed to the air. Not just any polyimide would produce LIG, and some woods are preferred over others, Tour said. The research team led by Rice graduate students Ruquan Ye and Yieu Chyan tried birch and oak, but found that pine’s cross-linked lignocellulose structure made it better for the production of high-quality graphene than woods with a lower lignin content. Lignin is the complex organic polymer that forms rigid cell walls in wood. Ye said turning wood into graphene opens new avenues for the synthesis of LIG from nonpolyimide materials. “For some applications, such as three-dimensional graphene printing, polyimide may not be an ideal substrate,” he said. “In addition, wood is abundant and renewable.”"</em> <a href="http://news.rice.edu/2017/07/31/need-graphene-grab-a-saw-2/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_NewMethodForAdditiveManufactur.jpg" alt="New method for additive manufacturing of liquids - LAM" class="lefter"></p>

<h2><a href="https://www.germanreprap.com/grr-dow-corning-liquid-manufacturing/">New method for additive manufacturing of liquids - LAM</a></h2>

<p><em>"German RepRap, the leading German manufacturer of FFF-3D printers and Dow Corning, a global leader in the field of industrial silicones, are presenting a new method for the additive manufacturing of liquids with the Dow Corning LC-3335 3D Pressure silicone on the formnext 2016. Developed in a joint cooperation, this ground-breaking new production technology allows for the first time the additive processing of silicone materials with nearly identical properties of silicones, which are already widely used in injection molding. "The LC-3335 3D printing silicone material represents the close collaboration between leading 3D printer manufacturers and materials suppliers," said Hugo da Silva, Dow Corning's global industry director for lighting and 3D printing. "More than just a technological achievement, this material brings the power and flexibility of silicon technology to the area of ​​3D printing where users now combine the unique advantages of Dow Corning silicones with faster production of prototypes and small series of highly complex parts. " German RepRap designed its patent-pending new LAM 3D printer to make the silicon processing industry available for the first time to the full potential of additive manufacturing. For example, highly complex geometries can be produced, which previously could not be produced in injection molding or at considerable expense. During the layered setup, a special thermal curing results in a complete crosslinking at the molecular level between the individual silicon layers. This complete crosslinking enables the actual outstanding property of this new process: the mechanical properties of the additive-made silicone part are very close to the mechanical properties of injection-molded parts. Thus this method is not of interest for the generation of functional models and prototypes, Specifically, the test parts made with the LC-3335 silicone on the German RepRap LAM 3D printer show the same sharp curing profile of injection-molded test samples, as well as about 80% of the mechanical properties. In detail, the 3D printed parts have about 70% of the tensile elongation and about 90% of the tensile strength of injection molded samples of comparable material."</em> <a href="https://www.germanreprap.com/grr-dow-corning-liquid-manufacturing/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_DevelopmentOfLogicCircuitsWith.jpg" alt="Development of Logic Circuits with Diamond-Based Transistors" class="lefter"></p>

<h2><a href="http://www.nims.go.jp/eng/news/press/2017/05/201705310.html">Development of Logic Circuits with Diamond-Based Transistors</a></h2>

<p><em>"A NIMS research group has succeeded for the first time in the world in developing a logic circuit equipped with diamond-based MOSFETs (metal-oxide-semiconductor field-effect-transistors) at two different operation modes. This achievement is a first step toward the development of diamond integrated circuits operational under extreme environments. "</em> <a href="http://www.nims.go.jp/eng/news/press/2017/05/201705310.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_LlnlFindsReasonBehindDefectsIn.jpg" alt="LLNL finds reason behind defects in 3D printing" class="lefter"></p>

<h2><a href="https://www.llnl.gov/news/llnl-finds-reason-behind-defects-3d-printing">LLNL finds reason behind defects in 3D printing</a></h2>

<p><em>"High-speed images of a common laser-based metal 3D printing process, coupled with newly updated computer models, have revealed the mechanisms behind material redistribution, a phenomenon that leads to defects in printed metal parts, Lawrence Livermore National Laboratory (LLNL) researchers reported. In a study published by Scientific Reports (link is external), LLNL scientists combined ultrafast imaging of melt-pool dynamics with high-resolution simulations, finding that particles of liquid metal ejected from the laser's path during the powder-bed fusion additive manufacturing (PBFAM) process -- commonly called "spatter" -- is caused by the entrainment of metal particles by an ambient gas flow, not from the laser's recoil pressure, as previously believed. "People have been assuming that recoil pressure leads to spatter because that's what the laser welding community has seen," said Sonny Ly, an LLNL physicist and the paper's lead author. "We imaged right at the melt pool and you could see particles ejected right from the pool due to recoil, but a majority of particles are swept away and entrained by the gas flow. The entrained particles can go back into the laser beam and are melted, leading to a more dominant form of spatter.""</em> <a href="https://www.llnl.gov/news/llnl-finds-reason-behind-defects-3d-printing">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_ArtificialSkinCouldAllowRobots.jpg" alt="Artificial skin could allow robots to feel like we do" class="lefter"></p>

<h2><a href="https://horizon-magazine.eu/article/artificial-skin-could-allow-robots-feel-we-do_en.html">Artificial skin could allow robots to feel like we do</a></h2>

<p><em>"Artificial skin with post-human sensing capabilities, and a better understanding of skin tissue, could pave the way for robots that can feel, smart-transplants and even cyborgs. Few people would immediately recognise the skin as our bodies’ largest organ, but the adult human has on average two square metres of it. It’s also one of the most important organs and is full of nerve endings that provide us with instant reports of temperature, pressure and pain. So far the best attempts to copy this remarkable organ have resulted in experimental skin with sensor arrays that, at best, can only measure one particular stimulus. But the SmartCore project, funded by the EU's European Research Council and at the Graz University of Technology (TU Graz) in Austria, hopes to create a material that responds to multiple stimuli. To do so requires working at a nanoscale — where one nanometre represents a billionth of a metre — creating embedded arrays of minuscule sensors that could be 2 000 times more sensitive than human skin. Principal investigator Dr Anna Maria Coclite, an assistant professor at TU Graz’s Institute for Solid State Physics, says the project aims to create a nanoscale sensor which can pick up temperature, humidity and pressure — not separately, but as an all-in-one package. ‘They will be made of a smart polymer core which expands depending on the humidity and temperature, and a piezoelectric shell, which produces an electric current when pressure is applied,’ she said. These smart cores would be sandwiched between two similarly tiny nanoscale grids of electrodes which sense the electrical charges given off when the sensors ‘feel’ and then transmit this data. If the team can surmount the primary challenge of distinguishing between the different senses, the first prototype should be ready in 2019, opening the door for a range of test uses."</em> <a href="https://horizon-magazine.eu/article/artificial-skin-could-allow-robots-feel-we-do_en.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_AlgorithmsThatCanSketchRecreat.jpg" alt="Algorithms that can sketch, recreate 3D shapes" class="lefter"></p>

<h2><a href="https://news.ubc.ca/2017/08/01/algorithms-that-can-sketch-recreate-3d-shapes/">Algorithms that can sketch, recreate 3D shapes</a></h2>

<p><em>"A University of British Columbia computer scientist has created a new software that can create a design sketch of an everyday object, addressing the challenge of accurately describing shapes. The program, called FlowRep, was designed by computer science professor Alla Sheffer, in cooperation with Adobe Research and Washington University in St. Louis. “If you try to explain what your computer mouse looks like to someone who has never seen a mouse before, you’re going to struggle to verbally describe its shape,” said Sheffer, who unveiled the new program today at SIGGRAPH 2017, the world’s largest computer graphics and interactive techniques conference. “Humans are good at verbally describing colour or dimensions, but cannot easily articulate geometric properties. The easiest way to describe shapes is to sketch them.” To create the program, Sheffer used insights from a field of psychology known as Gestalt psychology that explains how humans interpret visual content and understand depth from  two-dimensional drawings. The algorithms she developed based on these insights help turn diverse shapes like airplanes, cars, coffee makers and mugs into sketches. “All you need is a dozen strokes or less and people will be able to envision the geometry of an object,” she said. “This program answers the question about which surface curves we need to trace so that human observers can imagine a shape.” This research builds on earlier algorithms that Sheffer and her colleagues developed that can turn sketches and drawings into 3D shapes. Together, these methods can be used to recreate objects around us and has implications for fields like 3D printing and fabrication. Sheffer’s program has worked well in user studies. The sketches and 3D curves produced by the algorithm were deemed comparable to those produced by professional designers. Sheffer is now looking to explore additional applications of the system."</em> <a href="https://news.ubc.ca/2017/08/01/algorithms-that-can-sketch-recreate-3d-shapes/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_4DMoviesCapturePeopleInClothin.jpg" alt="4D Movies Capture People in Clothing, Creating Realistic Virtual Try-on" class="lefter"></p>

<h2><a href="https://is.tuebingen.mpg.de/news/4d-movies-capture-people-in-clothing-creating-realistic-virtual-try-on">4D Movies Capture People in Clothing, Creating Realistic Virtual Try-on</a></h2>

<p><em>"Researchers at the Max Planck Institute for Intelligent Systems (MPI-IS) have developed technology to digitally capture clothing on moving people, turn it into a 3D digital form, and dress virtual avatars with it. This new technology makes virtual clothing try-on practical. You see a brilliant dress on Michelle Obama and wonder what it would look like on you? Imagine trying it on and seeing how the fabric moves and how it fits before buying. This technology could make this possible by dressing your virtual avatar. Traditional virtual clothing try-on involves getting the 2D clothing pattern from the manufacturer, sizing this to a body, and simulating how the clothing drapes on the body. The new technique replaces garment simulation with garment capture. Capturing and transferring existing garments to new people greatly simplifies the process of virtual try-on. “Our approach is to scan a person wearing the garment, separate the clothing from the person, and then rendering it on top of a new person”-- says Dr. Gerard Pons-Moll, research scientist at MPI-IS and principal investigator of the project. “This process captures all the detail present in real clothing, including how it moves, which is hard to replicate with simulation,” says Pons-Moll. The ClothCap (ClothCapture) results exceed the realism of existing approaches (Figure 1)."</em> <a href="https://is.tuebingen.mpg.de/news/4d-movies-capture-people-in-clothing-creating-realistic-virtual-try-on">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_MicrobotOrigamiCanCaptureTrans.jpg" alt="Microbot Origami Can Capture, Transport Single Cells" class="lefter"></p>

<h2><a href="https://news.ncsu.edu/2017/08/microbot-origami/">Microbot Origami Can Capture, Transport Single Cells</a></h2>

<p><em>"Researchers at North Carolina State University and Duke University have developed a way to assemble and pre-program tiny structures made from microscopic cubes – “microbot origami” – to change their shape when actuated by a magnetic field and then, using the magnetic energy from their environment, perform a variety of tasks – including capturing and transporting single cells. The findings, published today in Science Advances, pave the way for microbots and micro-origami assemblies that can serve as cell characterization tools, fluid micromixers, and components of artificial muscles and soft biomimetic devices. “This research is about a topic of current interest – active particles which take energy from their environment and convert it into directional movement,” said Orlin Velev, INVISTA Professor of Chemical and Biomolecular Engineering at NC State and co-corresponding author of the paper. To create the microbot origami, the researchers started with microscopic polymer cubes that are metallic on one side, essentially allowing the metallic side to act as a magnet. Depending on their positioning, the cubes can be assembled in many different ways. “Since they are magnetized and interacting, the cubes store energy,” Velev said. “Tiny particles in the shape of cubes can attach together in sequences where they face in different directions to make, for example, clusters that behave like a tiny Pac-Man: You can open them by applying a magnetic field and then let them close by turning the magnetic field off. They close because they are releasing the stored magnetic energy. Thus, you inject internal energy every time you open the microclusters and release it when they close.” The researchers then gave the tiny Pac-Man a specific task: capturing a live cell, in this case a yeast cell. The microbot formed into a boxy shape and, through its opening and closing motions, “swam” to surround the yeast cell. The researchers then turned off the magnetic field that controlled the folding of the microbot to capture the yeast cell, moved it and finally released it."</em> <a href="https://news.ncsu.edu/2017/08/microbot-origami/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_LightsActionPhotoActivatedCata.jpg" alt="Lights! Action! Photo-Activated Catalyst Grabs CO2 to Make Ingredients for Fuel" class="lefter"></p>

<h2><a href="http://newscenter.lbl.gov/2017/07/28/photocatalyst-grabs-co2-to-make-ingredients-for-fuel/">Lights! Action! Photo-Activated Catalyst Grabs CO2 to Make Ingredients for Fuel</a></h2>

<p><em>"Scientists have developed a light-activated material that can chemically convert carbon dioxide into carbon monoxide without generating unwanted byproducts. The achievement marks a significant step forward in developing technology that could help generate fuel and other energy-rich products using a solar-powered catalyst while mitigating levels of a potent greenhouse gas. When exposed to visible light, the material, a “spongy” nickel organic crystalline structure, converted the carbon dioxide (CO2) in a reaction chamber exclusively into carbon monoxide (CO) gas, which can be further turned into liquid fuels, solvents, and other useful products. An international research team led by scientists at the Department of Energy’s Lawrence Berkeley National Laboratory (Berkeley Lab) and Nanyang Technological University (NTU) in Singapore published the work July 28 in the journal Science Advances. “We show a near 100 percent selectivity of CO production, with no detection of competing gas products like hydrogen or methane,” said Haimei Zheng, staff scientist in Berkeley Lab’s Materials Sciences Division and co-corresponding author of the study. “That’s a big deal. In carbon dioxide reduction, you want to come away with one product, not a mix of different things.”"</em> <a href="http://newscenter.lbl.gov/2017/07/28/photocatalyst-grabs-co2-to-make-ingredients-for-fuel/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_RedGreenYellowBlue.jpg" alt="Red, green, yellow, blue ..." class="lefter"></p>

<h2><a href="http://www.en.uni-muenchen.de/news/press-services/press-releases/2017/nickel_leds_eng.html">Red, green, yellow, blue ...</a></h2>

<p><em>"The color of the light emitted by an LED can be tuned by altering the size of their semiconductor crystals. LMU researchers have now found a clever and economical way of doing just that, which lends itself to industrial-scale production. Unlike our old friend the incandescent lightbulb, light-emitting diodes (or LEDs) produce light of a defined color within the spectral range from the infrared to the ultraviolet. The exact wavelength of the emission is determined by the chemical composition of the semiconductor employed, which is the crucial component of these devices. In the case of some semi-conducting materials, the color can also be tuned by appropriately modifying the size of the crystals of which the light-emitting layer is composed. In crystals with dimensions on the order of a few nanometers, quantum mechanical effects begin to make themselves felt. LMU researchers in collaboration with colleagues at the University of Linz (Austria) have now developed a method for the production of semi-conducting nanocrystals of defined size based on the cheap mineral oxide known as perovskite. These crystals are extremely stable, which ensures that the LEDs exhibit high color fidelity – an important criterion of quality. Moreover, the resulting semiconductors can be printed on suitable surfaces, and are thus predestined for the manufacture of LEDs for use in displays. The crucial element in the new method is a thin wafer, only a few nanometers thick, which is patterned like a waffle. The depressions serve as tiny reaction vessels, whose shape and volume ultimately determine the final size of the nanocrystals. “Optimal measurements of the size of the crystals were obtained using a fine beam of high-energy X-radiation at the Deutsche Elektronen-Synchrotron (DESY) in Hamburg“, says LMU researcher Dr. Bert Nickel, member of the Nanosystems Initiative Munich (NIM), a Cluster of Excellence. Moreover, the wafers are produced by means of an economical electrochemical process, and can be fashioned directly into LEDs. “Our nanostructure oxide layers also prevent contact between the semiconductor crystals and deleterious environmental factors such as free oxygen and water, which would otherwise limit the working lifetime of the LEDs,” as Dr. Martin Kaltenbrunner of the Johannes Kepler University in Linz explains. In the next step, we want to enhance the efficiency of these diodes further, and explore their potential for use in other applications, such as flexible displays."</em> <a href="http://www.en.uni-muenchen.de/news/press-services/press-releases/2017/nickel_leds_eng.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_ScientistsProbeTheConditionsOf.jpg" alt="Scientists probe the conditions of stellar interiors to measure nuclear reactions" class="lefter"></p>

<h2><a href="https://www.llnl.gov/news/scientists-probe-conditions-stellar-interiors-measure-nuclear-reactions">Scientists probe the conditions of stellar interiors to measure nuclear reactions</a></h2>

<p><em>"Most of the nuclear reactions that drive the nucleosynthesis of the elements in our universe occur in very extreme stellar plasma conditions. This intense environment found in the deep interiors of stars has made it nearly impossible for scientists to perform nuclear measurements in these conditions -- until now. In a unique cross-disciplinary collaboration between the fields of plasma physics, nuclear astrophysics and laser fusion, a team of researchers, including scientists from Lawrence Livermore National Laboratory (LLNL), Ohio University, the Massachusetts Institute of Technology (MIT) and Los Alamos National Laboratory (LANL), describe experiments performed in conditions like those of stellar interiors. The team's findings were published today by Nature Physics. The experiments are the first thermonuclear measurements of nuclear reaction cross-sections -- a quantity that describes the probability that reactants will undergo a fusion reaction -- in high-energy-density plasma conditions that are equivalent to the burning cores of giant stars, i.e., 10-40 times more massive than the sun. These extreme plasma conditions boast hydrogen-isotope densities compressed by a factor of a thousand to near that of solid lead and temperatures heated to approximately 50 million Kelvin. These are the conditions in stars that lead to supernovae, the most massive explosions in the universe."</em> <a href="https://www.llnl.gov/news/scientists-probe-conditions-stellar-interiors-measure-nuclear-reactions">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_QuantumMagnetsDopedWithHoles.jpg" alt="Quantum magnets doped with holes" class="lefter"></p>

<h2><a href="http://www.mpq.mpg.de/5529258/17_08_04">Quantum magnets doped with holes</a></h2>

<p><em>"Magnetism is a phenomenon that we experience in everyday-life quite often. The property, which is observed in materials such as such as iron, is caused by the alignment of electron spins. Even more interesting effects are expected in case that the magnetic crystals exhibit holes, i.e., lattice sites that are not occupied with an electron. Because of the interplay between the motion of the defect and the magnetic correlations of the electron spins, the magnetic order seems to be suppressed. In general, solid state physicists are not able to separate the two processes, so they cannot answer the question, whether the magnetic order is indeed reduced, or whether it is just hidden. Now a team of scientists around Dr. Christian Groß from the Quantum Many-Body Systems Division (director Professor Immanuel Bloch) at the Max Planck Institute of Quantum Optics has demonstrated that in one-dimensional quantum magnets the magnetic order is preserved even when they are doped with holes – a direct manifestation of spin-charge (density) separation. The quantum crystals were prepared by chains of ultracold atoms in an optical lattice. The observation was made possible with a unique tool which allows tracking the motion of holes and the spin excitations separately in one measurement process (Science, 4 August 2017). In the next step the scientists plan to extend the method to two-dimensional systems. Here the interaction between holes and magnetic correlations is by far more complex. It could lead to the detection of exotic many-body phases that might be responsible for the occurrence of high-temperature superconductivity. The Garching team starts with cooling an ensemble of fermionic lithium-6 atoms down to extremely low temperatures, a millionth of a Kelvin above absolute zero. The atoms are then captured in a single plane in a two-dimensional optical lattice that is created by laser beams. The plane in turn is split into about 10 one-dimensional tubes along which the atoms can move. In the last step, the tubes are superimposed with an optical lattice which mimics the periodic potential that electrons see in a real material. In analogy to electrons lithium atoms carry a spin-1/2 (or magnetic moment) which can point either upwards or downwards. In a previous experiment with a similar system the scientists have shown that below a certain temperature the magnetic moments of neighbouring atoms align in opposite directions such that antiferromagnetic correlations emerge. In the follow up experiment they investigate the influence of holes on the degree of order of the quantum crystal. “We achieve a certain amount of hole doping by making sure that the number of atoms loaded into the optical lattice is smaller than the number of lattice sites,” says Timon Hilker, first author and doctoral candidate at the experiment. “Now the questions arise, whether the holes are fixed or whether they can move, and how they affect the magnetic order of the system.”"</em> <a href="http://www.mpq.mpg.de/5529258/17_08_04">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_ScientistsCloserToExplainingWh.jpg" alt="Scientists closer to explaining why matter persists over antimatter" class="lefter"></p>

<h2><a href="http://www3.imperial.ac.uk/newsandeventspggrp/imperialcollege/newssummary/news_4-8-2017-14-35-38">Scientists closer to explaining why matter persists over antimatter</a></h2>

<p><em>"New results show a difference in the way neutrinos and antineutrinos behave, which could help explain why there is so much matter in the universe. The results, announced today by the international team of scientists including large group from Imperial College London, suggest there could be a difference between the behaviour of matter and antimatter. The T2K Collaboration of scientists studies the properties of neutrinos and their antimatter counterparts, antineutrinos. Neutrinos are fundamental particles that make up our universe and are among the least understood. Yet every second around 50 trillion neutrinos from the Sun pass through your body. Understanding whether neutrinos and antineutrinos behave differently is important, because if all types of matter and antimatter behave the same way, they should have completely wiped each other out shortly after the Big Bang. If this were the case, our universe would not exist. Neutrinos and antineutrinos can both change between three ‘flavours’ as they travel, named electron, muon and tau neutrinos. Changes between the three flavours are known as oscillations."</em> <a href="http://www3.imperial.ac.uk/newsandeventspggrp/imperialcollege/newssummary/news_4-8-2017-14-35-38">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_NewAiAlgorithmMonitorsSleepWit.jpg" alt="New AI algorithm monitors sleep with radio waves" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/new-ai-algorithm-monitors-sleep-radio-waves-0807">New AI algorithm monitors sleep with radio waves</a></h2>

<p><em>"Patients with sleep disorders could be studied nonintrusively at home using wireless signals. More than 50 million Americans suffer from sleep disorders, and diseases including Parkinson’s and Alzheimer’s can also disrupt sleep. Diagnosing and monitoring these conditions usually requires attaching electrodes and a variety of other sensors to patients, which can further disrupt their sleep. To make it easier to diagnose and study sleep problems, researchers at MIT and Massachusetts General Hospital have devised a new way to monitor sleep stages without sensors attached to the body. Their device uses an advanced artificial intelligence algorithm to analyze the radio signals around the person and translate those measurements into sleep stages: light, deep, or rapid eye movement (REM). “Imagine if your Wi-Fi router knows when you are dreaming, and can monitor whether you are having enough deep sleep, which is necessary for memory consolidation,” says Dina Katabi, the Andrew and Erna Viterbi Professor of Electrical Engineering and Computer Science, who led the study. “Our vision is developing health sensors that will disappear into the background and capture physiological signals and important health metrics, without asking the user to change her behavior in any way.” Katabi worked on the study with Matt Bianchi, chief of the Division of Sleep Medicine at MGH, and Tommi Jaakkola, the Thomas Siebel Professor of Electrical Engineering and Computer Science and a member of the Institute for Data, Systems, and Society at MIT. Mingmin Zhao, an MIT graduate student, is the paper’s first author, and Shichao Yue, another MIT graduate student, is also a co-author. The researchers will present their paper at the International Conference on Machine Learning on Aug. 9."</em> <a href="http://news.mit.edu/2017/new-ai-algorithm-monitors-sleep-radio-waves-0807">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_WorldsSmallestNeutrinoDetector.jpg" alt="World’s smallest neutrino detector finds big physics fingerprint" class="lefter"></p>

<h2><a href="https://www.ornl.gov/news/world-s-smallest-neutrino-detector-finds-big-physics-fingerprint">World’s smallest neutrino detector finds big physics fingerprint</a></h2>

<p><em>"After more than a year of operation at the Department of Energy’s (DOE’s) Oak Ridge National Laboratory (ORNL), the COHERENT experiment, using the world’s smallest neutrino detector, has found a big fingerprint of the elusive, electrically neutral particles that interact only weakly with matter. The research, performed at ORNL’s Spallation Neutron Source (SNS) and published in the journal Science, provides compelling evidence for a neutrino interaction process predicted by theorists 43 years ago, but never seen. “The one-of-a-kind particle physics experiment at Oak Ridge National Laboratory was the first to measure coherent scattering of low-energy neutrinos off nuclei,” said ORNL physicist Jason Newby, technical coordinator and one of 11 ORNL participants in COHERENT, a collaboration of 80 researchers from 19 institutions and 4 nations. The SNS produces neutrons for scientific research and also generates a high flux of neutrinos as a byproduct. Placing the detector at SNS, a mere 65 feet (20 meters) from the neutrino source, vastly improved the chances of interactions and allowed the researchers to decrease the detector’s weight to just 32 pounds (14.5 kilograms). In comparison, most neutrino detectors weigh thousands of tons: although they are continuously exposed to solar, terrestrial, and atmospheric neutrinos, they need to be massive because the interaction odds are more than 100 times lower than at SNS. The scientists are the first to detect and characterize coherent elastic scattering of neutrinos off nuclei. This long-sought confirmation, predicted in the particle physics Standard Model, measures the process with enough precision to establish constraints on alternative theoretical models. Typically, neutrinos interact with individual protons or neutrons inside a nucleus. But in “coherent” scattering, an approaching neutrino “sees” the entire weak charge of the nucleus as a whole and interacts with all of it. “The energy of the SNS neutrinos is almost perfectly tuned for this experiment—large enough to create a detectable signal, but small enough to take advantage of the coherence condition,” Newby said. “The only smoking gun of the interaction is a small amount of energy imparted to a single nucleus.” That signal is as tough to spot as a bowling ball’s tiny recoil after a ping-pong ball hits it. Physicist Juan Collar of the University of Chicago led the design of the detector used at SNS, a cesium iodide scintillator crystal doped with sodium to increase the prominence of light signals from neutrino interactions. After trying more sophisticated technologies, he went back to simple inorganic scintillators. “They are arguably the most pedestrian kind of radiation detector available, having been around for a century. Sodium-doped cesium iodide merges all of the properties required to work as a small, ‘handheld’ coherent neutrino detector,” he said. “Very often, less is more.” Success depended on finding the right combination of neutrino detector and source. “The detector was designed with SNS in mind,” Collar said. “SNS is unique not only as a neutron source, but also as a neutrino source. It will provide us with opportunities for many more exciting sorties into neutrino physics.” Because SNS produces pulsed neutron beams, the neutrinos are also pulsed, enabling easy separation of signal from background. That aspect makes data collection cleaner than at steady-state neutrino sources such as nuclear reactors. Three neutrino flavors were seen by COHERENT—muon neutrinos that emerged instantaneously with the neutron beam and muon antineutrinos and electron neutrinos that came a few microseconds later. “The Standard Model predicts the energy and time signatures we saw,” Newby said. “Juan [Collar] wanted to make sure that he chose a detection mechanism with the timing resolution to distinguish the prompt from delayed signals.”"</em> <a href="https://www.ornl.gov/news/world-s-smallest-neutrino-detector-finds-big-physics-fingerprint">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_TinyTerahertzLaserCouldBeUsedF.jpg" alt="Tiny terahertz laser could be used for imaging, chemical detection" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/tiny-terahertz-laser-imaging-chemical-detection-0808">Tiny terahertz laser could be used for imaging, chemical detection</a></h2>

<p><em>"Terahertz radiation — the band of the electromagnetic spectrum between microwaves and visible light — has promising applications in medical and industrial imaging and chemical detection, among other uses. But many of those applications depend on small, power-efficient sources of terahertz rays, and the standard method for producing them involves a bulky, power-hungry, tabletop device. For more than 20 years, Qing Hu, a distinguished professor of electrical engineering and computer science at MIT, and his group have been working on sources of terahertz radiation that can be etched onto microchips. In the latest issue of Nature Photonics, members of Hu’s group and colleagues at Sandia National Laboratories and the University of Toronto describe a novel design that boosts the power output of chip-mounted terahertz lasers by 80 percent. As the best-performing chip-mounted terahertz source yet reported, the researchers’ device has been selected by NASA to provide terahertz emission for its Galactic/Extragalactic ULDB Spectroscopic Terahertz Observatory (GUSTO) mission. The mission is intended to determine the composition of the interstellar medium, or the matter that fills the space between stars, and it’s using terahertz rays because they’re uniquely well-suited to spectroscopic measurement of oxygen concentrations. Because the mission will deploy instrument-laden balloons to the Earth’s upper atmosphere, the terahertz emitter needs to be lightweight. The researchers’ design is a new variation on a device called a quantum cascade laser with distributed feedback. “We started with this because it was the best out there,” says Ali Khalatpour, a graduate student in electrical engineering and computer science and first author on the paper. “It has the optimum performance for terahertz.” Until now, however, the device has had a major drawback, which is that it naturally emits radiation in two opposed directions. Since most applications of terahertz radiation require directed light, that means that the device squanders half of its energy output. Khalatpour and his colleagues found a way to redirect 80 percent of the light that usually exits the back of the laser, so that it travels in the desired direction. As Khalatpour explains, the researchers’ design is not tied to any particular “gain medium,” or combination of materials in the body of the laser. “If we come up with a better gain medium, we can double its output power, too,” Khalatpour says. “We increased power without designing a new active medium, which is pretty hard. Usually, even a 10 percent increase requires a lot of work in every aspect of the design.”"</em> <a href="http://news.mit.edu/2017/tiny-terahertz-laser-imaging-chemical-detection-0808">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_ByuResearchersDevelopMethodTha.jpg" alt="BYU researchers develop method that could produce stronger, more pliable metals" class="lefter"></p>

<h2><a href="https://news.byu.edu/news/byu-researchers-develop-method-could-produce-stronger-more-pliable-metals">BYU researchers develop method that could produce stronger, more pliable metals</a></h2>

<p><em>"It may not be as catchy as chains and weak links, but physicists and engineers know “a material is only as strong as its weakest grain boundary.” OK, that’s not catchy at all, but here’s the point: grain boundaries are a big deal. They are the microscopic, disordered regions where atom-sized building blocks bind the crystals (i.e. grains) together in materials. More importantly, grain boundaries help determine the properties of metals important to humans. For example, they can influence a metal’s strength (buildings!), corrosion resistance (bridges!) and conductivity (electricity!). But while researchers have studied grain boundaries for decades and gained some insight into the types of properties grain boundaries produce, no one has been able to nail down a universal system to predict if a certain configuration of atoms at grain boundaries will make a material stronger or more pliable. Enter the interdisciplinary BYU research team of Rosenbrock, Homer and Hart. The Ph.D. student (Conrad Rosenbrock) and two professors — one engineer (Eric Homer) and one physicist (Gus Hart) — might have cracked the code by juicing a computer with an algorithm that allows it to learn the elusive “why” behind the boundaries’ qualities. Their method, published in the most recent issue of Nature journal Computational Materials, provides a technique to produce a “dictionary” of the atomic building blocks found in metals, alloys, semiconductors and other materials. Their machine learning approach analyzes Big Data (think: massive data sets of grain boundaries) to provide insight into physical structures that are likely associated with specific mechanisms, processes and properties that would otherwise be difficult to identify. “We’re using machine learning, which means algorithms can see trends in lots and lots of data that a human can’t see,” Homer said. “With Big Data models you lose some precision, but we’ve found it still provides strong enough information to connect the dots between a boundary and a property.” When it comes to metals, the process can evaluate properties like strength, weight and lifespan of materials, leading to the eventual optimization of the best materials. Although the group is not actually creating materials yet, they can now decipher the “why” and the “how” of the makeup."</em> <a href="https://news.byu.edu/news/byu-researchers-develop-method-could-produce-stronger-more-pliable-metals">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_HighResolutionWithoutParticleA.jpg" alt="High resolution without particle accelerator" class="lefter"></p>

<h2><a href="https://www.uni-jena.de/en/Research+News/FM170807_Kohaerenztomo_en.html">High resolution without particle accelerator</a></h2>

<p><em>"A visit to the optometrist often involves optical coherence tomography. This imaging process uses infrared radiation to penetrate the layers of the retina and examine it more closely in three dimensions, without having to touch the eye at all. This allows eye specialists to diagnose diseases such as glaucoma without any physical intervention. However, this method would have even greater potential for science if a shorter radiation wavelength were used, thus allowing a higher resolution of the image. Physicists at Friedrich Schiller University Jena (Germany) have now achieved just that and they have reported their research findings in the latest issue of the specialist journal "Optica" (DOI: 10.1364/OPTICA.4.000903). For the first time, the University physicists used extreme ultraviolet radiation (XUV) for this process, which was generated in their own laboratory, and they were thus able to perform the first XUV coherence tomography at laboratory scale. This radiation has a wavelength of between 20 and 40 nanometres - from which it is therefore just a small step to the X-ray range. "Large-scale equipment, that is to say particle accelerators such as the German Elektronen-Synchotron in Hamburg, are usually necessary for generating XUV radiation," says Silvio Fuchs of the Institute of Optics and Quantum Electronics of the Jena University. "This makes such a research method very complex and costly, and only available to a few researchers." The physicists from Jena have already demonstrated this method at large research facilities, but they have now found a possibility for applying it at a smaller scale. In this approach, they focus an ultrashort, very intense infrared laser in a noble gas, for example argon or neon. "The electrons in the gas are accelerated by means of an ionisation process," explains Fuchs. "They then emit the XUV radiation." It is true that this method is very inefficient, as only a millionth part of the laser radiation is actually transformed from infrared into the extreme ultraviolet range, but this loss can be offset by the use of very powerful laser sources. "It's a simple calculation: the more we put in, the more we get out," adds Fuchs."</em> <a href="https://www.uni-jena.de/en/Research+News/FM170807_Kohaerenztomo_en.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_NewCubesatPropulsionSystemUses.jpg" alt="New CubeSat propulsion system uses water as propellant" class="lefter"></p>

<h2><a href="https://www.purdue.edu/newsroom/releases/2017/Q3/new-cubesat-propulsion-system-uses-water-as-propellant.html">New CubeSat propulsion system uses water as propellant</a></h2>

<p><em>"A new type of micropropulsion system for miniature satellites called CubeSats uses an innovative design of tiny nozzles that release precise bursts of water vapor to maneuver the spacecraft. Low-cost “microsatellites” and “nanosatellites” far smaller than conventional spacecraft, have become increasingly prevalent. Thousands of the miniature satellites might be launched to perform a variety of tasks, from high-resolution imaging and internet services, to disaster response, environmental monitoring and military surveillance. “They offer an opportunity for new missions, such as constellation flying and exploration that their larger counterparts cannot economically achieve,” said Alina Alexeenko, a professor in Purdue University’s School of Aeronautics and Astronautics. However, to achieve their full potential, CubeSats will require micropropulsion devices to deliver precise low-thrust “impulse bits” for scientific, commercial and military space applications. She has led research to develop a new micropropulsion system that uses ultra-purified water. “Water is thought to be abundant on the Martian moon Phobos,” she said. “making it potentially a huge gas station in space. Water is also a very clean propellant, reducing risk of contamination of sensitive instruments by the backflow from thruster plumes.” Research findings about the new system are detailed in a paper being presented during the 31st AIAA/USU Conference on Small Satellites, Aug. 5-10 in Logan, Utah."</em> <a href="https://www.purdue.edu/newsroom/releases/2017/Q3/new-cubesat-propulsion-system-uses-water-as-propellant.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_LunarDynamosLifetimeExtendedBy.jpg" alt="Lunar dynamo’s lifetime extended by at least 1 billion years" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/lunar-dynamo-lifetime-extended-least-1-billion-years-0809">Lunar dynamo’s lifetime extended by at least 1 billion years</a></h2>

<p><em>"New evidence from ancient lunar rocks suggests that an active dynamo once churned within the molten metallic core of the moon, generating a magnetic field that lasted at least 1 billion years longer than previously thought. Dynamos are natural generators of magnetic fields around terrestrial bodies, and are powered by the churning of conducting fluids within many stars and planets. In a paper published today in Science Advances, researchers from MIT and Rutgers University report that a lunar rock collected by NASA’s Apollo 15 mission exhibits signs that it formed 1 to 2.5 billion years ago in the presence of a relatively weak magnetic field of about 5 microtesla. That’s around 10 times weaker than Earth’s current magnetic field but still 1,000 times larger than fields in interplanetary space today. Several years ago, the same researchers identified 4-billion-year-old lunar rocks that formed under a much stronger field of about 100 microtesla, and they determined that the strength of this field dropped off precipitously around 3 billion years ago. At the time, the researchers were unsure whether the moon’s dynamo — the related magnetic field — died out shortly thereafter or lingered in a weakened state before dissipating completely. The results reported today support the latter scenario: After the moon’s magnetic field dwindled, it nonetheless persisted for at least another billion years, existing for a total of at least 2 billion years. Study co-author Benjamin Weiss, professor of planetary sciences in MIT’s Department of Earth, Atmospheric and Planetary Sciences (EAPS), says this new extended lifetime helps to pinpoint the phenomena that powered the moon’s dynamo. Specifically, the results raise the possibility of two different mechanisms — one that may have driven an earlier, much stronger dynamo, and a second that kept the moon’s core simmering at a much slower boil toward the end of its lifetime."</em> <a href="http://news.mit.edu/2017/lunar-dynamo-lifetime-extended-least-1-billion-years-0809">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_SpectacularImagesThanksToAnEff.jpg" alt="Spectacular images thanks to an efficient algorithm" class="lefter"></p>

<h2><a href="https://www.ethz.ch/en/news-and-events/eth-news/news/2017/08/spectacular-images-thanks-to-an-efficient-algorithm.html">Spectacular images thanks to an efficient algorithm</a></h2>

<p><em>"Filming of spectacular action scenes is expensive and the creative possibilities are often limited. An ETH doctoral student has developed an algorithm that allows drones to implement the desired picture compositions independently. The film Skyfall has its viewers spellbound as James Bond attempts to neutralise his adversary on the roof of a train as it races through the desert. Here, tension is created using a series of rapidly changing camera angles: a close-up of Bond’s face, then a medium shot of the fight scene, and lastly a very long shot of the train, the desert and the two men fighting. This was an extremely expensive scene to film in terms of personnel, materials and technology. Several camera operators were deployed for hours on end at a number of different locations. And a camera crane even had to be mounted on the train’s roof for the spectacular close-up shots. Tobias Nägeli, a doctoral student in the Advanced Interactive Technologies Lab led by ETH professor Otmar Hilliges, is convinced that these scenes can be filmed with fewer resources. Together with researchers from Delft University of Technology and ETH spin-off Embotech, he has developed an algorithm that enables drones to film dynamic scenes independently in the way that directors and cinematographers intend."</em> <a href="https://www.ethz.ch/en/news-and-events/eth-news/news/2017/08/spectacular-images-thanks-to-an-efficient-algorithm.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_BeforeItWas3DPrintingNowAdditi.jpg" alt="Before, it was 3D printing: Now Additive Manufacturing is the new black" class="lefter"></p>

<h2><a href="http://www.dtu.dk/english/news/2017/08/dynamo-theme-2-before-it-was-3d-printing-now-additive-manufacturing-is-the-new-black?id=d6742595-0eeb-4a4f-8399-d87d368c1798">Before, it was 3D printing: Now Additive Manufacturing is the new black</a></h2>

<p><em>"However, 3D printing is a key technology within Additive Manufacturing, a concept which is attracting the interest of a growing number of companies. Places were in high demand for the innovation conference ‘Additive Manufacturing’, which was held for Danish manufacturing companies in spring 2017. Additive Manufacturing covers manufacturing technologies that involve building up components in layers by depositing material.This can be done by means of several different methods, one of them being 3D printing. And the significant level of interest is not confined to Denmark, but is growing everywhere. “Additive Manufacturing is a hot topic in the manufacturing industry worldwide at the moment. Companies are looking for ways in which they can produce products and prototypes fast and in more cost-efficient ways,” says Guido Tosello, Associate Professor at DTU Mechanical Engineering, at the innovation conference. In recent years there has been a lot of hype surrounding 3D printing, but that is beginning to fade, says David Bue Pedersen, who holds Denmark’s first PhD in 3D printing and Additive Manufacturing, and who is a postdoc at DTU Mechanical Engineering: “People are finally coming to terms with what 3D printing can actually be used for. Several years ago, the mass media was predicting that 3D printing would replace all forms of production, which couldn’t have been more wrong. 3D printing is just one technology out of many whereby companies can work with Additive Manufacturing.”"</em> <a href="http://www.dtu.dk/english/news/2017/08/dynamo-theme-2-before-it-was-3d-printing-now-additive-manufacturing-is-the-new-black?id=d6742595-0eeb-4a4f-8399-d87d368c1798">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_CwruResearchersFindAChemicalSo.jpg" alt="CWRU researchers find a chemical solution shrinks digital data storage" class="lefter"></p>

<h2><a href="http://thedaily.case.edu/cwru-researchers-find-chemical-solution-shrinks-digital-data-storage/">CWRU researchers find a chemical solution shrinks digital data storage</a></h2>

<p><em>"Chemists at Case Western Reserve University have found a way to possibly store digital data in half the space current systems require. From supercomputers to smartphones, the amount of data people generate and collect continues to grow exponentially, and the need to store all that information grows with it. Computers and other digital devices operate and store data using a binary code, meaning two symbols—typically the numerals 0 and 1—represent information. To reduce storage space, engineers have traditionally used existing technology but made it smaller. For example, a compact disc is made with a red laser and a Blu-ray disc with a blue, more focused, laser that reduces the size of the symbols and the space between them, increasing data density. But according to a new study published in the Journal of Materials Chemistry C, researchers at Case Western Reserve demonstrate how commonly used polymer films containing two dyes can optically store data in a quaternary (four-symbol) code, potentially requiring about half as much space."</em> <a href="http://thedaily.case.edu/cwru-researchers-find-chemical-solution-shrinks-digital-data-storage/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_NewResearchInitiativeTurnsLase.jpg" alt="New research initiative turns laser focus on high-energy-density physics" class="lefter"></p>

<h2><a href="http://www.rochester.edu/newscenter/high-pressure-stakes-high-energy-density-physics-university-rochester-260662/">New research initiative turns laser focus on high-energy-density physics</a></h2>

<p><em>"Atoms behave much differently when squeezed to pressures more than a million—or even a billion—times the atmospheric pressure on Earth. Understanding how atoms react under such high-pressure conditions can lead to the creation of new materials and give scientists valuable insights into the make-up of stars and planets, as well as the universe itself. Those are among the reasons the University of Rochester has turned its attention to the relatively new field of high-energy-density physics. Another reason is that the University is well poised to make major contributions to the field. “Our people and our resources put us in a unique position to gain crucial insights in the field of high-energy-density physics,” says Provost and Senior Vice President for Research Rob Clark. Rochester’s Laboratory for Laser Energetics, for example, is home to the OMEGA laser. At 10 meters tall and 100 meters long, the OMEGA is the world’s largest university-based laser. Rochester has also recruited Gilbert “Rip” Collins to lead a new, multidisciplinary research initiative for high-energy-density physics. Collins was previously the director of Lawrence Livermore National Laboratory’s Center for High-Energy-Density Physics, and is now professor in the Department of Mechanical Engineering and the Department of Physics and Astronomy, as well as senior scientist at the University’s Laboratory for Laser Energetics. Collins says the initiative “will make it easier to collaborate between chemistry, engineering, physics, and astronomy,” leading to faster advances in the field. Collins studies, among other things, how atoms bond under conditions of extreme pressure. Typically, it’s the outermost electrons of an atom that react with the electrons of other atoms. But when the pressure on the atoms is greatly increased, the inner electrons get involved, and that’s when the fun begins."</em> <a href="http://www.rochester.edu/newscenter/high-pressure-stakes-high-energy-density-physics-university-rochester-260662/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_SensingTechnologyTakesAQuantum.jpg" alt="Sensing technology takes a quantum leap with RIT photonics research" class="lefter"></p>

<h2><a href="http://www.rit.edu/news/story.php?id=62861">Sensing technology takes a quantum leap with RIT photonics research</a></h2>

<p><em>"Research underway at RIT advances a new kind of sensing technology that captures data with better precision than currently possible and promises cheaper, smaller and lighter sensor designs. Mishkat Bhattacharya, a theoretical physicist at RIT, is investigating new precision quantum sensing solutions for the U.S. Department of the Navy’s Office of Naval Research. The three-year study is supported by $550,000 grant and is a continuation of a previous award. Bhattacharya will test interactions between light and matter at the nanoscale and analyze measurements of weak electromagnetic fields and gravitational forces. Specialized microscopes measure theoretical predictions that describe matter at the nanoscale in which a nanometer equals one-billionth of a meter and a human hair measures between 80,000-100,000 nanometers, according to the U.S. National Nanotechnology Initiative. Bhattacharya works in the emerging field of levitated optomechanics, an area of physics that investigates nanoparticles by trapping them in a laser beam. Laser trapping—a method known as “optical tweezers”—tests the limits of quantum effects in isolation and eliminates physical disturbances from the surrounding environment. Using the techniques of laser trapping, Bhattacharya takes quantum mechanics to the next level by probing quantum effects in the nanoparticles, which contain billions of atoms. He investigates where quantum mechanics (which governs the microscopic) butts up against classical physics (which explains the macroscopic) and explores light-matter interaction in macroscopic quantum physics."</em> <a href="http://www.rit.edu/news/story.php?id=62861">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_FourEarthSizedPlanetsDetectedO.jpg" alt="Four Earth-sized planets detected orbiting the nearest sun-like star" class="lefter"></p>

<h2><a href="https://news.ucsc.edu/2017/08/tau-ceti-planets.html">Four Earth-sized planets detected orbiting the nearest sun-like star</a></h2>

<p><em>"A new study by an international team of astronomers reveals that four Earth-sized planets orbit the nearest sun-like star, tau Ceti, which is about 12 light years away and visible to the naked eye. These planets have masses as low as 1.7 Earth mass, making them among the smallest planets ever detected around nearby sun-like stars. Two of them are super-Earths located in the habitable zone of the star, meaning they could support liquid surface water. The planets were detected by observing the wobbles in the movement of tau Ceti. This required techniques sensitive enough to detect variations in the movement of the star as small as 30 centimeters per second. "We are now finally crossing a threshold where, through very sophisticated modeling of large combined data sets from multiple independent observers, we can disentangle the noise due to stellar surface activity from the very tiny signals generated by the gravitational tugs from Earth-sized orbiting planets," said coauthor Steven Vogt, professor of astronomy and astrophysics at UC Santa Cruz. According to lead author Fabo Feng of the University of Hertfordshire, UK, the researchers are getting tantalizingly close to the 10-centimeter-per-second limit required for detecting Earth analogs. "Our detection of such weak wobbles is a milestone in the search for Earth analogs and the understanding of the Earth's habitability through comparison with these analogs," Feng said. "We have introduced new methods to remove the noise in the data in order to reveal the weak planetary signals." The outer two planets around tau Ceti are likely to be candidate habitable worlds, although a massive debris disc around the star probably reduces their habitability due to intensive bombardment by asteroids and comets. The same team also investigated tau Ceti four years ago in 2013, when coauthor Mikko Tuomi of the University of Hertfordshire led an effort in developing data analysis techniques and using the star as a benchmark case. "We came up with an ingenious way of telling the difference between signals caused by planets and those caused by star's activity. We realized that we could see how star's activity differed at different wavelengths and use that information to separate this activity from signals of planets," Tuomi said."</em> <a href="https://news.ucsc.edu/2017/08/tau-ceti-planets.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT119_LandscapesGiveLatitudeTo2DMate.jpg" alt="Landscapes give latitude to 2-D material designers" class="lefter"></p>

<h2><a href="http://news.rice.edu/2017/08/09/landscapes-give-latitude-to-2-d-material-designers/">Landscapes give latitude to 2-D material designers</a></h2>

<p><em>" Rice University researchers have learned to manipulate two-dimensional materials to design in defects that enhance the materials’ properties. The Rice lab of theoretical physicist Boris Yakobson and colleagues at Oak Ridge National Laboratory are combining theory and experimentation to prove it’s possible to give 2-D materials specific defects, especially atomic-scale seams called grain boundaries. These boundaries may be used to enhance the materials’ electronic, magnetic, mechanical, catalytic and optical properties. The key is introducing curvature to the landscape that constrains the way defects propagate. The researchers call this “tilt grain boundary topology,” and they achieve it by growing their materials onto a topographically curved substrate — in this case, a cone. The angle of the cone dictates if, what kind and where the boundaries appear. The research is the subject of a paper in the American Chemical Society journal ACS Nano."</em> <a href="http://news.rice.edu/2017/08/09/landscapes-give-latitude-to-2-d-material-designers/">[...]</a>
 </SPAN></DIV></p>

<h1 id="Documentacao">Documentação</h1>

<p>A documentação é parte essencial do processo de aprendizagem e a Internet além de artigos interessantes de explorar também tem alguma documentação em formato PDF interessante de ler. Todos os <em>links</em> aqui apresentados são para conteúdo disponibilizado livremente pelo editor do livro.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB119_FastFourierTransforms.jpg" alt="Fast Fourier Transforms" class="lefter"></p>

<h2><a href="http://cnx.org/exports/82e6ba6f-b828-42ef-9db1-8de4b448b869%4022.1.pdf/fast-fourier-transforms-22.1.pdf">Fast Fourier Transforms</a></h2>

<p><em>"This book focuses on the discrete Fourier transform (DFT), discrete convolution, and, particularly, the fast algorithms to calculate them. These topics have been at the center of digital signal processing since its beginning, and new results in hardware, theory and applications continue to keep them important and exciting. It is hard to overemphasis the importance of the DFT, convolution, and fast algorithms. With a history that goes back to Gauss [174] and a compilation of references on these topics that in 1995 resulted in over 2400 entries [362], the FFT may be the most important numerical algorithm in science, engineering, and applied mathematics. New theoretical results still are appearing, advances in computers and hardware continually restate the basic questions, and new applications open new areas for research. It is hoped that this book will provide the background, references, programs and incentive to encourage further research and results in this area as well as provide tools for practical applications."</em> <a href="http://cnx.org/exports/82e6ba6f-b828-42ef-9db1-8de4b448b869%4022.1.pdf/fast-fourier-transforms-22.1.pdf">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB119_Newelectronics8Agosto2017.jpg" alt="newelectronics 8 Agosto 2017" class="lefter"></p>

<h2><a href="http://journal-download.co.uk/digitalmagazines//ne/NE08Aug2017FullNE.pdf">newelectronics 8 Agosto 2017</a></h2>

<p><em>"New Electronics is a fortnightly magazine focusing on technological innovation, news and the latest developments in the electronics sector. Downloadable as a digital page turner or pdf file, or offered as a hard copy, the New Electronics magazine is available in a format to suit you."</em> <a href="http://journal-download.co.uk/digitalmagazines//ne/NE08Aug2017FullNE.pdf">[...]</a>
 </SPAN></DIV></p>

<h1 id="Projetos-Maker">Projetos Maker</h1>

<p>Diversos Projetos interessantes.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyTemperatureAndHumidityWirel.jpg" alt="DIY temperature and humidity wireless data logger" class="lefter"></p>

<h2><a href="https://blog.famzah.net/2011/12/26/diy-temperature-and-humidity-wireless-data-logger/">DIY temperature and humidity wireless data logger</a></h2>

<p><em>"Monitoring and controlling relative humidity is important for humans health. Too low or too high humidity feels uncomfortable, but most importantly high moisture is a factor for growing mold in your home, which could be health threatening (according to EPA and CDC). I will not go into details on how to control humidity. Instead I’ll describe what motivated me to design and create my own temperature and humidity sensor which reports its readings every minute to a central Linux server."</em> <a href="https://blog.famzah.net/2011/12/26/diy-temperature-and-humidity-wireless-data-logger/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_SmartOfficeAutomationUsingRasp.jpg" alt="Smart Office Automation Using Raspberry Pi" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Smart-Office-Automation-Using-Raspberry-Pi/">Smart Office Automation Using Raspberry Pi</a></h2>

<p><em>"The smart office concept has evolved significantly over the last few years. Energy efficiency is one of the most common functions for smart offices. Office Automation facilitates efficient and detailed information through the use of devices. Automation also increases the goodwill and reputation of any workplace because it adds to the prestige and status symbol of the enterprise.In this Instructables, we hope to show how you can easily automate your office or workplace with Prota OS with no skills and tailored specifically to your needs. The idea is to strategically use office resources that can monitor energy usage and enable easy control for devices. The key idea of this instructable is to optimize workplace resources and utilize them well.Features Automated and connected devices, lights and appliances. Trigger automation when entering or leaving office using IFTTT. Turn your webcam into a smart cam and receive a snapshot of your workplace and to monitor it easily. Save power and manage resources efficiently. Get notified for each and every automation easily."</em> <a href="http://www.instructables.com/id/Smart-Office-Automation-Using-Raspberry-Pi/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_IotBasedGardenAutomationAndMon.jpg" alt="IoT Based Garden Automation And Monitoring System" class="lefter"></p>

<h2><a href="https://www.hackster.io/vssureshvs1995/iot-based-garden-automation-and-monitoring-system-078229">IoT Based Garden Automation And Monitoring System</a></h2>

<p><em>"The system is designed to sense soil moisture, amount of light falling on the plants and water flow rate. I am belongs to a village and we have our own firm. During staying at my village we were getting plenty of fresh vegetables/herb leaves from our firm (see above images).But now the situation is different, as I am staying in a city no more fresh vegetables/herb leaves. I have to buy these from the store which are not at all fresh. Apart from these they are grown by using harmful pesticides which is not good for health. So I am planning to firming herbs at my balcony which is completely fresh and harmless. But firming is a time consuming process. I always forget to give water in my flower plants. This leads to give the idea of automated gardening system. The system is designed to sense soil moisture, amount of light falling on the plants and water flow rate. When the moisture content in the soil is too low, the system will give command to start a pump and water the soil. The flow meter monitor the water consumption. Apart from this the Arduino and ESP8266 it will transmit information on moisture level, ambient light and flow rate to the web .You can monitor all the data from your smart phone by using mobile app. Then a twit can be send to your account automatically if the moisture falls below a given threshold value. Care for the environment has become very important in recent years and there is an increasing demand for "green" applications that can help reduce CO2 emissions or make a more efficient management of energy consumed."</em> <a href="https://www.hackster.io/vssureshvs1995/iot-based-garden-automation-and-monitoring-system-078229">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyAWoodenLaserGunAsAXmasPrese.jpg" alt="DIY a Wooden Laser Gun As a Xmas Present for Your Child" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-a-Wooden-Laser-Gun-As-a-Xmas-Present-for-Your-/">DIY a Wooden Laser Gun As a Xmas Present for Your Child</a></h2>

<p><em>"Inspired by OVERWATCH, we have made a very cool Wooden Laser Gun toy for fun these day!The Wooden Laser Gun and the Gun Target are all based on an Arduino board called Seeeduino Lotus. The laser emitter on the Laser Gun is controlled to fire laser pulse to "activate" the Gun Target. And there are 3 light sensors on the Gun Target to detect the laser pulse. It seems very simple right? If you are interested in our project, please make one for yourself or your child! It's worth to spend one day DIY it as a Xmas present."</em> <a href="http://www.instructables.com/id/DIY-a-Wooden-Laser-Gun-As-a-Xmas-Present-for-Your-/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_MotionTrackingAirsoftTurret.jpg" alt="Motion Tracking Airsoft Turret" class="lefter"></p>

<h2><a href="https://hackaday.io/project/18665-motion-tracking-airsoft-turret">Motion Tracking Airsoft Turret</a></h2>

<p><em>"An Raspberry Pi powered autonomous motion tracking airsoft turret. In this video we show you how to build a DIY motion tracking airsoft (or nerf gun) turret with a raspberry pi 3. The airsoft turret is autonomous so it moves and fires the gun when it detects motion. There is also an interactive mode so that you can control it manually from your keyboard. We used an airsoft gun for this project, but you can easily change modify this build to use a Nerf instead. This project is small, lightweight and entirely battery operated. We created two separate operation modes: Interactive and Motion Detection. Interactive allows you to control the turret remotely and stream live video. Motion Detection uses openCV and computer vision to track moving targets in front of the camera. Since this device fires projectiles, please use the necessary safety precautions while operating the turret. :)"</em> <a href="https://hackaday.io/project/18665-motion-tracking-airsoft-turret">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_GhettoCpuBusyMeter.jpg" alt="Ghetto CPU busy-meter" class="lefter"></p>

<h2><a href="http://shadetail.com/blog/ghetto-cpu-busy-meter/">Ghetto CPU busy-meter</a></h2>

<p><em>"Many, or even most, embedded programmers have no idea how ‘busy’ their CPU is. By ‘busy’, I mean what proportion of the available CPU cycles are being spent on doing useful work in the name of the target application, and how much time its idle waiting for something to do. On your desktop PC you’ve got some sort of CPU busy meter available through the Task Manager, Activity Monitor or System Monitor depending on which OS religion you follow. Wouldn’t it be useful to have something similar on that embedded device you’re working on? Far too many people think you need an OS for that kind of info, but it turns out it’s trivially easy to do…and it should be table stakes for getting started on a new design. In most embedded design patterns, you’ve got some sort of loop where the application sits, waiting for something to happen. That might be a timer expiring, an interrupt arriving or some other event. The general pattern looks something like this;"</em> <a href="http://shadetail.com/blog/ghetto-cpu-busy-meter/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_ArduinoWebBasedTwoPlayerGame.jpg" alt="Arduino - Web-Based Two-Player Game" class="lefter"></p>

<h2><a href="https://www.hackster.io/khanhhs/arduino-web-based-two-player-game-584daa">Arduino - Web-Based Two-Player Game</a></h2>

<p><em>"Have fun with a colleague during break time with this web-based  game. There are two people playing game. each people uses two buttons to control direction of goalkeepers. Therefore, we need four buttons. Arduino reads the states of four buttons, If any of them is changed, Arduino will re-calculated the moving direction of goalkeeper and send the direction values to PHPoC WiFi Shield. When receiving the values, PHPoC WiFi Shield send it to Web Browser via websocket. JavaScript function will update the moving direction of goalkeepers. JavaScript program will continuously update position of ball, goalkeepers and obstacles based on their direction and check collision as well. Direction of goalkeepers are changed based on the state of buttons. "</em> <a href="https://www.hackster.io/khanhhs/arduino-web-based-two-player-game-584daa">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_FingerscanMusicAtYourfingertip.jpg" alt="Fingerscan: Music at YourFingertips" class="lefter"></p>

<h2><a href="https://www.hackster.io/touchmysound/fingerscan-music-at-your-fingertips-c224c4">Fingerscan: Music at YourFingertips</a></h2>

<p><em>"A tactile music wearable, made of ten vibration motors attached to your fingernails. This project is a tactile music wearable: 10 vibration motors (the same found in cellphones) are to be attached to fingernails. This device can be used to produce patterns for meditation/body consciousness, tactile music, 1-to-1 performances, music for deaf people, tactile communication systems, augmentation of perception (e.g. feeling the same sensation under a performing pianist’s skin), possible medical applications. Realized as the last work in the frame of the research project touchmysound, in 2016, this prototype of a wearable tries to translate the musical elements to a tactile level. While sound is totally absent here, the focus is on the spatialization of the tactile sensation."</em> <a href="https://www.hackster.io/touchmysound/fingerscan-music-at-your-fingertips-c224c4">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_ShowerRegulator.jpg" alt="Shower Regulator" class="lefter"></p>

<h2><a href="https://www.hackster.io/ChanR19/shower-regulator-497722">Shower Regulator</a></h2>

<p><em>"Learn how to make a device to limit your shower time! It may not seem like it, but the shower is easily one of the most wasteful appliances in a home and expends great amounts of water and energy. According to Home Water Works, the average flow rate of a shower is 2.1 Gallons (7.94L) per minute; this with an average shower time of 8.2 minutes results in 17.2 gallons (65.1L) used per shower or 51.6 gallons (195.3L) used in an average American household (3 people) per day. This makes it the third largest water user in a home. The numbers are even more surprising if you look at the energy use. According to Skidmore College, the average shower uses 440 BTUs (0.13 kWh) to heat one gallon (3.78L) of water. This means that about 2.2 kWh are used in a single typical 8.2 minute shower and 6.6 kWh used per household per day! According to the US Department of Energy, this makes up 17% of total home electricity usage. With the US EPA's estimate of 0.000703 metric tons (1.55 pounds; 0.7 kg) of CO2 per kWh, this results in 3.4 pounds (1.54kg) of CO2 per shower and 10.2 pounds per household. However, the recommended shower time is only 5 minutes according to Green Lifestyle Changes - this cuts water use by 6.7 gallons (25.4L), power use by 871Wh (That's enough to power 174 CFL bulbs for an hour!), and CO2 emission by 1.35 pounds (0.6 kg) per shower. This is where the Shower Regulator for the Intel Earth Day Challenge comes in which would limit the shower time to 5 minutes or to whatever time the user chooses. In one 365 day year, this would save 2,455.5 gallons (9,295.1L) of water (enough for a person to drink for about 13 years) and 317.9kWh or 492.7 pounds (223.5kg) of CO2 per person, resulting in 7,366.5 gallons (27,885.2L) of water, 953.7kWh of power, and 1,478.2 pounds (670.5kg) of CO2 saved per household."</em> <a href="https://www.hackster.io/ChanR19/shower-regulator-497722">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyArduinoBasedRcTransmitterAn.jpg" alt="DIY: Arduino Based RC Transmitter and Receiver" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-Arduino-Based-RC-Transmitter-and-Receiver/">DIY: Arduino Based RC Transmitter and Receiver</a></h2>

<p><em>"In this tutorial making of an Arduino based Tx and RX is explained which can be used to fly an RC plane. This transmitter has 4 channels but by applying some modification it can be increased to 8 or even more. This transmitter has the range of around 50m. And it can be made fewer than 600 Rs."</em> <a href="http://www.instructables.com/id/DIY-Arduino-Based-RC-Transmitter-and-Receiver/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DigitalTouchSensorUsingLm358.jpg" alt="Digital Touch Sensor Using LM358" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Digital-Touch-Sensor-Using-LM358/">Digital Touch Sensor Using LM358</a></h2>

<p><em>"Sensors are the best thing to work around with DIY electronics and this is the second instructable of a series of instructables which creates different sensors compatible with various microcontrollers. In the previous instructable I showed you how to build a digital tilt sensor. In this this instructable I'm going to show you how to build a Touch Sensor. This has various applications such as Touch Controlled switches, doorbells, etc.This instructable will require soldering skills it is easy to learn to solder and there are various YouTube videos that show you how to do that."</em> <a href="http://www.instructables.com/id/Digital-Touch-Sensor-Using-LM358/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyDaqMakeAnArduinoDataAcquisi.jpg" alt="DIY DAQ: Make an Arduino Data Acquisition System" class="lefter"></p>

<h2><a href="https://diyhacking.com/diy-daq-make-an-arduino-data-acquisition-system/">DIY DAQ: Make an Arduino Data Acquisition System</a></h2>

<p><em>"This project was made as part of my senior project at my university. The idea behind the device was to make a data logger that can be carried around a lab without the need to connect to a computer. In this segment, we will cover the components used for this project. Later, we’ll get into calibrating the sensors, setting up software programs, and running some experiments. "</em> <a href="https://diyhacking.com/diy-daq-make-an-arduino-data-acquisition-system/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_Atmega328PFuseBitsAndAnExterna.jpg" alt="ATmega328P Fuse Bits and an External Crystal Oscillator" class="lefter"></p>

<h2><a href="https://www.allaboutcircuits.com/projects/atmega328p-fuse-bits-and-an-external-crystal-oscillator/">ATmega328P Fuse Bits and an External Crystal Oscillator</a></h2>

<p><em>"This project introduces ATmega328P fuse bits and shows how to set them to use an external 16 MHz crystal oscillator. Fuse bits, also known as fuses or configuration bits, are settings made in microcontrollers to control certain operations that are not normally changed during the execution of the program code. This article will explain what these operations are in the ATmega328P, and how to set them in general. The fuse bits for selecting the clock source will be dealt with in more depth, including the how and why of a 16 MHz external crystal oscillator."</em> <a href="https://www.allaboutcircuits.com/projects/atmega328p-fuse-bits-and-an-external-crystal-oscillator/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_Ps2ControlledOmnidirectionalRo.jpg" alt="PS2 Controlled Omnidirectional Robot" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/PS2-Controlled-Omnidirectional-Robot/">PS2 Controlled Omnidirectional Robot</a></h2>

<p><em>"This omnidirectional robot is made with VEX holonomic wheels and a wireless PS2 controller (and receiver) from Hydra! Enjoy!!!"</em> <a href="http://www.instructables.com/id/PS2-Controlled-Omnidirectional-Robot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_RgbLedLightWritingWand.jpg" alt="RGB LED Light Writing Wand" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/RGB-LED-Light-Writing-Wand/">RGB LED Light Writing Wand</a></h2>

<p><em>"Following on from my previous instructable, I have an interest in long exposure photography. The tools to do this tend to be on the pricey side, so I decided to make a couple of my own.NOTE: I wanted RGB and white, however the chip will not light up white (RGB at the same time). I believe it to be because of one of 2 reasons; 1. The chip does not accept 3 channels of current at once. or 2. The 9v provided is not enough forward voltage to power all 3 channels at once. The pictures in this instructable will show 4 buttons, however I shall disregard the white button and only refer to 3 (RGB). I could add another battery, such as 1.5v aaa/aa in series with the white button to boost the voltage only when the white button is pressed. However as I did not test until the end of the soldering process, I had already cut my PVC pipe too short to allow additions. This wand is designed to give the user easy control of colour whilst in use, without having multiple tools or heads to change. A total of six colours can be achieved using single or a combination of two buttons."</em> <a href="http://www.instructables.com/id/RGB-LED-Light-Writing-Wand/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_VoiceControlledRobotUsing8051M.jpg" alt="Voice Controlled Robot Using 8051 Microcontroller" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Voice-Controlled-Robot-Using-8051-Microcontroller/">Voice Controlled Robot Using 8051 Microcontroller</a></h2>

<p><em>"A voice controlled robot takes specified command in the form of voice. Whatever the command is given through voice module or Bluetooth module, it is decoded by the existing controller and hence the given command is executed. Here in this project, I have used Bluetooth module and Android application to give voice command in the form of hex code. There are certain digits which can be sent directly to the Bluetooth module and automatically the digit is converted into its hex code.We can use these digits as a voice command for the specified operation pre-programmed in the microcontroller.Using digits as a voice command is easier than using alphabetical commands."</em> <a href="http://www.instructables.com/id/Voice-Controlled-Robot-Using-8051-Microcontroller/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_ArduinoPoweredWearableTail.jpg" alt="Arduino Powered Wearable Tail" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Powered-Wearable-Tail/">Arduino Powered Wearable Tail</a></h2>

<p><em>"One day I saw my daughter running around with a jump rope around her hip pretending that she is a pony and that she has a tail. Soon after that I got an idea to make a controlable tail that swings on command."</em> <a href="http://www.instructables.com/id/Arduino-Powered-Wearable-Tail/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DigitalVibrationSensorUsingLm3.jpg" alt="Digital Vibration Sensor Using LM358" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Digital-Vibration-Sensor-LM358/">Digital Vibration Sensor Using LM358</a></h2>

<p><em>"Working with sensors makes electronics better and easy to work with, there are thousands of sensors to choose from and designing sensors would make for cool DIY projects.This instructable will be a part of a series of instructables in which I show you how to build sensors compatible with most microcontroller you can find. In the last two instructables I showed you how to how to make a tilt sensor and how to make a Touch sensor. In this instructable I will show you how to build a vibration sensor, which could be used as a part of a security system."</em> <a href="http://www.instructables.com/id/Digital-Vibration-Sensor-LM358/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_RaspberryPiGoogleAssistantWith.jpg" alt="Raspberry Pi Google Assistant With Sleek Wood Box" class="lefter"></p>

<h2><a href="https://www.hackster.io/andrew-jones/raspberry-pi-google-assistant-with-sleek-wood-box-a50dcb">Raspberry Pi Google Assistant With Sleek Wood Box</a></h2>

<p><em>"I built a DIY Google AI Assistant using a Raspberry Pi, USB Speaker and USB microphone. I’ll show how to build a DIY Google AI Assistant using a Raspberry Pi, USB Speaker and USB microphone. I’ll also show how to make the sleek hardwood box it’s housed in. I’m assuming a basic knowledge of the linux operation system, raspberry pi and unix command line. If your new to raspberry pi there are plenty of good getting started tutorials here https://www.raspberrypi.org/help/ If your not interested in woodworking. You can easily substitute the wooden box for something simpler, like a cardboard box or a plastic project box."</em> <a href="https://www.hackster.io/andrew-jones/raspberry-pi-google-assistant-with-sleek-wood-box-a50dcb">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_RaspberryPiEmbeddedCapWithGps1.jpg" alt="Raspberry Pi Embedded Cap With GPS & 10DOF" class="lefter"></p>

<h2><a href="http://ozzmaker.com/raspberry-pi-embedded-cap-gps-10dof/">Raspberry Pi Embedded Cap With GPS &amp; 10DOF</a></h2>

<p><em>"In this post we will show you how to geotag and capture the “attitude”  of photos taken with the Raspberry Pi camera and record these values within the photo itself using EXIF metadata. We used a modified (hacked?) cap to take the images in this post. The cap took photos, geo-tagged and recorded attitude as we walked around Sydney Harbour."</em> <a href="http://ozzmaker.com/raspberry-pi-embedded-cap-gps-10dof/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_IrHomeAutomationOnArduino.jpg" alt="IR Home Automation on Arduino" class="lefter"></p>

<h2><a href="https://www.hackster.io/techduino/ir-home-automation-on-arduino-54a685">IR Home Automation on Arduino</a></h2>

<p><em>"Control all the appliances (up to 8) using just a single IR Remote. Everyone wants a remote to control all the appliances in your home. Some companies are introducing wireless controllers for various appliances but they are costly and you have to upgrade the existing for additional cost. So, what about making your own home automation system to control the appliances up to 8."</em> <a href="https://www.hackster.io/techduino/ir-home-automation-on-arduino-54a685">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_HowToMakeAUartToCassetteTapeIn.jpg" alt="How to Make a UART to Cassette Tape Interface" class="lefter"></p>

<h2><a href="https://diyhacking.com/make-uart-cassette-tape-interface/">How to Make a UART to Cassette Tape Interface</a></h2>

<p><em>"Before hard disks and floppy drives were widely used by the public, cassette tapes played a vital role in the world of information storage. In this project, we will learn how to build a simple UART to tape interface so you can save/load data from a simple cassette tape. To save data onto tapes, we have to turn our serial data (to/from UART) into audio signals that a tape cassette drive can record. Considering that the frequency range of a tape is abysmal at best, we will have to use low-frequency audio tones. Since the circuit has been designed with simplicity in mind we will use a one tone system where the presence of a tone represents a 1 bit and no tone represents a 0 bit. Other tape systems use frequency key shifting where changes in frequency represent data but that contains more complex circuitry (such as bandpass filters etc). The first step for us is to record data and this is done with a single 555 astable circuit (IC1) and a unity gain buffer (U1A). When the UART input is high, the 555’s reset pin is also high and this results in the 555 producing a square wave that is approximately 4kHz. When the input is low the 555’s reset is also low and this prevents the 555 from oscillating and thus produces no tone. This tone is then buffered via U1A for improving output impedance and this is then fed into a bypass capacitor to produce a tone that oscillates about 0V instead of having a positive offset. This bypassed signal is then directly connected to the input of a cassette recorder and thus when serial data is sent to this circuit, it will result in data encoded tones being recorded to a tape. The second step is to read data that we have saved onto tapes. This is achieved with two circuits; a Schmitt trigger, and a 555 monostable circuit. The Schmitt trigger is used to produce an output if there is a large signal detected from the tape (i.e. the sound of the tone that we recorded), and no output if there is no tone detected (i.e. the 0 from our data). The only problem with this is that when there is a tone, the Schmitt trigger will turn on and off at the same rate as the incoming tone (i.e. 4kHz). Therefore, we have to use a circuit that will remain on when a fast tone is detected. This is where the monostable comes in (IC3). But this is not your ordinary monostable, this monostable is a re-triggerable one! The monostable has been designed to stay on for 300us when triggered but if the 555 is re-triggered during the on state, it will not restart the monostable. This is what the function of Q1 is; to discharge the capacitor C8 which is directly responsible for the monostable on time. Therefore, a repeated signal to the 555 monostable circuit (i.e. the tone) will result in a monostable that stays on until there are no further triggers. The result is an output that matches the original UART signal that was fed in. The circuit works best when using a baud rate of 300 for the UART and is incredibly reliable. RV1 is a potentiometer that adjusts the strength of the output signal while RV2 will adjust the triggering levels of the Schmitt trigger. RV2 is the pot to consider if you are struggling to read data back, but if correctly configured, this circuit is surprisingly accurate with almost no lost bits. The baud rate could be increased but this would require a higher frequency tone and a faster monostable. The monostable time has been chosen to be slightly longer than the period of the tone to ensure that the monostable stays on between repeated triggers."</em> <a href="https://diyhacking.com/make-uart-cassette-tape-interface/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_SimpleEasyDimmerCircuitUsing55.jpg" alt="Simple & Easy Dimmer Circuit Using 555 IC for LED Strip Lights" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Simple-Easy-Dimmer-Circuit-Using-555-IC-for-LED-St/">Simple &amp; Easy Dimmer Circuit Using 555 IC for LED Strip Lights</a></h2>

<p><em>"In this tutorial i will show you how to build a dimmer for the LED Strip Lights using 555 IC.To build your own Dimmer Circuit using 555 IC you can watch the video embedded in this step or continue reading"</em> <a href="http://www.instructables.com/id/Simple-Easy-Dimmer-Circuit-Using-555-IC-for-LED-St/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_FiddyTheFtdiClip.jpg" alt="Fiddy - the FTDI Clip" class="lefter"></p>

<h2><a href="https://learn.adafruit.com/fiddy-ftdi-pogo-pin-clip">Fiddy - the FTDI Clip</a></h2>

<p><em>"FTDI is Great! But header pins can get in the way of your next tiny project. For the benefits of FTDI, without the bulk of header pins, Fiddy comes to the rescue. Using a spring, pogo pins, and a extreme optimism, Fiddy chomps down on the headers on your Pro Trinket, delivers and receives the debugging and programming information you need, and then speeds off to a glorious life once finished."</em> <a href="https://learn.adafruit.com/fiddy-ftdi-pogo-pin-clip">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_ArduinoOledTemperatureDisplayW.jpg" alt="Arduino OLED Temperature Display with Real Time Clock" class="lefter"></p>

<h2><a href="https://diyhacking.com/arduino-oled-temperature-display-real-time-clock/">Arduino OLED Temperature Display with Real Time Clock</a></h2>

<p><em>"In this article, we are going to make Arduino weather clock which will tell us the time, date, and temperature. The LM35 sensor will give us the temperature, the DS3231 will tell us the date and the time, and we will use the OLED to display the temperature, date, and time."</em> <a href="https://diyhacking.com/arduino-oled-temperature-display-real-time-clock/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_Computerception.jpg" alt="Computerception" class="lefter"></p>

<h2><a href="https://www.hackster.io/314reactor/computerception-f54418">Computerception</a></h2>

<p><em>"Why not put a Raspberry Pi into a 2007 netbook? Its always interesting to look back on hardware from the prior decade, late 2007 delivered us the Netbook; the promising but short lived micro-laptop that existed in the void prior to Apple’s iPad. Ten years before that we had The Tamagotchi and The Nintendo64. Also Half Life was just a twinkle in Gabe Newell’s eyes. The other day I recalled This awesome project and wondered if I could combine it with This also awesome project and have a tiny 2015 device (I’ll be using the original Pi-Zero not the new Zero W) inside a relatively tiny 2007 device. I thought it would be cool to put something like Lubuntu on the Netbook itself and be able to remote into the Pi inside to access the probably-faster but much-tinier hardware it provides."</em> <a href="https://www.hackster.io/314reactor/computerception-f54418">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_SmartAndSafeOutdoorPlantWateri.jpg" alt="Smart and Safe Outdoor Plant Watering System" class="lefter"></p>

<h2><a href="https://www.hackster.io/chipmc/smart-and-safe-outdoor-plant-watering-system-17d5c8">Smart and Safe Outdoor Plant Watering System</a></h2>

<p><em>"Monitors soil moisture and weather forecasts to give plants just the water they need. Safe garden hose hookup for season long watering. OK, so let me just say that I approached this project with a little trepidation - water, code and electricity don't mix well in my mind. I imagined creating a project that, if it failed, could waste hundreds of gallons of water and I might not be on-hand to stop it. That said, I have spent some time tending to the plants on my back deck and I did not want them to wilt and die when I was away. I know there are many plant watering projects on Hackster.io and the web. However, the ones I looked at did not meet my needs or address my concerns, so, I decided to make my own. I also saw this as a chance to improve my skills on the Particle Platform."</em> <a href="https://www.hackster.io/chipmc/smart-and-safe-outdoor-plant-watering-system-17d5c8">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyPwmDriver.jpg" alt="DIY PWM Driver" class="lefter"></p>

<h2><a href="https://www.hackster.io/pratik-makwana/diy-pwm-driver-ce07e6">DIY PWM Driver</a></h2>

<p><em>"In this project, I will show you how to make PWM Controller. In this Project, I will show you how to make PWM Controller. I'm using the laminator for the toner transfer method."</em> <a href="https://www.hackster.io/pratik-makwana/diy-pwm-driver-ce07e6">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyMetronome.jpg" alt="DIY Metronome" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-Metronome/">DIY Metronome</a></h2>

<p><em>"A metronome is a device that produces an audible beat—a click or other sound—at regular intervals that the user can set in beats per minute (BPM). It is typically used by musicians when practicing on a musical instrument in order to play at a regular pulse. Most metronomes have both an audible click sound synchronized with an inverted pendulum swing. This uses the Arduino's built in timer to calculate when the next beat is to be played, and adjusts the servo motor to swing the inverted pendulum, as well as give the buzzer the signal to make a 'click' sound."</em> <a href="http://www.instructables.com/id/DIY-Metronome/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_UwareADiyArHeadset.jpg" alt="Uware: a DIY AR Headset" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Uwear-a-DIY-AR-Headset/">Uware: a DIY AR Headset</a></h2>

<p><em>"Whats up everyone!Does anybody remember Google Glasses? No? It's okay, Google probably doesn't remember them either. Maybe because it was over priced or that they marketed to everyone or maybe just because you had to say, "take a picture" just to take a picture. But it still was a pretty cool idea. This instructable will guide you through the steps I used to make an AR Headset, that will display the date, time, and text messages from your phone. It will also allow you to take pictures from the headset itself all controlled with a gesture sensor (yup, its gesture controlled, no touching required).I got the idea when I went mountain biking with my brother. On that same day, we were supposed to meet up with our dad for lunch, so I had to continually check the time. It was really annoying to have to keep stopping to check my phone (any mountain bikers out there). So, I came up with the idea to make a headset that would display the time so I wouldn't have to rely on my phone as much. Overall, this AR Headset will allow you to check your phone less and be more focused on the task at hand. It is all controlled by an Arduino pro mini. This combined with an HC-06, a tiny OLED screen and a Gesture sensor and you get a sweet, relatively cheap AR head seat. It also has magnetic charging!! (see video above and step 7 for more details). The four main steps are, creating an enclosure, coding some code, assembling the electronics and combining them all."</em> <a href="http://www.instructables.com/id/Uwear-a-DIY-AR-Headset/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_ReplacingADeadLithiumCellInThe.jpg" alt="Replacing a dead lithium cell in the DS1387" class="lefter"></p>

<h2><a href="http://www.glitchwrks.com/2017/07/27/ds1387-rebuild">Replacing a dead lithium cell in the DS1387</a></h2>

<p><em>"While most PCs use a RTC/CMOS chip that has an external battery, many industrial x86 computers use RTC/NVRAM modules. They’re convenient when new, since the battery and RTC crystal are encapsulated into the module. The module’s potting keeps the lithium cell from drying out as quickly in high temperatures, extending its life. Since the cell is potted, in the unlikely event of a cell rupture or leak, the system won’t be destroyed by battery electrolyte. The downside is, the battery eventually dies, and often the NVRAM is used for storing some critical parameter that keeps you from booting. This was the case with the Multitech industrial 486 single-board computer on my bench today: it uses a Dallas DS1387 RTC/NVRAM module, which is similar to the DS1287 but with more NVRAM (4K vs. 114 bytes). Unfortunately, the DS1387 has no currently available replacement. The chip used in the module was produced as a bare IC, requiring external battery and crystal, but that part is also no longer available."</em> <a href="http://www.glitchwrks.com/2017/07/27/ds1387-rebuild">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_SkateboardingVisualizations.jpg" alt="Skateboarding Visualizations" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Skateboarding-Visualizations/">Skateboarding Visualizations</a></h2>

<p><em>"The hidden science and art underlying skateboard tricks is a source of fascination. This device 3 dimensionally tracks the skateboard position during the execution of tricks. The data and trails of the tricks are then used to create sculptures and immortalize the motion of the skateboard and the style of the individual skateboarder. Amongst the possible applications for this project, my work focused on creating artistic visualizations from skateboard tricks. There were two main technical challenges with this project: Achieve spatial position tracking with small electronics and without cameras and computer vision. Create a sturdy and compact case for the electronics"</em> <a href="http://www.instructables.com/id/Skateboarding-Visualizations/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_CallingAllSpeakersAHardwareBut.jpg" alt="Calling all speakers! A hardware button to toggle display mirroring" class="lefter"></p>

<h2><a href="http://seb.ly/2017/07/calling-all-speakers-a-hardware-button-to-toggle-display-mirroring/">Calling all speakers! A hardware button to toggle display mirroring</a></h2>

<p><em>"I’ve been really frustrated that my favourite keyboard shortcut to toggle display mirroring doesn’t work on TouchBar MacBooksso I’ve made a button that can emulate it! Of course since I’ve got this working I’ve discovered there’s a weird work-around to get it working on the TouchBar, but it’s still quite a fun device, and you could use it to emulate any key (missing that Escape key, anyone?)"</em> <a href="http://seb.ly/2017/07/calling-all-speakers-a-hardware-button-to-toggle-display-mirroring/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_MeasureYourWifiSignalStrengthU.jpg" alt="Measure Your WiFi Signal Strength Using Particle Photon " class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Measure-Your-WiFi-Signal-Strength-Using-Particle-P/">Measure Your WiFi Signal Strength Using Particle Photon </a></h2>

<p><em>"WiFi has become an integral part of our life and daily billions of people use WiFi as a method to access the internet. But the range of WiFi is limited, unlike a cellular connection. A normal WiFi router usually has a range of about a 100m in clear sight and about 20m to 50m without clear sight (With walls or any other electronic appliance). It would great to know the WiFi coverage of your Wireless router so you can place your router in a place at which you would usually get maximum range. The Ideal way to do it is to use a WiFi meter those devices are expensive and not easy to find. So in this instructable I'm going to show you How to build a WiFi Signal Strength meter using the Particle Photon. If you don't know what the particle photon is or if you are getting started with the particle photon I would recommend you to check out my previous instructables and also the documentation at the particles website."</em> <a href="http://www.instructables.com/id/Measure-Your-WiFi-Signal-Strength-Using-Particle-P/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_ArduinoWordClock.jpg" alt="Arduino Word Clock" class="lefter"></p>

<h2><a href="https://www.hackster.io/daniele-bonaldo/arduino-word-clock-b0566b">Arduino Word Clock</a></h2>

<p><em>"A clock that let you read the time, for real! What about a clock that speaks the user own language? Here it is! The core concept of this clock is that during the day, only the letters needed to create the current time in words will be on, while the others will be off. The first thing to do is to create a layout with all the letters and have it laser-cut of the right size to fit inside the picture frame and with every letter at the same distance between each others as the LEDs in the WS2812B strip are."</em> <a href="https://www.hackster.io/daniele-bonaldo/arduino-word-clock-b0566b">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_UniversalCameraTiltRotateMount.jpg" alt="Universal Camera Tilt/Rotate mount" class="lefter"></p>

<h2><a href="https://www.hackster.io/turtle-rover/universal-camera-tilt-rotate-mount-4e751c">Universal Camera Tilt/Rotate mount</a></h2>

<p><em>"This project showcases how to make your waterproof servo actuated pan/tilt camera holder. This project showcases how to make your DIY waterproof servo actuated pan/tilt camera holder. We designed this project for those looking to test outdoor camera’s capabilities mounted on mobile platforms (like for ex. Turtle Rover). Project is simple and low-cost thanks to 3d-printed parts and usage of hobby servos. Rotation of camera holder is provided by standard sized D3015 waterproof servo. Force created by the weight of camera and second servo is working along the axis of rotation so additional bearing is not required – metal servo horn with threads will make it. Tilt of camera is actuated by the same D3015 waterproof servo but to make image more stable we decided to use small ball bearing (606ZZ) on the other side of servo. Place for camera is universal so it is possible to mount any camera – but feel free to make some custom mount for your camera. Wide-angle servos gives us ~300 degrees of rotation and ~45 degrees of tilt which is more than enough according to wide-angle of view in outdoor cameras."</em> <a href="https://www.hackster.io/turtle-rover/universal-camera-tilt-rotate-mount-4e751c">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_VoltageControlledAtariPunkCons.jpg" alt="Voltage Controlled Atari Punk Console (mini PCB)" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Voltage-Controlled-Atari-Punk-Console-mini-PCB/">Voltage Controlled Atari Punk Console (mini PCB)</a></h2>

<p><em>"This gadget was designed as part of etching and PCB design workshop at PIFcamp 2017 by Staš Vrenko and Vadim Vooku Petrov. During the workshop participants learned to design a circuit in KiCAD and later etched and built the board. In this instructable the etching process will be skipped (there are plenty on Instructables, check this one). The circuit is based on the schematic of a classic APC, with two additional CV inputs, that you can connect to different CV sources (0 - 9 V) for example: Baby10 sequencer, 40106 oscillators, 4040 frequency dividers… We also tested the device with some “proper” synths, like Moog Werkstatt, and gained extended control over the sound."</em> <a href="http://www.instructables.com/id/Voltage-Controlled-Atari-Punk-Console-mini-PCB/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyBatteryLevelChecker.jpg" alt="DIY Battery Level Checker" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-Battery-Level-Checker/">DIY Battery Level Checker</a></h2>

<p><em>"Batteries are harmful to the environment, which is why there are special battery recycling facilities. However, we must not forget, reducing and reusing comes before recycling. Many batteries get thrown into the bad batteries pile even though thy still have a lot of juice left in them. For those without a multimeter and have no other way of checking a battery, if a battery-powered device is not being powered or turned on , the batteries are usually the first to blame and the first to be thrown out. This is a simple battery checker that will have an LED light up indicator to tell the user how much juice a battery still has to minimize our waste and pollutants. This allows us to reuse our batteries and consequently reducing our waste, every little help counts in helping save this planet."</em> <a href="http://www.instructables.com/id/DIY-Battery-Level-Checker/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_Diy18650BatteryHolder.jpg" alt="DIY 18650 Battery Holder" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-18650-Battery-Holder/">DIY 18650 Battery Holder</a></h2>

<p><em>"Today, 18650 Li-ion cells are widely used in every day to day gadgets like mobile powerbanks, laptop batteries and much more. These cells are very useful and available in various different ampere ratings. However, to use these batteries in DIY projects, we need specific holders to connect the battery as power source. The commercial Li-ion battery holders are quite expensive, so i decided to make 18650 Li-ion battery holder myself at home. In this instructable, we will learn how to make a 18650 battery holder at home and this technique can be used in making holders for any number of cells &amp; in any series / parallel configuration."</em> <a href="http://www.instructables.com/id/DIY-18650-Battery-Holder/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_RgbElectronicDie.jpg" alt="RGB Electronic Die" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/RGB-Electronic-Die/">RGB Electronic Die</a></h2>

<p><em>"This project is an RGB Electronic Die that generates the codes from 1 to 6 through 7 RGB LEDs as outputs for showing the mentioned numbers while the inputs are the codes generated by a 7490 counter fixed to count from 000-101. For carring out the RGB Electronic Die, it's necessary to design a decoder interface between counter and display by being this last one: a configuration of 7 RGB LEDs referenced previously. Also, we'll need to use a rotary switch of 4 poles y 3 positions for selecting the three possible colors: Red, Green or Blue."</em> <a href="http://www.instructables.com/id/RGB-Electronic-Die/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_HowToMakeAPlayableArduinoBased.jpg" alt="How to Make a Playable Arduino-based Drum Set With Beverage Can" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/How-to-Make-a-Playable-Arduino-based-Drum-Set-With/">How to Make a Playable Arduino-based Drum Set With Beverage Can</a></h2>

<p><em>"The drum set is a part of the standard rhythm section used in many music styles. The most usual type includes a bass drum, a floor tom, two tom-tom drums, also one or two ride cymbal, and a hi-hat. With some useless beverage cans at hand, let’s make mini drum set."</em> <a href="http://www.instructables.com/id/How-to-Make-a-Playable-Arduino-based-Drum-Set-With/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_RunAndJumpArduinoLcdGame.jpg" alt="Run and Jump Arduino LCD Game" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Run-and-Jump-Arduino-LCD-Game/">Run and Jump Arduino LCD Game</a></h2>

<p><em>"The Arduino is a really easy way to get started in electronics, it is simple to design a circuit around the arduino boards and easy to program using the arduino IDE. The arduino may not be as powerful as the raspberry pi or Intel Edison but it is cheap and easy to design projects. The arduino can be connected to different types of LCD displays and OLED displays, this gives the possibility of a large number of projects that display the sensor outputs on the LCD or OLED. But what's more is that these displays even support low resolution graphics which enable us to design low resolution pictures and even sprites and objects for games. In this instructable I'm going to show you How to build an arduino powered low resolution game with sprites and objects. The game is simple and involves running and jumping over objects or walls by clicking a button."</em> <a href="http://www.instructables.com/id/Run-and-Jump-Arduino-LCD-Game/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_InteractiveLaserSheetGenerator.jpg" alt="Interactive Laser Sheet Generator With Arduino" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Interactive-Laser-Sheet-Generator-With-Arduino/">Interactive Laser Sheet Generator With Arduino</a></h2>

<p><em>"Lasers can be used to create incredible visual effects. In this project, I constructed a new type of laser display that is interactive and plays music. The device rotates two lasers to form two vortex-like sheets of light. I included distance sensors in the device so that the laser sheets could be manipulated by moving your hand towards them. As the person interacts with the sensors, the device also plays music through a MIDI output. It incorporates ideas from laser harps, laser vortexes, and POV displays. The instrument is controlled with an Arduino Mega that takes in the inputs of ultrasonic sensors and outputs the type of laser sheet formed and music generated. Due to the many degrees of freedom of the spinning lasers, there are tons of different laser sheet patterns that can be created. I did preliminary brainstorming on the project with a new art/tech group in St. Louis called Dodo Flock. Emre Sarbek also ran some initial tests on the sensors used to detect motion near the device. If you construct a laser sheet device, please remember to be safe operating lasers and spinning discs."</em> <a href="http://www.instructables.com/id/Interactive-Laser-Sheet-Generator-With-Arduino/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_WallFollowingRobotObstacleAvoi.jpg" alt="Wall Following Robot / Obstacle Avoiding Robot" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Wall-Following-Robot-Obstacle-Avoiding-Robot/">Wall Following Robot / Obstacle Avoiding Robot</a></h2>

<p><em>"Fully autonomous and intelligent machines can minimize human liability and extend automation to fields like civil services and defense. AI researchers are attempting to automate services like firefighting, medical care, disaster management, and lifesaving duties through autonomous robotic vehicles. One challenge that these vehicles must overcome is how to successfully detect and avoid obstacles such as rubble, fire, pitfalls, etc. In this Instructable we will show how to create an autonomous wall following robot (vehicle) using a few external ultrasonic and infrared (IR) sensors and Silego GreenPAK."</em> <a href="http://www.instructables.com/id/Wall-Following-Robot-Obstacle-Avoiding-Robot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_DiyPcAmbientLightingUsingArdui.jpg" alt="DIY PC Ambient Lighting Using Arduino and WS2812b LEDs" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-PC-Ambient-Lighting-Using-Arduino-and-WS2812b-/">DIY PC Ambient Lighting Using Arduino and WS2812b LEDs</a></h2>

<p><em>"Wanted some more depth for my gaming/movie viewing experience so here's how I installed my ambient lighting. Before we begin, this project requires you to know how to use a soldering iron and some other basic tools. If you're not comfortable soldering, you can get somebody to do it for you... or learn how :) Note: I'm making this after I finished the project so the pictures shown will be from the finished product."</em> <a href="http://www.instructables.com/id/DIY-PC-Ambient-Lighting-Using-Arduino-and-WS2812b-/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_HowToMakeATemperatureGunWithEs.jpg" alt="How to Make a Temperature Gun With Esp32" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/How-to-Make-a-Temperature-Gun-With-Esp32/">How to Make a Temperature Gun With Esp32</a></h2>

<p><em>"What a hot day it is! Too hot to drive and ride and I am thinking of making a temperature measurement sensor. With FireBeetle ESP32 produced by DFRobot and MLX90614 (a noncontact IR temperature sensor) on hand, let’s do it!"</em> <a href="http://www.instructables.com/id/How-to-Make-a-Temperature-Gun-With-Esp32/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_FidgetSpinnersArduinosAndFlapp.jpg" alt="Fidget Spinners, Arduinos, and Flapping Birds" class="lefter"></p>

<h2><a href="http://robmsantos.com/arduino-fidget-spinner-custom-arcade-game-controller-robdevs/">Fidget Spinners, Arduinos, and Flapping Birds</a></h2>

<p><em>"This past weekend, I had the pleasure of joining local St. Louis game developers and many other guests from around the nation in showcasing our latest creations at the fourth annual PixelPop Games Festival. One of my personal festival traditions is hooking up an old CRT TV with my port of FlappyNES running on an actual 1985 Nintendo Entertainment System for young gamers (many of whom have never held an NES controller before), but this year, I had a more modern surprise for curious attendees"</em> <a href="http://robmsantos.com/arduino-fidget-spinner-custom-arcade-game-controller-robdevs/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_BuildAnAutonomousRCCarWithRasp.jpg" alt="Build an Autonomous R/C Car with Raspberry Pi" class="lefter"></p>

<h2><a href="http://makezine.com/projects/build-autonomous-rc-car-raspberry-pi/">Build an Autonomous R/C Car with Raspberry Pi</a></h2>

<p><em>"In May of 2016, the Self Racing Cars group held their inaugural autonomous track day for full-size cars at Thunderhill Raceway Park in Northern California. Will and I both attended, but wouldn’t actually meet until a few months later. We were intrigued by the event, but we knew that full-sized autonomous racing cars were not for hobbyists like ourselves. Then in November, Chris Anderson announced a hackathon for scaled-down cars (later named DIYRobocars), and we both showed up excitedly. The new mini series included a league for 1/10th scale R/C cars, which is a perfect scale for a low-cost car. I brought an R/C car, a Raspberry Pi, and some hastily 3D-printed and laser-cut parts. While I was assembling my vehicle, Will introduced himself to me and asked if he could help — thus beginning the partnership that has led to the creation of the Donkey Self Racing Car."</em> <a href="http://makezine.com/projects/build-autonomous-rc-car-raspberry-pi/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_SoundActivatedIotAlarmWithEsp8.jpg" alt="Sound-Activated IoT Alarm with ESP8266 and RIOTOUS" class="lefter"></p>

<h2><a href="https://diyhacking.com/sound-activated-iot-alarm-esp8266-riotous/">Sound-Activated IoT Alarm with ESP8266 and RIOTOUS</a></h2>

<p><em>"The IoT has created an industry that is rapidly growing and connecting even the simplest circuits to the internet allows for data gathering and home automation. In this DIY project, we will look at an IoT platform called RIOTOUS to make a simple sound-activated PIC18 alarm that can alert a RIOTOUS server when a threshold is detected."</em> <a href="https://diyhacking.com/sound-activated-iot-alarm-esp8266-riotous/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_The1SheeldVirtualPeopleCounter.jpg" alt="The 1sheeld Virtual People Counter" class="lefter"></p>

<h2><a href="https://www.open-electronics.org/the-1sheeld-virtual-people-counter/">The 1sheeld Virtual People Counter</a></h2>

<p><em>"A virtual shield and a smartphone, with the addition of ultrasound sensors that allow us to detect passage and direction of anyone crossing a passage. Most of Arduino’s success is also due to the fact that the base features of this board can be expanded by simply adding shields, which are boards containing hardware that is specific for each application. The possibility to add new hardware on the existing base board also provides almost countless development options and encouraged the most important manufacturers of components and electronic devices to propose an innovative and interesting solution. Do you want satellite localization? Add a shield with a GPS receiver! Do you want an application with a graphic display? All you have to do is add a shield with a GLCD (Graphic Liquid Crystal Display). Nowadays, for each function, there is a dedicated shield, which is commercially available in numerous options based on the manufacturer. In this scenario, the team of Integreight had an absolutely genius idea, thinking about the potential of interaction between an Arduino board and a recent smartphone. Actually, many functions carried out by the shield are already present in a smartphone, which is well equipped in terms of built-in sensors; besides, it has a sophisticated communication section ranging from Bluetooth to 3G. Finally, in integrates a high-res display. Well, Integreight team thought that every feature of a smartphone could be represented on a shield for Arduino; all they had to do was establish a communication with Arduino and they were set. That’s where the idea for 1Sheeld came from, that is a unique Arduino shield that allows taking advantage of all the features of a smartphone; the pun is intended and it indicates that it’s just one single shield for many functionalities."</em> <a href="https://www.open-electronics.org/the-1sheeld-virtual-people-counter/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM119_MakingAPickit3Clone.jpg" alt="Making a PICKIT 3 Clone" class="lefter"></p>

<h2><a href="https://reviahh.wordpress.com/2016/01/31/making-a-pickit-3-clone/">Making a PICKIT 3 Clone</a></h2>

<p><em>"After using the Microchip tools to program and debug the projects I work on, I wondered about creating my own programming/debugging module that I could put on my own boards – just like Microchip does with their starter kits and such. As I became more interested in that idea, I began to search the web to see if anyone else had already done something similar. Initially, I found lots of posts regarding the 2nd version of the Pickit – the Pickit 2, but not as much regarding the latest version – the Pickit 3 – which is what I need to program the 32 bit pic processors that I am using. After a while I came across a post – From this blog. This Individual had created his own version of the Pickit 3 and had posted his method for doing so. I was excited to see some real information about the process, and set about determining how I would do the same, now that I knew someone else had verified that it would work. The version that was built on the blog linked above, was done so on a protoboard using a variety of components, and was completely hand-wired. As impressive as that is, I was looking for something a bit sleeker – especially since I was looking at some point to modularize it and use it on other designs. I decided that I would design my project to use surface mount components and a purpose designed PCB. With that in mind, I set out to create my schematic. After looking at the one from Hendrik’s blog post above, and also studying the actual Microchip pickit 3 schematics that are publicly available in the documents released by Microchip, I came up with the following schematic. It is pictured below, and here is a link to the full-sized PDF: My Schematic"</em> <a href="https://reviahh.wordpress.com/2016/01/31/making-a-pickit-3-clone/">[...]</a>
 </SPAN></DIV></p>

<hr />

<p>That's all Folks!</p>

<script data-cfasync="false" src="../../../../../../cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>SHB.build({elementID: 'shb', pref: { btnSizeClass: 'btn-md', btnClass: 'btn my-btn'}, buttons: { fbLike: true, fbShare:true, tweet: true, plusOne: true, plusShare: true,linkedInShare:true}});</script>

					</div>
				</section>
				</div> <!-- Container -->

				<footer id="footer" class="panel-footer">
					<div class="inner">
						<a href="https://github.com/PhileCMS/Phile">Phile</a> was made by <a href="https://github.com/PhileCMS">The PhileCMS Community</a>.
					</div>
				</footer>
			</div>
		</div>
</div>
		<script type="text/javascript">
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-20725619-1']);
            _gaq.push(['_trackPageview']);
            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
        </script>
		<!-- Matomo -->
<script type="text/javascript">
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//matomo.altlab.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '2']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
	</body>
</html>
