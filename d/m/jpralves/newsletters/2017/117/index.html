<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

		<!-- <base href="https://altlab.org/d/" />  -->
		<title>Newsletter altLab - 2017-07-27 - Nº 117 | altLab Documenta</title>
				<meta name="description" content="Newsletter altLab Nº117 de 27 de julho de 2017">
				<meta property="og:type" content="article" />
		<meta property="og:title" content="Newsletter altLab - 2017-07-27 - Nº 117 | altLab Documenta" />
		<meta property="og:description" content="Newsletter altLab Nº117 de 27 de julho de 2017" />
		<meta property="og:url" content="https://altlab.org/d/m/jpralves/newsletters/2017/117/" />
		<meta property="og:site_name" content="altLab Documenta" />

		<!-- Bootstrap -->
		<link href="../../../../../themes/altlab/css/bootstrap.min.css" rel="stylesheet">
		<link href="../../../../../themes/altlab/override-test.css" rel="stylesheet">
		<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
		<script src="../../../../../themes/altlab/js/jquery-1.12.4.min.js"></script>
		<!-- Include all compiled plugins (below), or include individual files as needed -->
		<script src="../../../../../themes/altlab/js/bootstrap.min.js"></script>

	</head>
	<body>
<div class="container">
<div class="container-fluid">
      <div class="page-header hidden-xs" id="brand-logo">
        <h1><a href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-gradoverwhite.png" width="180" height="120" alt="Home" style="vertical-align:text-bottom" /></a> Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></h1>

      </div>
			<nav class="navbar navbar-inverse">

				<div class="container-fluid">
					<div class="navbar-header">
						<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#myNavbar">
							<span class="sr-only">Toggle navigation</span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
<div class="visible-xs">
<a class="navbar-brand" href="../../../../../../index.html"><img src="../../../../../themes/altlab/altlab-logo-documenta.png" width="58" height="35" alt="Home" style="margin-top: -7px;"></a>
						<a class="navbar-brand" href="../../../../../index.html">Documenta <span class="glyphicon glyphicon-leaf" style="color:#98ff98; padding-left:5px; top:2.8px;"></span></a></div>
					</div>
					<div class="collapse navbar-collapse" id="myNavbar">
						<ul class="nav navbar-nav">

           	<li id="dropdown.1" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Membros <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../index.html">Index</a>
</li>
   
           	<li id="dropdown.101" class="dropdown">
		<a href="../../../index.html">João Alves <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.102" class="dropdown">
		<a href="../../../../sislog/index.html">Fernando Carvalho <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.103" class="dropdown">
		<a href="../../../../pangelo/index.html">Pedro Ângelo <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.104" class="dropdown">
		<a href="../../../../dinix/index.html">Dinix <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../funke/funke.html">m/funke/funke</a>
  
   	</li>
            	<li id="dropdown.106" class="dropdown">
		<a href="../../../../afonsom/index.html">Afonso Muralha <span class="caret"></span></a>
  
      	</li>
            	<li id="dropdown.107" class="dropdown">
		<a href="../../../../x3msnake/index.html">X3msnake <span class="caret"></span></a>
  
      	</li>
            	<li>
		<a href="../../../../ampmendes/index.html">António Mendes</a>
  
   	</li>
            	<li>
		<a href="../../../../guardajoao/index.html">GuardaJoao</a>
  
   	</li>
            	<li>
		<a href="../../../../jac/index.html">JAC</a>
  
   	</li>
            	<li>
		<a href="../../../../nini/index.html">Nuno Nini</a>
  
   	</li>
 
</ul>
    	</li>
            	<li id="dropdown.2" class="dropdown">
		<a class= "dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Documentação Partilhada <span class="caret"></span></a>
  
    <ul class="dropdown-menu">
<li>
<a href="../../../../../s/index.html">Index</a>
</li>
   
                         	<li id="dropdown.203" class="dropdown">
		<a href="../../../../../s/workshops/index.html">Workshops <span class="caret"></span></a>
  
      	</li>
                   	<li>
		<a href="../../../../../s/documenta/index.html">Documenta DevMap</a>
  
   	</li>
                   	<li>
		<a href="../../../../../s/processos/index.html">Processos do Lab (draft)</a>
  
   	</li>
            	<li id="dropdown.208" class="dropdown">
		<a href="../../../../../s/recursos/index.html">Recursos <span class="caret"></span></a>
  
      	</li>
 
</ul>
    	</li>
 
						</ul>
					</div>
				</div>
			</nav>

			<div class="container">
				<div class="container">
				<section id="content">
					<div class="inner">
						<p><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
<link rel="stylesheet" href="../res/_shb.css"></p>

<script src="../res/_shb.min.js" type="text/javascript"></script>

<div style="text-align: center;">
<button class="btn my-btn btn-md disabled">Share:</button>
<div class="btn-group" id="shb"></div>
</div>

<p><br></p>

<h1 id="topo"><img src="../res/__Titulo.png" alt="Newsletter altLab" /></h1>

<p>2017-07-27 - Nº 117</p>

<div style="position: fixed; z-index: 65535; right: 10px; bottom: 10px;">
<a href='#topo' title='Go to Top'><img src="../res/_gotop.png" alt="go to top image" /></a>
</div>

<div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'pt', layout: google.translate.TranslateElement.FloatPosition.TOP_LEFT, multilanguagePage: true}, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<p><DIV class="articledetail"><SPAN class="articledetail"></p>

<p><a href="index.html"><img src="Newsletter117.jpg" alt="Newsletter117Cover" /></a></p>

<h2>Editorial</h2>

<p>Esta é a Newsletter Nº 117 que se apresenta com o mesmo formato que as anteriores. Se gostar da Newsletter partilhe-a!</p>

<p>Todas as Newsletters encontram-se indexadas no <a href="../../index.html">link</a>.</p>

<p>Esta Newsletter tem os seguintes tópicos:</p>

<ul>
<li><a href="#Novidades-da-Semana">Novidades da Semana</a></li>
<li><a href="#Ciencia-e-Tecnologia">Ciência e Tecnologia</a></li>
<li><a href="#Modelos-3D">Modelos 3D</a></li>
<li><a href="#Documentacao">Documentação</a></li>
<li><a href="#Projetos-Maker">Projetos Maker</a></li>
</ul>

<p>Faz hoje anos que nascia, em 1848, <a href="https://en.wikipedia.org/wiki/Lor%C3%A1nd_E%C3%B6tv%C3%B6s">Loránd Eötvös</a>. Este físico astro-húngaro ficou conhecido pelos seus trabalhos sobre gravitação e tensão superficial, e pela invenção do pêndulo de torção.
Faz também anos hoje que nascia <a href="https://en.wikipedia.org/wiki/John_Hopkinson">John Hopkinson</a>. Nascido em Manchester em 1849, este físico e engenheiro electrotécnico inglês ficou conhecido pela invenção do sistema trifásico para a distribuição de energia eléctrica. Ficou também conhecido pela Lei de Hopkinson que é a analogia magnética à Lei de Ohm. Esta lei estabelece que num circuito magnético a força magneto-motriz é igual ao produto do fluxo magnético com a relutância magnética. Como a lei de Ohm, a lei de Hopkinson pode ser interpretada como uma equação empírica que funciona para alguns materiais, ou pode servir como uma definição de relutância.
Faz igualmente anos hoje que nascia, em 1870, <a href="https://en.wikipedia.org/wiki/Bertram_Boltwood">Bertram Boltwood</a>. Este físico e químico norte-americano ficou conhecido pelo seu trabalho pioneiro na radioquímica. Estudou a radioactividade do urânio e do tório, e seus produtos resultantes, que lançaram as bases para o conceito de isótopos. Boltwood estudou cada "série radioactiva" de elementos radioactivos em rochas enquanto se desintegram sequencialmente em outros isótopos ou elementos. Ele estabeleceu que o chumbo era o produto final de decomposição do urânio, observou que a relação de urânio-chumbo era maior em rochas mais antigas e, com a sugestão de Ernest Rutherford, foi o primeiro a medir a idade das rochas pela decadência do urânio para chumbo. O composto mineral designado por Boltwoodite foi nomeado em sua honra.
Por fim, faz também anos hoje que nascia, em 1927, <a href="http://lemelson.mit.edu/resources/allen-k-breed">Allen K. Breed</a>. Este inventor norte-americano ficou conhecido por em 1967, ter inventado um componente mecânico de bola-em-tubo para detecção de um choque. Este sensor electromecânico com uma bola de aço anexada a um tubo por um imã que conseguia insuflar um airbag em menos de 30 milissegundos. Uma pequena explosão de azida de sódio em vez de ar comprimido foi utilizada pela primeira vez durante a insuflação.</p>

<p>Esta semana continuamos a ver imagens impressionantes de Saturno enviadas pela sonda Cassini. Como a sonda Cassini da NASA faz sua série sem precedentes de mergulhos semanais entre Saturno e seus anéis, os cientistas estão a descobrir - até agora - que o campo magnético do planeta não tem inclinação discernível. Esta surpreendente observação, significa que o verdadeiro comprimento do dia de Saturno ainda é desconhecida, é apenas uma das várias ideias iniciais da fase final da missão de Cassini, conhecida como o Grande Finale.
Esta semana também ficámos a saber que a especificação do USB 3.2 irá trazer incrementalmente sobre a versão actual. Os novos hosts e dispositivos USB 3.2 agora podem ser projectados como soluções de várias pistas, permitindo até duas pistas de 5 Gbps ou duas pistas de operação de 10 Gbps duplicando a performance actual.
Esta semana também ficámos a saber que o Breakthrough Starshot, um programa multifacetado para desenvolver e lançar missões espaciais interestelares práticas, voou com sucesso sua primeira nave espacial - a menor lançada. Em 23 de Junho, uma série de protótipos "Sprites" - as mais pequenas sondas espaciais totalmente funcionais do mundo, construídas por uma única placa de circuito - obtiveram órbita terrestre baixa, acompanhando os satélites 'Max Valier' e 'Venta' de OHB System AG. Os chips de 3.5 por 3.5 centímetros pesam apenas quatro gramas, mas contêm painéis solares, computadores, sensores e rádios. Esses veículos são o próximo passo de uma revolução na miniaturização da nave espacial que pode contribuir para o desenvolvimento de "StarChips" de centímetros e gramas imaginados pelo projecto Breakthrough Starshot.</p>

<p>Na Newsletter desta semana apresentamos diversos projetos de maker assim como um modelo 3D que poderá ser útil. É apresentada revista MagPI Nº60 de Agosto.</p>

<p><img src="../res/_jpralves.jpg" alt="jpralves" /> João Alves (<a href="https://altlab.org/d/m/jpralves/newsletters/2017/117/&#x6d;&#97;&#105;&#x6c;&#116;&#111;&#x3a;&#x6a;&#112;&#114;&#x61;&#108;&#118;&#x65;&#x73;&#64;g&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;o&#x6d;#x6d;&a&i&l&t&o&:&j&p&r&a&l&v&e&s&@g&m&a&i&l&.&co&m"><span class="__cf_email__" data-cfemail="98f2e8eaf9f4eefdebd8fff5f9f1f4b6fbf7f5">[email&#160;protected]</span></a>)</p>

<p>O conteúdo da Newsletter encontra-se sob a licença <img src="../res/_by-nc-sa4.0.png" alt="by-nc-sa4.0" /> <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>

<p></SPAN></DIV></p>

<hr />

<h1 id="Novidades-da-Semana">Novidades da Semana</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS117_SaturnSurprisesAsCassiniContin.jpg" alt="Saturn Surprises As Cassini Continues its Grand Finale" class="lefter"></p>

<h2><a href="https://www.jpl.nasa.gov/news/news.php?feature=6900">Saturn Surprises As Cassini Continues its Grand Finale</a></h2>

<p><em>"As NASA's Cassini spacecraft makes its unprecedented series of weekly dives between Saturn and its rings, scientists are finding -- so far -- that the planet's magnetic field has no discernible tilt. This surprising observation, which means the true length of Saturn's day is still unknown, is just one of several early insights from the final phase of Cassini's mission, known as the Grand Finale. Other recent science highlights include promising hints about the structure and composition of the icy rings, along with high-resolution images of the rings and Saturn's atmosphere. Cassini is now in the 15th of 22 weekly orbits that pass through the narrow gap between Saturn and its rings. The spacecraft began its finale on April 26 and will continue its dives until Sept. 15, when it will make a mission-ending plunge into Saturn's atmosphere. "Cassini is performing beautifully in the final leg of its long journey," said Cassini Project Manager Earl Maize at NASA's Jet Propulsion Laboratory, Pasadena, California. "Its observations continue to surprise and delight as we squeeze out every last bit of science that we can get." Cassini scientists are thrilled as well -- and surprised in some cases -- with the observations being made by the spacecraft in the finale. "The data we are seeing from Cassini's Grand Finale are every bit as exciting as we hoped, although we are still deep in the process of working out what they are telling us about Saturn and its rings," said Cassini Project Scientist Linda Spilker at JPL."</em> <a href="https://www.jpl.nasa.gov/news/news.php?feature=6900">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS117_Usb30PromoterGroupAnnouncesUsb.jpg" alt="USB 3.0 Promoter Group Announces USB 3.2 Update" class="lefter"></p>

<h2><a href="http://www.businesswire.com/news/home/20170725005509/en">USB 3.0 Promoter Group Announces USB 3.2 Update</a></h2>

<p><em>"The USB 3.0 Promoter Group today announced the pending release of the USB 3.2 specification, an incremental update that defines multi-lane operation for new USB 3.2 hosts and devices. USB Developer Days 2017 will include detailed technical training covering USB 3.2, fast charging advancements in USB Power Delivery, and other exciting topics. While USB hosts and devices were originally designed as single-lane solutions, USB Type-C™ cables were designed to support multi-lane operation to ensure a path for scalable performance. New USB 3.2 hosts and devices can now be designed as multi-lane solutions, allowing for up to two lanes of 5 Gbps or two lanes of 10 Gbps operation. This enables platform developers to continue advancing USB products to fit their customers’ needs by effectively doubling the performance across existing cables. For example, a USB 3.2 host connected to a USB 3.2 storage device will now be capable of realizing over 2 GB/sec data transfer performance over an existing USB Type-C™ cable that is certified for SuperSpeed USB 10 Gbps. “When we introduced USB Type-C to the market, we intended to assure that USB Type-C cables and connectors certified for SuperSpeed USB or SuperSpeed USB 10 Gbps would, as produced, support higher performance USB as newer generations of USB 3.0 were developed,” said Brad Saunders, USB 3.0 Promoter Group Chairman. “The USB 3.2 update delivers the next level of performance.” “With increased performance and seamless compatibility, the new USB 3.2 specification brings even more speed and bandwidth benefits to new USB 3.2 devices, while remaining compatible with USB 3.0 and earlier devices,” said Roanne Sones, General Manager, Strategy and Ecosystem for Windows and Devices, Microsoft. “We’re excited to work with our partners in the USB 3.0 Promoter Group to help showcase these benefits to users around the world.”"</em> <a href="http://www.businesswire.com/news/home/20170725005509/en">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="NS117_InQuestToReachAlphaCentauriBre.jpg" alt="In quest to reach Alpha Centauri, breakthrough starshot launches world’s smallest spacecraft" class="lefter"></p>

<h2><a href="https://breakthroughinitiatives.org/News/12">In quest to reach Alpha Centauri, breakthrough starshot launches world’s smallest spacecraft</a></h2>

<p><em>"Breakthrough Starshot, a multi-faceted program to develop and launch practical interstellar space missions, successfully flew its first spacecraft – the smallest ever launched. On June 23, a number of prototype “Sprites” – the world’s smallest fully functional space probes, built on a single circuit board – achieved Low Earth Orbit, piggybacking on OHB System AG’s ‘Max Valier’ and ‘Venta’ satellites. The 3.5-by-3.5 centimeter chips weigh just four grams but contain solar panels, computers, sensors, and radios. These vehicles are the next step of a revolution in spacecraft miniaturization that can contribute to the development of centimeter- and gram-scale “StarChips” envisioned by the Breakthrough Starshot project. The Sprite is the brainchild of Breakthrough Starshot’s Zac Manchester, whose 2011 Kickstarter campaign, “KickSat”, raised the first funds to develop the concept. The Sprites were constructed by researchers at Cornell University and transported into space as secondary payloads by the Max Valier and Venta satellites, the latter built by the Bremen-based OHB System AG, whose generous assistance made the mission possible. The Sprites remain attached to the satellites. Communications received from the mission show the Sprite system performing as designed. The spacecraft are in radio communication with ground stations in California and New York, as well as with amateur radio enthusiasts around the world. This mission is designed to test how well the Sprites' electronics perform in orbit, and demonstrates their novel radio communication architecture."</em> <a href="https://breakthroughinitiatives.org/News/12">[...]</a>
 </SPAN></DIV></p>

<h2>Outras Notícias</h2>

<ul>
<li><a href="http://www.electronicdesign.com/embedded-revolution/ibm-processor-aims-blanket-encryption-over-everything">IBM Processor Aims to Blanket Encryption Over Everything</a></li>
<li><a href="https://www.jpl.nasa.gov/news/news.php?feature=6901">A Final Farewell to LISA Pathfinder</a></li>
<li><a href="http://www.materialx.org/index.html">MaterialX</a></li>
<li><a href="https://www.microsoft.com/en-us/research/blog/second-version-hololens-hpu-will-incorporate-ai-coprocessor-implementing-dnns/">Second version of HoloLens HPU will incorporate AI coprocessor for implementing DNNs</a></li>
<li><a href="http://media.nxp.com/phoenix.zhtml?c=254228&amp;p=RssLanding&amp;cat=news&amp;id=2289486">NXP and Amazon Web Services Launch Cooperation in IoT</a></li>
</ul>

<h1 id="Ciencia-e-Tecnologia">Ciência e Tecnologia</h1>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_StanfordResearchersDevelopANew.jpg" alt="Stanford researchers develop a new type of soft, growing robot" class="lefter"></p>

<h2><a href="http://news.stanford.edu/2017/07/19/stanford-researchers-develop-new-type-soft-growing-robot/">Stanford researchers develop a new type of soft, growing robot</a></h2>

<p><em>"Imagine rescuers searching for people in the rubble of a collapsed building. Instead of digging through the debris by hand or having dogs sniff for signs of life, they bring out a small, air-tight cylinder. They place the device at the entrance of the debris and flip a switch. From one end of the cylinder, a tendril extends into the mass of stones and dirt, like a fast-climbing vine. A camera at the tip of the tendril gives rescuers a view of the otherwise unreachable places beneath the rubble. This is just one possible application of a new type of robot created by mechanical engineers at Stanford University, detailed in a June 19 Science Robotics paper. Inspired by natural organisms that cover distance by growing – such as vines, fungi and nerve cells – the researchers have made a proof of concept of their soft, growing robot and have run it through some challenging tests. “Essentially, we’re trying to understand the fundamentals of this new approach to getting mobility or movement out of a mechanism,” explained Allison Okamura, professor of mechanical engineering and senior author of the paper. “It’s very, very different from the way that animals or people get around the world.” To investigate what their robot can do, the group created prototypes that move through various obstacles, travel toward a designated goal, and grow into a free-standing structure. This robot could serve a wide range of purposes, particularly in the realms of search and rescue and medical devices, the researchers said. "</em> <a href="http://news.stanford.edu/2017/07/19/stanford-researchers-develop-new-type-soft-growing-robot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_EmpoweringRobotsForEthicalBeha.jpg" alt="Empowering robots for ethical behavior" class="lefter"></p>

<h2><a href="https://www.sciencedaily.com/releases/2017/07/170718103528.htm">Empowering robots for ethical behavior</a></h2>

<p><em>"Scientists at the University of Hertfordshire in the UK have developed a concept called Empowerment to help robots to protect and serve humans, while keeping themselves safe. Robots are becoming more common in our homes and workplaces and this looks set to continue. Many robots will have to interact with humans in unpredictable situations. For example, self-driving cars need to keep their occupants safe, while protecting the car from damage. Robots caring for the elderly will need to adapt to complex situations and respond to their owners' needs. Recently, thinkers such as Stephen Hawking have warned about the potential dangers of artificial intelligence, and this has sparked public discussion. "Public opinion seems to swing between enthusiasm for progress and downplaying any risks, to outright fear," says Daniel Polani, a scientist involved in the research, which was recently published in Frontiers in Robotics and AI. However, the concept of "intelligent" machines running amok and turning on their human creators is not new. In 1942, science fiction writer Isaac Asimov proposed his three laws of robotics, which govern how robots should interact with humans. Put simply, these laws state that a robot should not harm a human, or allow a human to be harmed. The laws also aim to ensure that robots obey orders from humans, and protect their own existence, as long as this doesn't cause harm to a human. The laws are well-intentioned, but they are open to misinterpretation, especially as robots don't understand nuanced and ambiguous human language. In fact, Asimov's stories are full of examples where robots misinterpreted the spirit of the laws, with tragic consequences. One problem is that the concept of "harm" is complex, context-specific and is difficult to explain clearly to a robot. If a robot doesn't understand "harm," how can they avoid causing it? "We realized that we could use different perspectives to create 'good' robot behavior, broadly in keeping with Asimov's laws," says Christoph Salge, another scientist involved in the study. The concept the team developed is called Empowerment. Rather than trying to make a machine understand complex ethical questions, it is based on robots always seeking to keep their options open. "Empowerment means being in a state where you have the greatest potential influence on the world you can perceive," explains Salge. "So, for a simple robot, this might be getting safely back to its power station, and not getting stuck, which would limit its options for movement. For a more futuristic, human-like robot this would not just include movement, but could incorporate a variety of parameters, resulting in more human-like drives." The team mathematically coded the Empowerment concept, so that it can be adopted by a robot. While the researchers originally developed the Empowerment concept in 2005, in a recent key development, they expanded the concept so that the robot also seeks to maintain a human's Empowerment. "We wanted the robot to see the world through the eyes of the human with which it interacts," explains Polani. "Keeping the human safe consists of the robot acting to increase the human's own Empowerment.""</em> <a href="https://www.sciencedaily.com/releases/2017/07/170718103528.htm">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_BuildingABetterBattery.jpg" alt="Building a better battery" class="lefter"></p>

<h2><a href="https://www.engr.washington.edu/news/membrion">Building a better battery</a></h2>

<p><em>"Imagine revolutionizing the renewable energy market with the silica gel packets you find in shoeboxes and snack bags. The research team behind Membrion is working to do just that. Developed by chemical engineering researchers Greg Newbloom (PhD ’14) and Weyerhaeuser Endowed Associate Professor Lilo Pozzo, the Membrion technology seeks to innovate battery storage with a lower cost, improved battery membrane that uses silica gel. And, the team says, they couldn’t be doing it without the support of partners on and off campus committed to advancing alternative energy research, innovation and commercialization. Membrion, which incorporated in March 2016, won this year’s Buerk Center for Entrepreneurship’s Business Plan Competition as well as the competition’s “Best Idea for the Future” award. Newbloom is founder and CTO of the new company; he and Pozzo recently spoke with us about their emerging technology, its entrepreneurial journey and where they hope to take it next. Explain to us what Membrion is and how it will affect the renewable energy market. GN: Renewable energy, like solar or wind energy, is great but it’s not always available on demand. For example, if you want to watch T.V. after dark, you can’t rely on direct solar power. So, to provide on-demand power, renewable energy is stored in batteries. To store a lot of energy, you need a lot of really big batteries — this is often referred to as “grid-scale” storage. Flow batteries are the ideal choice for grid-scale energy storage, but they tend to be very pricy in large part due to their complex polymer membranes. This is where Membrion is changing things: We’re making membranes from silica gel instead. It’s more durable, less expensive, and will yield better performance overall. Our goal is to make batteries affordable and efficient so that renewable energy becomes an even more accessible and desired source to power communities worldwide."</em>  <a href="https://www.engr.washington.edu/news/membrion">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_AdvancingQuantumTechnologyIn40.jpg" alt="Advancing Quantum Technology in 40 Picoseconds" class="lefter"></p>

<h2><a href="http://gsas.yale.edu/news/advancing-quantum-technology-40-picoseconds">Advancing Quantum Technology in 40 Picoseconds</a></h2>

<p><em>"Linran Fan (Engineering and Applied Science) is first author of an article published in Nature Photonics that presents a significant breakthrough in quantum communications and quantum computing. Working in the lab of Hong Tang, the Llewellyn West Jones, Jr. Professor of Electrical Engineering &amp; Physics, Fan and fellow researchers developed a new technique to control the frequency of single photons – a crucial step in realizing the potential of quantum technology. Established methods for changing photon frequency have significant drawbacks. The most common technique uses “nonlinear optical effects,” in which a laser essentially acts as a pump, changing the photon frequency by providing extra photons to mix with the original one. Because the effect is weak and probabilistic, the process requires a very strong laser that creates “noise,” which causes some of the quantum properties to be lost. Using a completely different technique, the Tang lab was able to alter photon frequency by up to 300 GHz without creating any noise. They did this by changing the photon’s propagating medium – the material in which the light travels. In standard integrated photonics, silicon, silicon nitride, and silicon di-oxide (SiO2) are commonly used for the “waveguide,” the structure that guides the light. Tang’s lab introduced the use of aluminum nitride as the propagating medium, and that made all the difference. They were able to stretch or compress the photon and change its frequency while the photon was in the waveguide — a process that takes about 40 picoseconds. A picosecond is one-trillionth of a second, and since the frequency change must happen exactly as the photon enters the waveguide, achieving this was quite a challenge. “We utilize microwave and the piezoelectric effect, which turns microwave energy into mechanical stress, to change the waveguide structure,” Fan explains. The piezoelectric effect is the ability of certain materials to generate an alternating current (AC) voltage when subjected to mechanical stress or vibration, or to vibrate when subjected to an AC voltage, or both. “We don’t need the optical pump, so we don’t create any noise photon.”"</em> <a href="http://gsas.yale.edu/news/advancing-quantum-technology-40-picoseconds">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_HamburgResearchGroupDevelopsNe.jpg" alt="Hamburg research group develops new transistor" class="lefter"></p>

<h2><a href="https://www.uni-hamburg.de/en/newsroom/presse/2017/pm56.html">Hamburg research group develops new transistor</a></h2>

<p><em>"Transistor are electrical components that are direct electronic signals and enable us to process information. Millions of them are built into every single computer chip, and they are usually made out of the semiconductor material silicon. Dr. Christian Klinke's research group at the Institute of Physical Chemistry at the University of Hamburg recently succeeded in the production of nanoparticles. The new material lowers production costs and facilitates the use of energy-efficient applications. The research results are published in the current issue of Science Advances. Transistors are electrical components with which currents can be controlled and information processed. They are used billions of times on every computer chip and consist mostly of the semiconducting material silicon. The group around PD Dr. Christian Klinke from the Institute for Physical Chemistry at the University of Hamburg has now succeeded in producing transistors made of metal nanoparticles, which allows a more economical production as well as energy-saving applications. The results were published in the current issue of the scientific journal "Science Advances". Scientists have succeeded in producing transistors that are based on a completely new principle: instead of semiconductors, they use metal nanoparticles that are so small that they no longer show their metallic character under current flow, but have an energy gap that is larger than that of the semiconductor Is caused by the repulsion of the electrons among one another, which gives them semi-conductor-like properties. With a control voltage, this gap can be moved energetically and the current flow can thus be switched on and off as desired. These nanotransistors have several advantages that make them interesting for commercial applications: the chemical production of the metal nanoparticles is very controllable and scalable and provides very small nanoparticles that can be stored in solvents and easily further processed. In contrast to previous similar approaches, the nanoparticles are not installed as individual structures, rendering the production very complex and the properties of the corresponding components unreliable, but as thin films having only a single layer of nanoparticles. Thus, the electrical properties of the components are not only adjustable and almost identical, but the transistors are also less expensive. In addition, they function not only at low temperatures, but also at room temperature. "Our work shows that there are alternatives to the traditional transistor concepts, which can be used in various special applications in the future," says Christian Klinke. "The components developed by us can not only be used as transistors, but they are also very interesting as chemical sensors, since the interstices of nanoparticles to nanoparticles react highly sensitively to chemical deposits or attachments. The application as transistors and sensors opens up new research perspectives. ""</em> <a href="https://www.uni-hamburg.de/en/newsroom/presse/2017/pm56.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_ReshapingComputerAidedDesign.jpg" alt="Reshaping computer-aided design" class="lefter"></p>

<h2><a href="http://news.mit.edu/2017/reshaping-computer-aided-design-instantcad-0724">Reshaping computer-aided design</a></h2>

<p><em>"Almost every object we use is developed with computer-aided design (CAD). Ironically, while CAD programs are good for creating designs, using them is actually very difficult and time-consuming if you’re trying to improve an existing design to make the most optimal product. Researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Columbia University are trying to make the process faster and easier: In a new paper, they’ve developed InstantCAD, a tool that lets designers interactively edit, improve, and optimize CAD models using a more streamlined and intuitive workflow. InstantCAD integrates seamlessly with existing CAD programs as a plug-in, meaning that designers don’t have to learn new tools to use it."</em> <a href="http://news.mit.edu/2017/reshaping-computer-aided-design-instantcad-0724">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_HologramsTakenToNewDimension.jpg" alt="Holograms taken to new dimension" class="lefter"></p>

<h2><a href="https://unews.utah.edu/holograms-taken-to-new-dimension/">Holograms taken to new dimension</a></h2>

<p><em>"echnology developed by a team of University of Utah electrical and computer engineers could make the holographic chess game R2-D2 and Chewbacca played in “Star Wars” a reality. The team led by electrical and computer engineering associate professor Rajesh Menon has discovered a way to create inexpensive full-color 2-D and 3-D holograms that are far more realistic, brighter and can be viewed at wider angles than current holograms. The applications for this technology could be wide-ranging, from currency and identification badges to amusement rides and advertisements. “You can have rich colors at high efficiency, with high brightness and at low cost. And you don’t need fancy lasers and complicated optics,” Menon says. The team’s technology was profiled in a new paper published July 19, 2017, in the current issue of Scientific Reports. The paper, “Full Color, Large Area, Transmissive Holograms Enabled by Multi-Level Diffractive Optics,” was co-authored by University of Utah doctoral students Nabil Mohammad, Monjurul Meem and Xiaowen Wan. Typically, the projection of any image, whether it is two or three dimensional, is inefficient because when white light shines on an object, we can only see the reflected color that bounces back to our eyes while the rest of the colors of the spectrum are absorbed. Therefore, there is a lot of wasted light. With a typical LCD projector, for example, you may only see as little as 5 percent of the total light at one time. Menon and his team have discovered a better way that borrows from the same principle behind how wings of certain butterflies display their colors: Instead of reflecting only the colors you see while absorbing the rest, all of the white light is redirected so you see the wavelengths of the wing’s colors at different locations. None of the light is absorbed and therefore wasted. Using sophisticated algorithms and a new fabrication method, the engineers can create holograms that do the same thing — redirect colors to appropriate locations — instead of absorbing most of it to project much brighter photographic images either in 2-D or 3-D and with full, natural colors. Currently, full-color holograms require lasers to not only make them, but also to view them. Menon’s holograms can be viewed with regular white light. Most importantly, these holograms can be viewed from any angle, and the image detail does not change, much like a real object."</em> <a href="https://unews.utah.edu/holograms-taken-to-new-dimension/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_WhoWillControlTheSwarm.jpg" alt="Who will control the swarm?" class="lefter"></p>

<h2><a href="https://engineering.stanford.edu/news/who-will-control-swarm">Who will control the swarm?</a></h2>

<p><em>"The world is already well on its way to a day when innumerable autonomous cars and drones buzz about, shuffling commuters to work and packages to doorsteps. In fact, there is new term for it floating around the circles of engineers and venture capitalists who hope to see the day arrive sooner rather than later: They call it “The Swarm.” But this dramatic-sounding reality raises a critical question that has yet to be answered: Who will control the swarm? Some say control will be distributed. Each car and every drone will be its own self-sustaining unit – individually aware of its surroundings, individually directed where to go and individually outfitted with all the computational power to make it through the world efficiently and without accident. A collection of faculty at Stanford have a different view. They believe that device swarms will be managed centrally, using applications running in large datacenters, much the way the cloud centralized big data. The faculty members have formed a new laboratory at Stanford, called the Platform Lab, to develop infrastructure for these new “Big Control” applications. “We think all these self-driving cars and drones will be controlled not individually, but centrally, in a coordinated fashion,” says John Ousterhout, faculty director of the lab. “This has the potential to change how society functions on a daily basis.” While most current research into autonomous vehicles assumes a distributed model – relatively autonomous devices, controlled in a peer-to-peer fashion with each machine doing its own calculations – the concentrated model has its advantages, says Ousterhout. First is the ease of creating applications. Writing applications for the distributed model is very difficult, since each device has limited information about the state of the world. With the centralized approach, data from all the devices is collected in one place. This provides a big-picture view of the world that allows better control of higher-level tasks like system-wide situational perception, decision-making and large-scale traffic planning. Second, control applications running in datacenters have many more resources available, such as computing horsepower and large back-end datasets. This allows them to implement more sophisticated collaborative behaviors for the device swarm. In addition, the centralized applications can take advantage of powerful machine learning algorithms, which allow the control system to learn and improve its behavior."</em> <a href="https://engineering.stanford.edu/news/who-will-control-swarm">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_DeepLearningCreatesEarthLikeTe.jpg" alt="Deep Learning Creates Earth-like Terrain by Studying NASA Satellite Images" class="lefter"></p>

<h2><a href="https://www.technologyreview.com/s/608316/deep-learning-creates-earth-like-terrain-by-studying-nasa-satellite-images/">Deep Learning Creates Earth-like Terrain by Studying NASA Satellite Images</a></h2>

<p><em>"The landscapes in video games and artificial worlds can be generated in two ways. The first is to hand-craft the terrain and populate it with appropriate colors and textures such as rocks, grass, trees, snow and so on. This produces high-quality results but is expensive because of the human labor involved. The second method is to generate the landscape algorithmically, a process that is much quicker and cheaper. This is how players in the game Minecraft enter an entirely new landscape every time they play. The algorithms behind this process are well developed, and programmers have fine-tuned them over the years to produce different climates, textures, height variations and so on. But new landscape-generating algorithms are themselves time-consuming and expensive to write. So a way to automate their creation would be a significant advance. Today Christopher Beckham and Christopher Pal at the Montreal Institute of Learning Algorithms in Canada say they have trained a deep-learning machine to generate realistic landscapes using satellite images of Earth as a training set. In effect, the machine writes its own algorithm. The work promises to significantly change the way artificial landscapes can be generated on the fly. The system that Beckham and Pal exploit is called a generative adversarial network. It consists of two deep-learning machines that work together to tackle a problem, in this case generating realistic terrain. The first machine generates new terrain while the second evaluates the results and provides feedback. The first machine then uses this feedback to produce another set of landscapes, which the second machine evaluates with feedback, and so on. The idea is that the second machine learns to produce landscapes that match the feedback given by the first machine."</em> <a href="https://www.technologyreview.com/s/608316/deep-learning-creates-earth-like-terrain-by-studying-nasa-satellite-images/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_TulaneTeamAdvancesKnowledgeTow.jpg" alt="Tulane team advances knowledge toward more efficient electronics" class="lefter"></p>

<h2><a href="http://news.tulane.edu/pr/tulane-team-advances-knowledge-toward-more-efficient-electronics">Tulane team advances knowledge toward more efficient electronics</a></h2>

<p><em>"A recent discovery by a team of researchers led by Tulane University advances fundamental knowledge that could one day lead to more energy-efficient computers, televisions, cellphones and other electronics. The researchers’ discovery of a new magnetic topological semimetal is featured in the latest edition of the prestigious journal Nature Materials. The Tulane team was led by physics professor Zhiqiang Mao, the Tulane School of Science and Engineering’s Outstanding Researcher for 2017. Mao’s research, which focuses on quantum materials such as superconductors, magnetic materials and topological materials, was carried out in response to the need for better ways to power electronics, especially given continually shrinking transistors in smartphones and other devices. Topological semimetals represent a new quantum state of matter."</em> <a href="http://news.tulane.edu/pr/tulane-team-advances-knowledge-toward-more-efficient-electronics">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_DesigningA4DCameraForRobots.jpg" alt="Designing a 4D camera for robots" class="lefter"></p>

<h2><a href="http://news.stanford.edu/press-releases/2017/07/21/new-camera-impro-virtual-reality/">Designing a 4D camera for robots</a></h2>

<p><em>"Stanford engineers have developed a 4D camera with an extra-wide field of view. They believe this camera can be better than current options for close-up robotic vision and augmented reality. A new camera that builds on technology first described by Stanford researchers more than 20 years ago could generate the kind of information-rich images that robots need to navigate the world. This camera, which generates a four dimensional image, can also capture nearly 140 degrees of information. “We want to consider what would be the right camera for a robot that drives or delivers packages by air. We’re great at making cameras for humans but do robots need to see the way humans do? Probably not,” said Donald Dansereau, a postdoctoral fellow in electrical engineering."</em> <a href="http://news.stanford.edu/press-releases/2017/07/21/new-camera-impro-virtual-reality/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_PhysicistsObserveIndividualAto.jpg" alt="Physicists observe individual atomic collisions during diffusion for the first time" class="lefter"></p>

<h2><a href="http://www.uni-kl.de/en/news/pressemitteilungen/news/detail/News/physicists-observe-individual-atomic-collisions-during-diffusion-for-the-first-time/">Physicists observe individual atomic collisions during diffusion for the first time</a></h2>

<p><em>"In the world of research, diffusion is understood as a process in which tiny particles disperse uniformly throughout a gas or liquid. Although these media are made up of individual particles, diffusion is perceived as a continuous process. So far, the effects of an individual collision between particles – the cornerstone of diffusion – had not been observed. Now, physicists in Kaiserslautern and Erlangen have succeeded in observing the fundamental steps of diffusion by individual atoms in a gas and have provided a theoretical description of this mechanism. The study has been published in the renowned journal Physical Review Letters. Almost two hundred years ago, the Scottish doctor and researcher Robert Brown observed that particles of pollen quiver as they move through a liquid. Tiny particles, such as molecules or atoms, exhibit similar behaviour as they disperse within gases and liquids. Resulting from a huge number of random collisions, the particles show a zigzag pattern of movements causing various substances to mix. Scientists refer to these zigzag movements as “Brownian motion” and to the dispersion and mixing of various substances as diffusion. “Diffusion is a key phenomenon in many areas of science and forms the basis for numerous transport processes, for example in living cells or energy storage devices,” says Professor Artur Widera, who conducts research into the quantum physics of individual atoms and ultracold quantum gases at TU Kaiserslautern. “That’s why it’s important to have an understanding of diffusion processes in almost every area of the life sciences, the natural sciences, and technological development.” An easy, simplified understanding of diffusion can be obtained by disregarding the individual collisions between particles. “In this context, we also talk of a continuous medium with, for example, a larger particle diffusing into it. This simplification becomes all the more accurate as the mass of the particles in the medium becomes smaller and the frequency of collisions becomes higher,” says Dr. Michael Hohmann, who is researcher in Professor Widera’s group and first author of this study. One everyday example is fog, which can also be viewed as a medium of this kind although it actually consists of tiny individual water droplets. For their experiments, the physicists working under Widera tweaked the conditions that characterise a continuous medium: “Instead of large particles, such as pollen, we studied the diffusion of individual atoms that have almost the same mass as atoms of the gas. Furthermore, we used a very cold, dilute gas in order to drastically reduce the frequency of collisions,” explains Hohmann. By doing so, the Kaiserslautern-based researchers observed, for the first time, how caesium atoms diffuse at a temperature close to absolute zero in a gas made up of rubidium atoms. “These are temperatures that no refrigerator can reproduce, so we used laser beams to cool the atoms and hold them in place in a vacuum apparatus. This slowed the diffusion down to such an extent that the effect of individual collisions could be observed,” explains Professor Widera with regard to the experimental setup. For the theoretical description of the experiment, the researchers in Kaiserslautern received assistance from their colleague Professor Eric Lutz, a professor of theoretical physics at the Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), who helped them to develop the mathematical modelling. “With the new model, we can now describe the atoms’ motions more accurately,” says the Erlangen-based researcher. Together, they showed that it is sufficient to alter the coefficient of friction in the theoretical calculation from the continuous model. By doing so, it is also possible to describe cases that do not involve a continuous medium, as in the above experiment. Examples of such cases include when aerosols – mixtures of suspended particles – disperse in thin layers of air in the upper atmosphere, in interstellar space or in vacuum systems. The publishers of the journal Physical Review Letters highlight the study as an especially interesting and noteworthy article and have published it as an Editor’s Suggestion: “Individual tracer atoms in an ultracold dilute gas.”"</em> <a href="http://www.uni-kl.de/en/news/pressemitteilungen/news/detail/News/physicists-observe-individual-atomic-collisions-during-diffusion-for-the-first-time/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_PinpointingSourcesOfWaterPollu.jpg" alt="Pinpointing sources of water pollution with a robotic eel" class="lefter"></p>

<h2><a href="https://actu.epfl.ch/news/pinpointing-sources-of-water-pollution-with-a-robo/">Pinpointing sources of water pollution with a robotic eel</a></h2>

<p><em>"Researchers from EPFL, together with other institutes, have developed a robotic eel that swims through contaminated water to find the source of the pollution. The sensor-equipped robot can be controlled remotely or move on its own. In tests carried out in a small section of Lake Geneva, the robot was able to generate maps of water conductivity and temperature. EPFL researchers are taking part in an ambitious project funded by the Swiss NanoTera Program to develop a swimming robot that can detect the source of water pollution. The robot, named Envirobot, is equipped with chemical, physical and biological sensors and measures nearly 1.5 meters long. It moves through water like an eel, without stirring up mud or disturbing aquatic life. Its sensors take measurements at different locations in the water as it swims and send the data to a computer in real-time. The robot is regularly tested in Lake Geneva. A recent test involved simulating water pollution by diffusing salt into a small area just off the shore, thus changing the water’s conductivity. The researchers then let the robot swim in the contaminated area. The robot successfully mapped the variations in conductivity and generated a temperature map. The ultimate goal is for the robot to be able to detect heavy metals like mercury or other pollutants. “There are many advantages to using swimming robots. They can take measurements and send us data in real-time – much faster than if we had measurement stations set up around the lake. And compared with conventional propeller-driven underwater robots, they are less likely to get stuck in algae or branches as they move around. What’s more, they produce less of a wake, so they don’t disperse pollutants as much,” says Auke Ijspeert, Head of EPFL's Biorobotics Laboratory (BioRob). “The Envirobot can follow a preprogrammed path, and has also the potential to make its own decisions and independently track down the source of pollution.” That could be by, for example, steadily swimming in the direction of increasing toxicity. The robot is made up of numerous modules that each contain a small electric motor for changing curvature, enabling it to move smoothly through the water. The modular design also allows engineers to change its composition and vary its length as needed. “The robot can be easily taken apart, transported to a remote water reservoir, for example, and put back together to begin testing,” says Behzad Bayat, another BioRob researcher."</em> <a href="https://actu.epfl.ch/news/pinpointing-sources-of-water-pollution-with-a-robo/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_BguResearcherDevelopsNew3DScan.jpg" alt="BGU Researcher Develops New 3-D Scanning Technique" class="lefter"></p>

<h2><a href="https://aabgu.org/new-3d-scanning-technique/">BGU Researcher Develops New 3-D Scanning Technique</a></h2>

<p><em>"An international group of researchers developed a technique that results in more accurate 3-D scanning for reconstructing complex objects than what currently exists. The innovative method combines robotics and water. “Using a robotic arm to immerse an object on an axis at various angles, and measuring the volume displacement of each dip, we combine each sequence and create a volumetric shape representation of an object,” says Prof. Andrei Scharf, of Ben-Gurion University of the Negev, Department of Computer Science. “The key feature of our method is that it employs fluid displacements as the shape sensor,” Prof. Scharf explains. “Unlike optical sensors, the liquid has no line-of-sight requirements. It penetrates cavities and hidden parts of the object, as well as transparent and glossy materials, thus bypassing all visibility and optical limitations of conventional scanning devices.” The researchers used Archimedes’ theory of fluid displacement — the volume of displaced fluid is equal to the volume of a submerged object — to turn the modeling of surface reconstruction into a volume measurement problem. This serves as the foundation for the team’s modern, innovative solution to challenges in current 3-D shape reconstruction. The group demonstrated the new technique on 3-D shapes with a range of complexity, including an elephant sculpture, a mother and child hugging, and a DNA double helix. The results show that the dip reconstructions are nearly as accurate as the original 3-D model. The new technique is related to computed tomography — an imaging method that uses optical systems for accurate scanning and pictures. However, tomography-based devices are bulky and expensive and can only be used in a safe, customized environment."</em> <a href="https://aabgu.org/new-3d-scanning-technique/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_ConductivityKeyToMappingWaterI.jpg" alt="Conductivity key to mapping water inside Earth" class="lefter"></p>

<h2><a href="https://www.llnl.gov/news/conductivity-key-mapping-water-inside-earth">Conductivity key to mapping water inside Earth</a></h2>

<p><em>"Hydrogen at elevated temperature creates high electrical conductivity in the Earth's mantle. New work by Lawrence Livermore National Laboratory (LLNL) scientists shows the dispersal of water (incorporated as hydrogen in olivine, the most abundant mineral in the upper mantle), could account for high electrical conductivity seen in the asthenosphere (part of the upper mantle just below the lithosphere that is involved in plate tectonic movement). The research appears in Nature Scientific Reports (link is external). The work could lead to a better understanding of present day water distribution in the mantle, which has strong implications for planetary dynamics and evolution. Researchers said such information might provide key evidence as to why Earth is the only known planetary body in our solar system to develop plate tectonics and to retain liquid water oceans on its surface. "We approached the problem from a different perspective, using new hydrogen diffusion measurements to infer what the contribution of hydrogen would be to electrical conductivity," said LLNL's Wyatt Du Frane, the principal investigator on the project. "Our experiments on olivine indicated a larger temperature dependence than previously thought to occur for this phenomenon. The contribution of hydrogen to electrical conductivity, while modest at lower temperatures, becomes quite large at the temperatures expected to occur in the mantle." Minerals formed deep in the mantle and transported to the Earth's surface contain tens to hundreds of parts per million in weight (ppm wt) of water, providing evidence for the presence of dissolved water in the Earth's interior. Even at these low concentrations, water greatly affects the physico-chemical properties of mantle materials. The diffusion of hydrogen controls the transport of water in the Earth's upper mantle, but until now was not fully understood for olivine. Earth's hydrosphere is a distinctive feature of our planet where massive oceans affect its climate and support its ecosystem. The distribution of water on Earth is not limited to its outermost shell (hydrosphere and hydrated minerals), but extends to great depths within the planet. Downwelling oceanic lithosphere (at subduction zones) and upwelling magmas (at mid ocean ridges, volcanoes and hotspots) are vehicles for transport of H2O between the surface and the Earth's deep interior."</em> <a href="https://www.llnl.gov/news/conductivity-key-mapping-water-inside-earth">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_CarnegieMellonDevelopsLandmark.jpg" alt="Carnegie Mellon Develops Landmark Achievement in Walking Technology" class="lefter"></p>

<h2><a href="https://www.cmu.edu/news/stories/archives/2017/july/walking-technology.html">Carnegie Mellon Develops Landmark Achievement in Walking Technology</a></h2>

<p><em>"Researchers in Carnegie Mellon University’s College of Engineering are using feedback from the human body to develop designs for exoskeletons and prosthetic limbs. Published in Science, their technique, called human-in-the-loop optimization, customizes walking assistance for individuals and significantly lessens the amount of energy needed when walking. The algorithm that enables this optimization represents a landmark achievement in the field of biomechatronics. “Existing exoskeleton devices, despite their potential, have not improved walking performance as much as we think they should,” said Steven Collins, a professor of mechanical engineering. “We’ve seen improvements related to computing, hardware and sensors, but the biggest challenge has remained the human element — we just haven't been able to guess how they will respond to new devices.” The software algorithm is combined with versatile emulator hardware that automatically identifies optimal assistance strategies for individuals. During experiments, each user received a unique pattern of assistance from an exoskeleton worn on one ankle. The algorithm tested responses to 32 patterns over the course of an hour, making adjustments based on measurements of the user’s energy use with each pattern. The optimized assistance pattern produced larger benefits than any exoskeleton to date, including devices acting at all joints on both legs."</em> <a href="https://www.cmu.edu/news/stories/archives/2017/july/walking-technology.html">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_ScientistsDesignSolarCellThatC.jpg" alt="Scientists Design Solar Cell that Captures Nearly All Energy of Solar Spectrum" class="lefter"></p>

<h2><a href="https://mediarelations.gwu.edu/scientists-design-solar-cell-captures-nearly-all-energy-solar-spectrum">Scientists Design Solar Cell that Captures Nearly All Energy of Solar Spectrum</a></h2>

<p><em>"Scientists have designed and constructed a prototype for a new solar cell that integrates multiple cells stacked into a single device capable of capturing nearly all of the energy in the solar spectrum. The new design converts direct sunlight to electricity with 44.5 percent efficiency, giving it the potential to become the most efficient solar cell in the world. The approach is different from the solar panels one might commonly see on rooftops or in fields. The new device uses concentrator photovoltaic (CPV) panels that employ lenses to concentrate sunlight onto tiny, micro-scale solar cells. Because of their small size—less than one millimeter square—solar cells utilizing more sophisticated materials can be developed cost effectively. The stacked cell acts almost like a sieve for sunlight, with the specialized materials in each layer absorbing the energy of a specific set of wavelengths. By the time the light is funneled through the stack, just under half of the available energy has been converted into electricity. By comparison, the most common solar cell today converts only a quarter of the available energy into electricity. “Around 99 percent of the power contained in direct sunlight reaching the surface of Earth falls between wavelengths of 250 nm and 2500 nm, but conventional materials for high-efficiency multi-junction solar cells cannot capture this entire spectral range,” said Matthew Lumb, lead author of the study and a research scientist at the GW School of Engineering and Applied Science. “Our new device is able to unlock the energy stored in the long-wavelength photons, which are lost in conventional solar cells, and therefore provides a pathway to realizing the ultimate multi-junction solar cell.”  While scientists have worked towards more efficient solar cells for years, this approach has two novel aspects. First, it uses a family of materials based on gallium antimonide (GaSb) substrates, which are usually found in applications for infra-red lasers and photodetectors. The novel GaSb-based solar cells are assembled into a stacked structure along with high efficiency solar cells grown on conventional substrates that capture shorter wavelength solar photons. In addition, the stacking procedure uses a technique known as transfer-printing, which enables three dimensional assembly of these tiny devices with a high degree of precision. This particular solar cell is very expensive, however researchers believe it was important to show the upper limit of what is possible in terms of efficiency. Despite the current costs of the materials involved, the technique used to create the cells shows much promise. Eventually a similar product may be brought to market, enabled by cost reductions from very high solar concentration levels and technology to recycle the expensive growth substrates."</em> <a href="https://mediarelations.gwu.edu/scientists-design-solar-cell-captures-nearly-all-energy-solar-spectrum">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_NusEngineersAchieveSignificant.jpg" alt="NUS engineers achieve significant breakthrough in spin wave based information processing technology" class="lefter"></p>

<h2><a href="http://news.nus.edu.sg/press-releases/spin-wave-information-processing">NUS engineers achieve significant breakthrough in spin wave based information processing technology</a></h2>

<p><em>"Novel method of propagating spin waves could pave the way for high speed, miniaturised data processing devices. Conventional electronic devices make use of semiconductor circuits and they transmit information by electric charges. However, such devices are being pushed to their physical limit and the technology is facing immense challenges to meet the increasing demand for speed and further miniaturisation. Spin wave based devices, which utilise collective excitations of electronic spins in magnetic materials as a carrier of information, have huge potential as memory devices that are more energy efficient, faster, and higher in capacity. While spin wave based devices are one of the most promising alternatives to current semiconductor technology, spin wave signal propagation is anisotropic in nature – its properties vary in different directions – thus posing challenges for practical industrial applications of such devices."</em> <a href="http://news.nus.edu.sg/press-releases/spin-wave-information-processing">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_ChaosTheoryStrengthensDigitalL.jpg" alt="Chaos Theory Strengthens Digital Locks" class="lefter"></p>

<h2><a href="https://www.asianscientist.com/2017/07/tech/vector-stream-cipher-cybersecurity/">Chaos Theory Strengthens Digital Locks</a></h2>

<p><em>"Using the principles of chaos theory, researchers from Kyoto University have definitively demonstrated the strength of a 128-bit digital lock for cybersecurity applications. Their findings are published in the journal Nonlinear Theory and Its Applications. How do we know if the electronic keys we use in our devices are really secure? While it is possible to rigorously test the strength of a cipher—a kind of digital data lock—there are rarely any definitive proofs of invulnerability. Ciphers are highly complex, and while they may ward off certain attacks, they might be overcome by others. In this study, the group led by Professor Ken Umeno of Kyoto University released new data on its Vector Stream Cipher (VSC), the first example of a 128-bit key chaotic cipher with provable security. “We first developed VSC in 2004 as a simple, fast cipher, and parts of it have already been utilized in the private sector,” explained Umeno. “Many theoretical attacks in the past have failed to break it, but until now we hadn’t shown definitive proof of security.” The researchers conducted a number of tests, such as a method to evaluate the lock’s randomness. Many ciphers rely on number sequences that appear to be random, but are actually generated through recurring relations that are vulnerable to being reproduced."</em> <a href="https://www.asianscientist.com/2017/07/tech/vector-stream-cipher-cybersecurity/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_CcnyPhysicistsMasterUnexplored.jpg" alt="CCNY physicists master unexplored electron property" class="lefter"></p>

<h2><a href="https://www.ccny.cuny.edu/news/ccny-physicists-master-unexplored-electron-property">CCNY physicists master unexplored electron property</a></h2>

<p><em>"While the charge and spin properties of electrons are widely utilized in modern day technologies such as transistors and memories, another aspect of the subatomic particle has long remained uncharted. This is the “valley” property which has potential for realizing a new class of technology termed “valleytronics” – similar to electronics (charge) and spintronics (spin). This property arises from the fact that the electrons in the crystal occupy different positions that are quantum mechanically distinct. Now City College of New York physicists led by Vinod Menon have demonstrated how to manipulate the “valley” property using light by placing two-dimensional semiconductors in a light trapping structure called microcavity.  This gave rise to half-light-half matter quasi-particles which have the fingerprint of the “valley” property. These quasi-particles were then optically controlled using a laser to access the electrons occupying specific “valley.” The research appears in the latest issue of “Nature Photonics” and is a major step towards realization of “valleytronic” devices for logic gates. “Observing this property in traditional semiconductors was not easy. However with the advent of the new class of two-dimensional semiconductors, this property became accessible to manipulation,” said Zheng Sun, a graduate student in Menon’s research group and lead author of the paper. Other researchers included CCNY graduate students, Jie Gu and Christopher Considine; undergraduate Michael Dollar, postdoctoral researcher Biswanath Chakraborty, Zav Shotan, and  Xiaoze Liu; physics professor Pouyan Ghaemi and his postdoctoral researcher Areg Ghazaryan; and Stephane Kena-Cohen (Ecole Polytechnic, Montreal, Canada) also participated in the study. The work was supported by the NSF through the EFRI 2-DARE program, the ECCS division, the Columbia-CCNY NSF MRSEC Center, the US Army Research Office and a Discovery grant from the Natural Sciences and Engineering Research Council of Canada."</em> <a href="https://www.ccny.cuny.edu/news/ccny-physicists-master-unexplored-electron-property">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_CarbonNanotubesTurnElectricalC.jpg" alt="Carbon nanotubes turn electrical current into light-matter quasi-particles" class="lefter"></p>

<h2><a href="https://www.st-andrews.ac.uk/news/archive/2017/title,1460002,en.php">Carbon nanotubes turn electrical current into light-matter quasi-particles</a></h2>

<p><em>"Material scientists and physicists from Heidelberg University (Germany) and the University of St Andrews (Scotland) have demonstrated electrical generation of hybrid light-matter particles, so-called exciton-polaritons, by using field-effect transistors with semiconducting carbon nanotubes integrated in optical microcavities. The extraordinary stability of these transistors enabled electrical pumping at unprecedented rates, which paves the way for electrically pumped lasers with solution-processed and carbon-based semiconductors. As the emission of these light sources can be tuned across a wide range of the near-infrared spectrum, this work holds particular promise for applications in telecommunications. These results, published in Nature Materials (DOI: 10.1038/nmat4940), are the latest outcome of a fruitful cooperation between Professor Dr Jana Zaumseil (Heidelberg) and Professor Dr Malte C Gather (St Andrews)."</em> <a href="https://www.st-andrews.ac.uk/news/archive/2017/title,1460002,en.php">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="CT117_NewRobotPrinterSpitsOutRecycla.jpg" alt="New robot printer spits out recyclable robots" class="lefter"></p>

<h2><a href="https://en.itu.dk/about-itu/press/news-from-itu/2017/new-robot-printer-spits-out-recyclable-robots">New robot printer spits out recyclable robots</a></h2>

<p><em>"Building a robot takes a long time and when the robot is finally finished, it can usually only be used for one single purpose. Inconvenient in situations where time is scarce and tasks may not be known in advance. In an attempt to solve these challenges, researchers from ITU, MIT, Columbia and Cornell have now developed a robot printer that in a matter of minutes produces simple, yet functional robots that can complete a variety of tasks. "We use a premanufactured material consisting of a one-dimensional aluminum wire with motors that are connected to each other. We then feed the wire to the printer, which then bends the material into a robot whose form determines the function. If the material is folded in a certain way, it will be able to crawl. If you fold it differently, it could potentially climb or roll. After use, you can simply flatten the robot, press a button, and print a robot with a new function,” explains Sebastian Risi, an Associate Professor at ITU."</em> <a href="https://en.itu.dk/about-itu/press/news-from-itu/2017/new-robot-printer-spits-out-recyclable-robots">[...]</a>
 </SPAN></DIV></p>

<h1 id="Modelos-3D">Modelos 3D</h1>

<p>Com a disponibilidade de ferramentas que permitem dar azo a nossa imaginação na criação de peças 3D e espaços como o <a href="http://www.thingiverse.com/">thingiverse</a> para as publicar, esta rubrica apresenta alguns modelos selecionados que poderão ser úteis.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="MP117_BananaJackAdapterForBreadboard.jpg" alt="Banana jack adapter for breadboards" class="lefter"></p>

<h2><a href="https://www.thingiverse.com/thing:2446431">Banana jack adapter for breadboards</a></h2>

<p><em>"I've created this adapter to facilitate the interface between banana plugs and breadboards. It allows you to connect up to four banana plugs on each side of the standard 840 pin breadboard."</em> <a href="https://www.thingiverse.com/thing:2446431">[...]</a>
 </SPAN></DIV></p>

<h1 id="Documentacao">Documentação</h1>

<p>A documentação é parte essencial do processo de aprendizagem e a Internet além de artigos interessantes de explorar também tem alguma documentação em formato PDF interessante de ler. Todos os <em>links</em> aqui apresentados são para conteúdo disponibilizado livremente pelo editor do livro.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="EB117_TheMagpi60.jpg" alt="The MagPI 60" class="lefter"></p>

<h2><a href="https://www.raspberrypi.org/magpi-issues/MagPi60.pdf">The MagPI 60</a></h2>

<p><em>"Your essential guide to solving Raspberry Pi problems. We wanted the perfect Pi troubleshooting guide for our own workshop, and we thought you might like a copy in yours. lus! All this inside issue 60: Get creative with your Raspberry Pi: Build incredible works of art with Raspberry Pi; Turn a Pi Zero W into a Wireless USB Drive: Set up your own network storage device; Hack a fidget spinner into a game pad: Transform a toy into an amazing maze runner controller; Make your own earthquake monitor: Detect quakes with Raspberry Pi Shake; Get started with Scratch 2.0 and Thonny IDE: Learn to use the latest programming tools."</em> <a href="https://www.raspberrypi.org/magpi-issues/MagPi60.pdf">[...]</a>
 </SPAN></DIV></p>

<h1 id="Projetos-Maker">Projetos Maker</h1>

<p>Diversos Projetos interessantes.</p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_UsingOv7670CameraModuleWithArd.jpg" alt="Using OV7670 Camera Module With Arduino" class="lefter"></p>

<h2><a href="https://www.hackster.io/chauhannaman98/using-ov7670-camera-module-with-arduino-1cd980">Using OV7670 Camera Module With Arduino</a></h2>

<p><em>"This is an Arduino camera module, using the Surveillance camera's digital image processing chip-OV0706. The OV7670 image sensor is a small size, low voltage, single-chip VGA camera and CMOS image processor for all functions. It provides full-frame, sub-sampled or windowed 8-bit images in various formats, controlled through the Serial Camera Control Bus (SCCB) interface. The camera module is powered from a single +3.3V power supply, and external clock source for camera module XCLK pin. The OV7670 camera module built-in onboard LDO regulator only requires single 3.3V power and can be used in Arduino, STM32, Chipkit, ARM, DSP, FPGA and etc."</em> <a href="https://www.hackster.io/chauhannaman98/using-ov7670-camera-module-with-arduino-1cd980">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_IotRedPhone.jpg" alt="IoT Red Phone" class="lefter"></p>

<h2><a href="https://www.hackster.io/ulrich-pech/iot-red-phone-083cfe">IoT Red Phone</a></h2>

<p><em>"The phone will ring if you have an alert in your AWS Cloudwatch. If you pick up the handset, it tells you whats wrong. For this project I hacked an old rotary phone, so it will tell me if a HTTP server in my AWS account is down. To do this a Lambda function will check via Cloudwatch Events an EC2 instance by checking a HTML page. The Lambda function is tracked by a Cloudwatch Alert. If the check fails, an alert is triggered and a SNS message is sent to a topic. A second Lambda function is connected to this SNS topic and will forward this message to a MQTT topic. The Pi Zero in the red phone is subscribed to this topic. If a MQTT message is reaching the red phone, it will ring, the Pi than calls the AWS Polly API to transform the text message into an Audio File an plays it on the handset."</em> <a href="https://www.hackster.io/ulrich-pech/iot-red-phone-083cfe">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_HomeMonitoringSystemBasedOnLat.jpg" alt="Home Monitoring System Based on LattePanda, ZigBee and Azure" class="lefter"></p>

<h2><a href="https://www.hackster.io/JiongShi/home-monitoring-system-based-on-lattepanda-zigbee-and-azure-ce4e03">Home Monitoring System Based on LattePanda, ZigBee and Azure</a></h2>

<p><em>"Design your home monitoring system with LattePanda (with Windows 10 Home x64 OS), CC2530 ZigBee devices, and Microsoft Azure services. LattePanda is a powerful development board that can run a full version of Windows 10. It is equipped with an Intel Quad Core processor and has excellent connectivity, with three USB ports, integrated WiFi and Bluetooth 4.0. In this project, our home monitoring system consists of LattePanda (with Windows 10 Home x64 OS), CC2530 ZigBee devices, and Microsoft Azure services. Let’s take a look at the architecture of the proposed system, which is depicted in Fig.1 as follows."</em> <a href="https://www.hackster.io/JiongShi/home-monitoring-system-based-on-lattepanda-zigbee-and-azure-ce4e03">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ZerobotRaspberryPiZeroFpvRobot.jpg" alt="ZeroBot - Raspberry Pi Zero FPV Robot" class="lefter"></p>

<h2><a href="https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot">ZeroBot - Raspberry Pi Zero FPV Robot</a></h2>

<p><em>"ZeroBot is a Raspberry Pi Zero W based robot. It can be controlled using any computer or smartphone via a web browser. The integrated camera module makes for a low latency video stream. In addition the Raspberry Pi acts as a Wifi access point, so no router is required. The parts for the hull as well as the wheels can easily be printed on any regular 3D printer. Some of the key features are:  - Compact CAD design with 3D printed components; - Analog control via a joystick (and multitouch); - Simple battery solution using only a standard power bank; - Low latency streaming (~0.2s); - Easy and cheap to build using widely available components "</em> <a href="https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ArduinoAmigaFloppyDiskReader.jpg" alt="Arduino Amiga Floppy Disk Reader" class="lefter"></p>

<h2><a href="https://www.hackster.io/robsmithdev/arduino-amiga-floppy-disk-reader-485582">Arduino Amiga Floppy Disk Reader</a></h2>

<p><em>"An Arduino powered floppy disk controller and reader for making disk images from old AmigaDOS floppy disks. I owe my career to the Amiga, specifically the A500+ that my parents purchased for me for Christmas at the age of 10. At first I played the games, but after a while I started getting curious about what else it could do. I played with the Deluxe Paint III and learnt about Workbench. Every month I purchased the popular Amiga Format magazine. One month had a free copy of AMOS. I entered the Amiga Format Write A Game In AMOS competition when AMOS Professional was put on a coverdisk later, and was one of the 12 (I think) winners with In The Pipe Line. You really had to chase them for prizes though! Moving on, I used it as part of my GCSEs and A-Level projects (thanks to Highspeed Pascal, which was compatible with Turbo Pascal on the PC) Anyway, that was a long time ago, and I have boxes of disks, and an A500+ that doesn’t work anymore, so I thought about backing those disks up onto my computer, for both preservation and nostalgia. The Amiga Forever website has an excellent list of options that include hardware, and abusing two floppy drives in a PC - Sadly none of these were an option with modern hardware, and the KryoFlux/Catweasel controllers are too expensive. I was really surprised that most of it was closed source. Massively into electronics and having played with Atmel devices (AT89C4051) whilst at University I decided to take a look at the Arduino (credit to GreatScott for the inspiration showing just how easy it is to get started) I wondered if this was possible. So I Googled for Arduino floppy drive reading code, and after skipping all of the projects that abused the drive to play music, I didn’t really find any solutions. I found a few discussions in a few groups suggesting it wouldn’t be possible. I did find a project based around an FPGA which was very interesting reading, but not the direction I wanted to go, so the only option was to build a solution myself."</em> <a href="https://www.hackster.io/robsmithdev/arduino-amiga-floppy-disk-reader-485582">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_HowToConvertOldFilmReelsWithAR.jpg" alt="How to Convert Old Film Reels With a Raspberry Pi" class="lefter"></p>

<h2><a href="http://spectrum.ieee.org/geek-life/hands-on/how-to-convert-old-film-reels-with-a-raspberry-pi">How to Convert Old Film Reels With a Raspberry Pi</a></h2>

<p><em>"My grandfather Leo was a self-taught electrical engineer and IEEE member who designed control systems for tire factories. He was also an avid photographer, and his eight children—and later, his grandchildren—were among his favorite subjects, right up to his death in 1974, when I was 5. Fast-forward to 2013: During a move, my uncle uncovered a trove of more than 130 reels of Leo’s 8-mm and 16-mm home movies, some dating back to 1939. While commercial conversion services exist, converting so many reels would have been pretty expensive, so my cousin and I set out to preserve them digitally ourselves, to better share them with Leo’s enormous extended family. First, a quick primer on film projection for digital natives. In a projector, a motor pulls film through a vertical “gate.” Each film frame is held still and flat in the gate while a lamp illuminates it from within the projector’s housing. Lenses on the other side of the gate focus the image so that it appears sharp on whatever surface the film is projected. Between the gate and the lamp, a rotating shutter wheel blocks the light while the next frame is sliding into position. (Without this shutter, the film would be one big blur.) For our initial movie conversion attempt, we tried to record digital video directly from a projector. We mounted a DSLR camera attached to a series of lenses focused on the gate. We started the projector and camera, and everything initially seemed to be going great. The camera recorded video with excellent detail and color. However, it also highlighted the dirt, cracks, and scratches on many of the reels. Even more problematic, the speed of our projector—as with most—couldn’t be precisely controlled. This meant that even under the best conditions, mismatches between the frame rates of the projector and the camera resulted in rolling dark areas, flickering, and other artifacts. These, along with the dirt and scratches, could not be easily remedied digitally. Going back to the drawing board, we learned that a frame-by-frame transfer—capturing a still image of each film frame and then converting the collection of images into a video—gives far superior results. The still images, in particular, are quite amenable to digital postprocessing. Such transfers are usually performed on specialized equipment for high fees. Fortunately, I remembered there was a spare Super 8 projector in my basement and an unused Raspberry Pi in my closet, and that a Pi camera was just US $30. Could we do a frame-by-frame transfer with these?"</em> <a href="http://spectrum.ieee.org/geek-life/hands-on/how-to-convert-old-film-reels-with-a-raspberry-pi">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ZigfridAPassiveRfidFuzzer.jpg" alt="Zigfrid – A Passive RFID Fuzzer" class="lefter"></p>

<h2><a href="https://z4ziggy.wordpress.com/2017/07/21/zigfrid-a-passive-rfid-fuzzer/">Zigfrid – A Passive RFID Fuzzer</a></h2>

<p><em>"Zigfrid is the end result of my RFID tinkering. Since I will most definitely forget most things described here in the (very) near future, I share this for those few who might find it interesting. Please be warned: This is not a toy. It is completely unreliable, untested, malicious tool, which can and will cause elevators to stop or even shut down immediately, locks to jam, hackers get jailed, and other weird RFID phenomenons. Ok, you get the idea, lets move on. I guess I watched too many movies as a kid, and craved myself one of those futuristic-looking RFID “master keys” which opens all doors [with a few flashing leds for a more attractive effect], but as I grew older and learned there isn’t one I decided to try and build one for myself. I ended up with a tiny passive device consisting an ATtiny85 AVR, an antenna (coil), and 1 capacitor, with no need for external power. It’s so tiny, it can fit in a common chewing gum and glued next to any RF reader to fuzz away. My RFID adventures began with a cheap 20$ Handheld RFID Reader/Copier – a simple battery-powered device with 2 buttons controlling the read &amp; write functions of it’s PCB, which uses an obscure chip labeled with the mysterious “F300 ET94 242+” which later found to be based on a more popular chip C8051F300. I hacked the PCB and connected it via it’s pins to my Arduino and later to my BusPirate in the hope of getting something on it’s serial line via the RX &amp; TX pins – (and maybe later to alter it?) for vain – only a random bits every a few reads was letting me know I’m looking at it all wrong. And I was."</em> <a href="https://z4ziggy.wordpress.com/2017/07/21/zigfrid-a-passive-rfid-fuzzer/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_EcoFriendlyArduinoMetalDetecto.jpg" alt="Eco Friendly Arduino Metal Detector" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Eco-Friendly-Arduino-Metal-Detector/">Eco Friendly Arduino Metal Detector</a></h2>

<p><em>"Metal Detecting is a lot of fun. One of the challenges is being able to narrow the exact place to dig to minimize the size of the hole left behind.This unique metal detector has four search coils, a color touch screen to identify and pinpoint the location of your find.Incorporating auto calibration, a USB rechargeable power pack, with four different screen modes, frequency, and pulse width adjustment which allows you to customize how you search.Once you have pinpointed the treasure a single hole centered above each coil enables you to use a wooden skewer to push into the earth so you can start to dig a small plug from the ground reducing damage to the environment.Each coil can pinpoint detect coins and rings at a depth of 7-10cm so is ideal for looking for lost coins and rings around parks and beaches."</em> <a href="http://www.instructables.com/id/Eco-Friendly-Arduino-Metal-Detector/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_EspAlarmMakeAnIotWiFiEnabledAl.jpg" alt="ESP Alarm: Make an IoT, Wi-Fi Enabled Alarm Clock with an ESP8266" class="lefter"></p>

<h2><a href="https://www.allaboutcircuits.com/projects/esp-alarm-set-alarms-from-your-mobile-phone-esp8266-arduino-uno-wifi-iot/">ESP Alarm: Make an IoT, Wi-Fi Enabled Alarm Clock with an ESP8266</a></h2>

<p><em>"The “ESP Alarm” is a connected alarm with your smart phone via Wi-Fi using ESP8266 module. You can add/modify/delete/activate/deactivate alarms using an Android application when the device is up and connected with the same Wi-Fi network which your phone is connected to. It’s common to set-up alarms using our mobile phones to wake up in the morning—and it’s not unusual to set-up several alarms in an attempt to wake up at a specific time. The problem is that, after we finally wake up, sometimes our phone's battery is drained during the battle to get up from bed! So I decided to make an “ESP Alarm” device that allows me to set alarms using my smartphone through Wi-Fi and leave the rest to the alarm clock. In simple terms, it’s a Wi-Fi-enabled, IoT alarm clock! This is my second project using the tiny monster ESP8266 Wi-Fi module. Check out my first project, "How to Build a Control Circuit with Adjustable Working Time via Wi-Fi" here on AAC."</em> <a href="https://www.allaboutcircuits.com/projects/esp-alarm-set-alarms-from-your-mobile-phone-esp8266-arduino-uno-wifi-iot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_DiyPwmController.jpg" alt="DIY PWM Controller" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/DIY-PWM-Controller/">DIY PWM Controller</a></h2>

<p><em>"In this instructable, I will show you how to make PWM Controller. I'm using the laminator for the toner transfer method. What things you will need: Copper - clad board (Dual Layer) Ferric Chloride (FeCl3) Acetone (Nail polish remover) Glossy Paper LASER Printer Marker Pen Scissors Plastic container Sand paper Safety gloves Latex gloves Saw - For copper board cutting Laminator or iron"</em> <a href="http://www.instructables.com/id/DIY-PWM-Controller/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_RoboticArm3DPrintedDiyInitialP.jpg" alt="Robotic Arm 3D Printed (DIY Initial Prosthetic Prototype)" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Robotic-Arm-3D-Printed-DIY-Initial-Prosthetic-Prot/">Robotic Arm 3D Printed (DIY Initial Prosthetic Prototype)</a></h2>

<p><em>"Most open source robotic hands are limited by the fact they have servos in the forearm, which is the logical place to put them, given the vast space in the arm. However this restricts the wrist motion as the strings attaching the fingers to the servos run through the wrist and if the wrist rotates the strings will pull on the fingers, moving the fingers when they should otherwise be stationary.Instead by hacking apart and redesigning several sg90 servos I was able to fit all the required servos inside the palm of the hand which allowed me to create a wrist that rolls in a similar motion to that of a humans. Whether or not you decide to build this arm the steps about the servos and how to make them compact and continuously rotate might be of interest.Counter-intuitively to what Instructables is meant for I do NOT encourage anyone to build this arm. This prototype has several flaws as outlined in the link below. Rather this is documentation of my experience in the hopes it can help others who wish to design a robotic arm avoid the same pitfalls. If you wish to build this arm by all means do, but just be prepared to troubleshoot and problem solve as you go. I have made all the code and .f3d files available online. If you just want to build a robotic arm that works without problems I would suggest either the InMoov hand or the Flexy Hand (although you will need to redesign the forearm to work with servos)."</em> <a href="http://www.instructables.com/id/Robotic-Arm-3D-Printed-DIY-Initial-Prosthetic-Prot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_LedPovDisplayWithArduinoUno.jpg" alt="Led POV Display With Arduino UNO" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Led-POV-Display-With-Arduino-UNO/">Led POV Display With Arduino UNO</a></h2>

<p><em>"Persistence of vision refers to the optical illusion that occurs when visual perception of an object does not cease for some time after the rays of light proceeding from it have ceased to enter the eye."</em> <a href="http://www.instructables.com/id/Led-POV-Display-With-Arduino-UNO/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ArduinoUnoWirelessWeatherStati.jpg" alt="Arduino Uno Wireless Weather Station" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Uno-Wireless-Weather-Station-Wundergroundc/">Arduino Uno Wireless Weather Station</a></h2>

<p><em>"In this Instructable I am going to show you how to build a Wireless Weather Station using ArduinoA Weather station is a device that collects data related to the weather and environment using many different sensors. We can measure many things like: TemperatureHumidityWindBarometric PressureUV index RainMine inspiration to create this weather station is Greg from www.cactus.io Davis anemometer, wind speed and rain meter Arduino code copyright rights belong to him. I'm using Arduino Uno as main board. ESP8266 WiFi module will send data to www.wunderground.com Weather Underground is a commercial weather service providing real-time weather information via the Internet.I will use these sensors:Temperature - Dallas DS18B20 Humidity, Pressure - BME280UV, Solar - ML8511Anenometer and wind speed - Davis 6410Rain gauge - Ventus W174"</em> <a href="http://www.instructables.com/id/Arduino-Uno-Wireless-Weather-Station-Wundergroundc/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ReverseEngineeringTheSymaS107G.jpg" alt="Reverse Engineering the Syma S107G IR Protocol" class="lefter"></p>

<h2><a href="http://www.kerrywong.com/2012/08/27/reverse-engineering-the-syma-s107g-ir-protocol/">Reverse Engineering the Syma S107G IR Protocol</a></h2>

<p><em>"I got a Syma S107G IR controlled helicopter for my son a while ago. This tiny remote control helicopter is a rather amazing toy. Not only its movement is very stable, but the rotor speed, forward backward movements and turning can be all proportionally controlled as well. I thought it might be interesting to take a look at its control protocol to see how things are done. And yes, I do have a video at the very end showing controlling the S107G using the reverse engineered remote control. Before I started decoding the IR protocol, I was hoping that I could find some useful information by examining the circuit board of the remote control."</em> <a href="http://www.kerrywong.com/2012/08/27/reverse-engineering-the-syma-s107g-ir-protocol/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_GhettoProgrammingGettingStarte.jpg" alt="Ghetto Programming: Getting Started With AVR Microprocessors on the Cheap" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Ghetto-Programming%3A-Getting-started-with-AVR-micro/">Ghetto Programming: Getting Started With AVR Microprocessors on the Cheap</a></h2>

<p><em>"Microprocessors are so cheap these days. If only there were a way to program them up just as cheaply... *wavy dream-sequence lines*In this instructable, find out how to build up a complete AVR microprocessor toolchain: compiler, programmer software, programmer hardware, and some simple demos to get your feet wet. From there, it's just a hop, skip, and a jump to world domination.The endpoint is not quite as swanky as Atmel's suite, but it's gonna run you about $150 less and take only a little more work to get it set up. This instructable is based on the Atmel ATtiny 2313 chip, mostly because it's one of the smaller chips (in size) while still being beefy enough to do most anything. And at $3 a pop (non-bulk), they don't break the bank. That said, most of the steps are applicable across the AVR family, so you'll be able to re-use most everything when your programming needs outgrow the ATtiny and you reach for the $8-$12 ATmegas."</em> <a href="http://www.instructables.com/id/Ghetto-Programming%3A-Getting-started-with-AVR-micro/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_Esp32SolarWeatherStation.jpg" alt="ESP32 Solar Weather Station" class="lefter"></p>

<h2><a href="https://www.hackster.io/Tiobel/esp32-solar-weather-station-bf9c23">ESP32 Solar Weather Station</a></h2>

<p><em>"Get the temperature, humidity and pressure, and display them over the internet; everything is powered by the sun. For my first IoT project I wanted to build a Weather Station and send the data to data.sparkfun.com. Small correction: when I decided to open my account in Sparkfun, they were not accepting more connections, so I chose another IoT data collector...thingspeak.com. The system will be placed on my balcony and will retrieve temperature, humidity and air pressure. The microcontroller selected for this project is the FireBeetle ESP32 IOT Microcontroller supplied by DFRobot. Please check DFRobot wiki page for more info regarding this microcontroller and how to upload the code using Arduino IDE. All the physic parameters are given by the BME280 sensor. Also check the wiki page for some more info. To turn the system completely "wireless" the power necessary is provided by two 6V solar panels that can deliver 2W of power. The cells will be connected in parallel. The energy produce is then be stored in a 3.7V Polymer Lithium Ion Battery with +/- 1000mAh capacity. The Solar Lipo Charger module from DFRobot will be responsible for the energy management."</em> <a href="https://www.hackster.io/Tiobel/esp32-solar-weather-station-bf9c23">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_GloveForBlind.jpg" alt="Glove for Blind" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Glove-for-Blind/">Glove for Blind</a></h2>

<p><em>"Many techniques have to evolved in past twenty years to help visually challenged people.The new technology that is helping them,although has many features and applications but it is not economical and so people are spending lot of money on it.The glove that I have made is most cheapest and simple way to alert them about the surrounding objects which would be in their way of walking.When we put on the glove we are flexible to move our hands and so we could detect objects in all directions which are in 100 cm of our range.The glove gives a visually challenged person to walk freely without anyone's help.The glove detect objects in 100 cm range and gives feedback by creating an alarming sound and also vibrating our hand and by this he is alerted from encountering the objects.It cost me RS 600 for making this glove.So lets get ready!"</em> <a href="http://www.instructables.com/id/Glove-for-Blind/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_FingerSixAxisRobotArmChallenge.jpg" alt="Finger Six Axis, Robot Arm Challenge" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Finger-Six-Axis-Robot-Arm-Challenge/">Finger Six Axis, Robot Arm Challenge</a></h2>

<p><em>"Hello this is 3DMeister Julius. Enjoy my project and forgive my english!This is an experimental prototype, a manual controlled mechanic 6 axis robot arm. All 6 axis are connected with two pull cables wich are connected to one slide controller. 3 rotation axis and 3 hinge axis, driven by the closed loop cables with the fingers, can turn and lift at the same time.The target of this experiment was to find out more about multi axis robot arm movements, possibilities and fun.You are welcome try this at home, i hope to see enhancements, don't blame me, there is much that can be done with this schematics, maybe start with only 2 axis.Download and check the 3D model from Grabcad or Thingiverse.https://grabcad.com/library/cable-6-axis-robot-arm...https://www.thingiverse.com/thing:2448938Look at recent 6-axis tests, movements with this gadget:https://www.instagram.com/sixaxistoy/Watch how i made this toy.Write a comment and recommend this project to someone who might be interested."</em> <a href="http://www.instructables.com/id/Finger-Six-Axis-Robot-Arm-Challenge/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_BluetoothRcCarUsingL293DHc05.jpg" alt="Bluetooth RC Car Using L293D & HC-05" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/RC-Car-Using-L293D-HC-05/">Bluetooth RC Car Using L293D &amp; HC-05</a></h2>

<p><em>"Hey! Guys How You all doing!Today I am Here With My First Arduino Instructable.It is A Bluetooth Controlled RC Car Using Only L293D IC (No Motor Shields).You Can Use Motor Drivers/H-Bridge Also.The Car Works Well! Also I Designed The App..Please Have a Look At it.I wanted to have the information I learned in one place, and easy to Understand.Comments and suggestions are welcome and appreciated as I'm still trying to learn all this stuff."</em> <a href="http://www.instructables.com/id/RC-Car-Using-L293D-HC-05/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_IrRemoteControlledRobot.jpg" alt="IR Remote Controlled Robot" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/IR-Remote-Controlled-Robot/">IR Remote Controlled Robot</a></h2>

<p><em>"hello guys..this is our new project thats called ir remote controlled robot using arduino.thats controlled by any remote...we have used as ir remote...so lets start."</em> <a href="http://www.instructables.com/id/IR-Remote-Controlled-Robot/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_3DPrintYourOwnLeatherStamps.jpg" alt="3D Print Your Own Leather Stamps" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/3D-Print-Your-Own-Leather-Stamps/">3D Print Your Own Leather Stamps</a></h2>

<p><em>"You can create some beautiful patterns and textures by stamping leather, but there are only so many options for pre-made leather stamps. I was excited by the idea of having full creative control over my leather projects with my own custom designed stamps, and I wanted to see if I could do it with 3D printing.The stamps I ended up creating were simple to design and they worked surprisingly well. They might not have quite the durability or definition that metal stamps do, but they still created some great patterns. I now have a million more ideas for interesting ways to use this technique, and I think it has the potential to create some very unique designs that differ from the familiar leatherworking aesthetic. This would also be a great way to add a logo stamp to personalize your designs if you are creating leather pieces to sell."</em> <a href="http://www.instructables.com/id/3D-Print-Your-Own-Leather-Stamps/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ConvertYourPringlesCansToRtttl.jpg" alt="Convert Your Pringles Cans to RTTTL Audio Player" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Convert-Your-Pringles-Cans-to-Audio-PlayerSimple-R/">Convert Your Pringles Cans to RTTTL Audio Player</a></h2>

<p><em>"hello everyone , in this tutorial I will show you how to build a RTTTL player ,and I will show you how to do that using Teensy 3.1 .You can expand the number of the songs you want to add , and will show you how to do that later and give you a resources for more than 10K files.first , let's talk a look for what we need : Teensy 3.1 MCU board. 8 ohm speaker Nokia 5110 PCD8544 LCD Button * 2 pcs potentiometer jumpers(female-male and male-male) resistor 2.2K mini breadboard DC power jack 2.1mm. drill. Something to hold everything inside , I used Pringles can as the only choice I had"</em> <a href="http://www.instructables.com/id/Convert-Your-Pringles-Cans-to-Audio-PlayerSimple-R/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_MechanicalIrisDoor.jpg" alt="Mechanical Iris Door" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Mechanical-Iris-Door/">Mechanical Iris Door</a></h2>

<p><em>"For a really long time now, my dad has wanted an automatic chicken door coop. A few weeks before fathers day I decided I would make one for him. But on the fathers day I knew I wouldn't have time to finish. I then decided I would continue to think about it but wait until summer to start it. It's a good thing I did. This project ended up taking way longer than I thought it would. However, I am really proud of what I have made. I think it was well worth the time I put into it. I certainly learned a lot.If you want to learn how to make the bow tie featured read this Instructable."</em> <a href="http://www.instructables.com/id/Mechanical-Iris-Door/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ArduinoLatencyMeasurementToolk.jpg" alt="Arduino Latency Measurement Toolkit" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Latency-Measurement-Toolkit/">Arduino Latency Measurement Toolkit</a></h2>

<p><em>"In this Instructable we will show you how to do simple input latency measurements with an Arduino.This instructable is part of a final project of the lecture Designing Interactive Systems 2 from the Media Computing Group at the RWTH Aachen University. It was created with the support of the Fablab Aachen.Goal of this project is to describe how to build a measurement system with simple and cheap components, that measures the latency between a mouse click (or a different input signal) and the actual change of an object on the computer screen. This system can be used in HCI research to compare different input methods or simply measure the latency of different systems.To measure the latency of a system reliable we need to connect sensors from the outside to it that can not be influenced by the system itself. To accomplish this, we use a pressure sensor to detect the input of the system. A pressure sensor can be placed for example on top of any mouse button without disassembling the mouse and can sense when the mouse button is pressed. Additionally this sensor can be placed on any other button (like a key from a keyboard), a touchpad or in some cases even on a touchscreen. This external sensor is independent of the mouse button itself. The change on the screen will be detected with a lightsensor (diode) that is placed directly on the screen surface. This diode will measure the change of the light emitted by the screen at a specific point. In our case we use a simple website that changes the color from black to white when clicked. The measurement itself will take place on an Arduino microcontroller board that is connected to the light sensor and the pressure sensor. This way the measurement system is independent from the system that will be measured. Our system has its limitations and is meant to be seen as a basis for future latency measurement systems."</em> <a href="http://www.instructables.com/id/Arduino-Latency-Measurement-Toolkit/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ProgrammableLed.jpg" alt="Programmable LED" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Programmable-LED/">Programmable LED</a></h2>

<p><em>"Inspired by various LED Throwies, blinking LEDs and similar instructables I wanted to do my version of an LED controlled by a microcontroller.The idea is to make the LED blinking sequence reprogrammable. This reprogramming can be done with light and shadow, e.g. you could use your flashlight.This is my first instructable, any comments or corrections are welcome.Update 12/08/2008: There is now a kit available at the Tinker Store.Here is a video of reprogramming it. Sorry for the quality."</em> <a href="http://www.instructables.com/id/Programmable-LED/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_JarOfFireflies.jpg" alt="Jar of Fireflies" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Jar-of-Fireflies/">Jar of Fireflies</a></h2>

<p><em>"This project uses green surface-mount LED's along with an AVR ATTiny45 microcontroller to simulate the behavior of fireflies in a jar. (note: the firefly behavior in this video has been greatly sped up in order to be easier to represent in a short film. The default behavior has significantly more variance in its brightness and delay between plays.)"</em> <a href="http://www.instructables.com/id/Jar-of-Fireflies/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_MiniCnc3DPrintedPcbCreator.jpg" alt="Mini CNC 3D Printed PCB Creator" class="lefter"></p>

<h2><a href="https://www.hackster.io/DamienHarman/mini-cnc-3d-printed-pcb-creator-47af42">Mini CNC 3D Printed PCB Creator</a></h2>

<p><em>"This project makes a mini CNC 3D printer. For a previous project, I wanted to be able to create PCB's quickly and simply. I have tried many methods: Toner Transfer (Iron Method); Photosensitive; Hand Drawing. None of these I found particularly inspiring or reliable. So after watching countless videos on Mini CNC machines, I have decided to build my own. I have been using Google SketchUp to design my parts and my AnyCubic Kossel to realize my designs. The design phase has been quite challenging for me, making sure each part has the correct dimensions and that each component will work with the rest of the project. Then you have to print it, and things very rarely go to plan, so you then need to tweak it. Re-model in SketchUp and Re-Print."</em> <a href="https://www.hackster.io/DamienHarman/mini-cnc-3d-printed-pcb-creator-47af42">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_SenseAndDisplayWithAndroidThin.jpg" alt="Sense and Display with Android Things and Kotlin" class="lefter"></p>

<h2><a href="https://www.hackster.io/andri/sense-and-display-with-android-things-and-kotlin-705304">Sense and Display with Android Things and Kotlin</a></h2>

<p><em>"This project shows how to get started to read I2C temperature sensor and display the reading to OLED display using Android Things and Kotlin. Imagine that you can leverage your existing Android programming skill you acquired for many years, to develop app for Internet of Things. Android Things allows you to do that. Personally, I'm happy with Google direction to take on Internet of Things. As an IoT influencer and maker in Indonesia, I need to learn and share it to the community. And just about tme, on last Jul 22, I had the opportunity to share about Android Things development in a event called Google I/O Extended Jakarta - Indonesia. But developing for Android, and also Android Things, requires us to use Java (you can always C++ with NDK, but that's not for mere-mortals :)). I have no issue with Java, I acquired Java skill since 18 years ago, working on my under-graduated project with it, and always be part of my life. I've also been using Java for developing Android apps since 4 years ago. But my love to it became less and less lately due to its nature and new languages came along. Luckily, there's a new kid on the block, Kotlin. Actually, it's been around since 2011, but made popular lately, especially after Google announced to officially use it for developing for Android. It kinda made me curious how good it is. So, to learn developing for Android Things, I think it will be a good opportunity to also learn Kotlin. So, this project is my first attempt to use Kotlin. It turns out, Kotlin is very easy to learn. I have a bonus already having experience with Swift programming language, you know, the one that you can use to develop app for Apple platforms. Turns out both languages share similar syntax. I don't say Kotlin copies Swift or vice versa, I just happen to know Swift first. So the learning journey began. It's very hard to learn new technologies without objective, so this project is my objective to learn Kotlin."</em> <a href="https://www.hackster.io/andri/sense-and-display-with-android-things-and-kotlin-705304">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_HowToMakeASafetyBox.jpg" alt="How to Make a Safety Box" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/How-to-Make-a-Safety-Box/">How to Make a Safety Box</a></h2>

<p><em>"It is so hot! I am surprised to find that my beers are gone! To avoid this situation happens again, I decided to DIY a private safe to keep my drinks.Come on! Chocho shows an ultimate skill now~Hardware in need:FireBeetle ESP32 board×1 FireBeetle Covers-Gravity I/O Expansion Shield ×1 Gravity: Digital Push Button ×1 3-Wire LED Module 8 Digital (Arduino Compatible)×1 Rotary Encoder ×1 Crash sensor ×1 9g micro servo ×1 Dupont wires Cardboard *Click here to download software code in need."</em> <a href="http://www.instructables.com/id/How-to-Make-a-Safety-Box/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_WaterLevelIndicator.jpg" alt="Water Level Indicator" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Water-Level-Indicator-2/">Water Level Indicator</a></h2>

<p><em>"Hello friends this is my another video, this is a simple project which is very useful in every home, the main attribute of this project is that, it is very simple and anybody can make this with almost zero knowledge of electronics. I also installed this kit in my home and it is working very good from 2 years.Basically this is a water level Indicator, in this circuit I am using 4 NPN Transistors, so it can indicate total four level of Water, three levels are indicated by Led's and fourth level which indicate full is indicated by a buzzer."</em> <a href="http://www.instructables.com/id/Water-Level-Indicator-2/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_HowToMakeAnIronManArcReactor.jpg" alt="How to Make an Iron Man Arc Reactor" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/How-to-make-an-Iron-Man-Arc-Reactor/">How to Make an Iron Man Arc Reactor</a></h2>

<p><em>"Iron Man Arc Reactor This instructable is one of two parts detailing how to build an arc reactor and an iron man mask. Both work together but are written as seperate instructables for clarity. This part is for the Arc Reactor the Iron Man Mask can be found here: https://www.instructables.com/id/How-to-make-an-Iron-Man-Mask/My costume was built for a fancy dress party but it is so cool I'm thinking about wearing it else where.First I needed something to copy, I work best when I'm copying someone elses ideas so I used the following screen shot of Tony Stark in Iron man as a basis for my arc reactor. As you can see it has 10 well defined sections and a glowing centre. I'm also going to use the sleeveless T-shirt and I attempted to grow my own facial hair in time for the party.I'm rather pleased at my attempt to make the arc reactor and very happy with the segments of light that eminate from it. I'd also like to pay respects to the other arc light reactor on instructables, imagine my horror as the weekly round up arrives in my inbox only find out that I had been beaten to the write up for the same project."</em> <a href="http://www.instructables.com/id/How-to-make-an-Iron-Man-Arc-Reactor/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_RingPong.jpg" alt="Ring Pong" class="lefter"></p>

<h2><a href="https://www.hackster.io/aerodynamics/ring-pong-b91a4f">Ring Pong</a></h2>

<p><em>"A simple Ping Pong game played on a NeoPixel Ring with Arduino. The main purpose of this simple project was to create a game for the Neopixel Ring (24px in this case). It ended up with a simple ping pong game on a ring so a RING PONG. It is quite simple to build. You only need 2 buttons, an arduino board and the Neopixel ring. To play : The first player push the button, it engages the ball at normal speed. The 2nd player has to push his button when the ball is in the 3 last pixel before the green one. If he pushes on the last pixel he has super speed on his ball. If he misses the ball or press to soon, it is one point for the other player. When the ball goes back to the first player, the same rules apply for him. The game ends when a player has 3 pts. Futher improvement will be adding a box and some fancy buttons..."</em> <a href="https://www.hackster.io/aerodynamics/ring-pong-b91a4f">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_RaspberryPiZeroGarageDoorOpene.jpg" alt="Raspberry PI Zero Garage Door Opener Using Blynk" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Raspberry-PI-Zero-Garage-Door-Opener-Using-Blynk/">Raspberry PI Zero Garage Door Opener Using Blynk</a></h2>

<p><em>"Ever lose a garage door opener and looked for a replacement on Amazon? The replacements for my garage door were $20-$30. I figured I'd make one using a $10 pi zero (Ok for like $30 after all accessories) but at least I can use it to control my garage from anywhere I am connected to the internet.Materials:PI Zero Wireless and all accessories (power supply, gpio header, case, etc)4 channel Relay (you can use a 1 ch or 2 ch, but the price difference for 4 ch was very little so I bought the 4 ch)Blynk app (App store and http://www.blynk.cc/ )If you can follow instructions and have some linux/unix experience, you should be able to do this pretty easily."</em> <a href="http://www.instructables.com/id/Raspberry-PI-Zero-Garage-Door-Opener-Using-Blynk/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_EasyDiyArduinoTouchSensorPiano.jpg" alt="Easy DIY Arduino Touch Sensor Piano" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Easy-DIY-Arduino-Touch-Sensor-Mini-Piano/">Easy DIY Arduino Touch Sensor Piano</a></h2>

<p><em>"This mini piano requires no soldering and is very easy to make.It's a great starter project to get into Arduinos. I had tons of fun making it and playing it once finished!This project can be completed by anyone, from children to seniors!I got the inspiration for this project from Julian Ilett's first penny organ video. If you like electronics, and have not seen his amazing YouTube channel, check it out here: https://www.youtube.com/channel/UCmHvGf00GDuPYG9DZ...I remade and simplified it so that anyone can build it!This has gone through several iterations (each looking better than the last) and this is the best one so far!"</em> <a href="http://www.instructables.com/id/Easy-DIY-Arduino-Touch-Sensor-Mini-Piano/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_ArduinoKeyboardPianoWith8BitR2.jpg" alt="Arduino Keyboard Piano With 8 Bit R2R DAC" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Arduino-Keyboard-Piano-With-8-Bit-R2R-DAC/">Arduino Keyboard Piano With 8 Bit R2R DAC</a></h2>

<p><em>"I used an Arduino to generate sin waves of the appropriate frequency which are then triggered by the keypad.This project uses an external speaker to play the tones. The arduino sends audio data via AUX cable.Features-Plays the basic notes SA, RE, GA, MA, PA, DHA, NI, SA, as well as the komal and teevra notes re, ga, teevra ma, dha and a note of the next octave for total 13 distinct notes.A test button which plays all these notes in succession when pressed.A record feature: Press this button to begin recording. The led attached to pin 13 will blink while it records.Play feature: Play the recorded sound."</em> <a href="http://www.instructables.com/id/Arduino-Keyboard-Piano-With-8-Bit-R2R-DAC/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_SequencerForElectronicMusic.jpg" alt="Sequencer (for electronic music)" class="lefter"></p>

<h2><a href="http://owyheesound.com/sequencer.php">Sequencer (for electronic music)</a></h2>

<p><em>"A sequencer used for music is a device that sequences musical events for predictable playback. For early electronic instruments these sequencers often take the form of a collection of switches that are cued in series and which trigger some other device like an VCA. The switches may also be used to control a variable voltage source which controls the pitch of an oscillator. The sequencer most commonly has a number of switches that is a multiple of 2 like 4, 8, 12, 16, and has a looping function so that the series of switching may restart as soon as the last switch in series is triggered. The sequencer is primarily designed around the 4017 ic chip. The 4017 is a decade counter that can be reset to start over counting from one at any step. This is achieved by connecting the next sequential step to the reset pin. For example if you want the sequencer to count to five and start over the step six pin is connected to the reset pin, and if you want the sequencer to count to step 8 and start over then the step nine pin should be connected to reset pin. To get further detail about the 4017 chip simply google image search "4017 data sheet" From the 4017 chip several features are provided in the above schematic including a voltage out that can control any VCO (voltage controlled oscillator) like the ones found on Moog, Dot Com, Paia Doepher, and other analog synths. Each step has a potentiometer that may assign a specific voltage for that step. This allows for 8 note melodies or bass riffs to be easily programmed. Another feature is the S-Trigger/Gate output option. This sequencer may be used as a rhythmator type sequencer by using the s-trigger output. The s-trigger can be used to control the through put of any line level audio signal, and by toggling the switches for each step patterns can be created beyond simple binary oscillations. The gate is similar but sends a voltage to its output to control other devices like VCA (voltage controlled amplifiers) or even envelope generators on analog synthesizers."</em> <a href="http://owyheesound.com/sequencer.php">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_SimpleRcMecanumWheelsRobotWifA.jpg" alt="Simple RC Mecanum Wheels Robot Wif Arduino " class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Simple-RC-Mecanum-Wheels-Robot-Wif-Arduino/">Simple RC Mecanum Wheels Robot Wif Arduino </a></h2>

<p><em>""The Mecanum wheel is a design for a wheel which can move a vehicle in any direction."This robot/car is just a hand large and is quite simple to build (except the wheels) :)This RC mecanum wheels robot consist of two parts: the robot/car body and the joystick controller."</em> <a href="http://www.instructables.com/id/Simple-RC-Mecanum-Wheels-Robot-Wif-Arduino/">[...]</a>
 </SPAN></DIV></p>

<p><DIV class="articledetail"><SPAN class="articledetail">
<img src="PM117_PortableWifiAnalyzer.jpg" alt="Portable WiFi Analyzer" class="lefter"></p>

<h2><a href="http://www.instructables.com/id/Portable-WiFi-Analyzer/">Portable WiFi Analyzer</a></h2>

<p><em>"This instructables shows how to use a Tic Tac sweet box make a portable WiFi Analyzer.You may find more background in my previous instructables. WiFi Analyzer is very useful in some situations: WiFi everywhere now and 2.4 GHz is still most compatible frequency. At my home and office, I can found over 20 AP SSID but 2.4 GHz only have 11 channels. That means the signal substantially overlapped and interference degrade the network performance. Choose a right channel for your AP is very important. For example, in the above photo snap situation, channel 8 and 9 is much better than others. If you need to use free WiFi in the street, you may choose one with strongest signal strength, but it is not always the fastest network. if you can find a channel with lesser overlapping you should have better experience. For example, in the above photo snap situation, channel 4 and 6 is much better than channel 11. Portable device share file wirelessly by building temporary AP with a random channel. Sometime it may hit a channel that already very busy and transfer file very slow. WiFi Analyzer can help you detect this situation, normally restart the device wireless sharing function can switch to another random channel. If you found other useful situation, leave me a comment. ;>"</em> <a href="http://www.instructables.com/id/Portable-WiFi-Analyzer/">[...]</a>
 </SPAN></DIV></p>

<hr />

<p>That's all Folks!</p>

<script data-cfasync="false" src="../../../../../../cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>SHB.build({elementID: 'shb', pref: { btnSizeClass: 'btn-md', btnClass: 'btn my-btn'}, buttons: { fbLike: true, fbShare:true, tweet: true, plusOne: true, plusShare: true,linkedInShare:true}});</script>

					</div>
				</section>
				</div> <!-- Container -->

				<footer id="footer" class="panel-footer">
					<div class="inner">
						<a href="https://github.com/PhileCMS/Phile">Phile</a> was made by <a href="https://github.com/PhileCMS">The PhileCMS Community</a>.
					</div>
				</footer>
			</div>
		</div>
</div>
		<script type="text/javascript">
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-20725619-1']);
            _gaq.push(['_trackPageview']);
            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
        </script>
		<!-- Matomo -->
<script type="text/javascript">
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//matomo.altlab.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '2']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
	</body>
</html>
